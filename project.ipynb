{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train an MLP with 2 inputs, 3-4+ hidden units and one output on the following examples (XOR function):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) Build a perceptron\n",
    "A stack of perceptrons together == hidden layer a.k.a a dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, X, y, hidden_units=3, epochs=100, learning_rate=.1, random_state=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.hidden_units = hidden_units\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def checkParameters(self):\n",
    "        self.num_inputs = self.X.shape[1]\n",
    "        self.num_outputs = self.y.shape[1]\n",
    "        if self.X.shape[0] != self.y.shape[0]:\n",
    "            raise ValueError('X and Y have mismatched shapes')\n",
    "        if self.num_inputs < 1:\n",
    "            raise ValueError('Must have at least 1 input')\n",
    "        if self.num_outputs < 1:\n",
    "            raise ValueError('Must have at least 1 output')\n",
    "        if self.hidden_units < 1:\n",
    "            raise ValueError('Must have at least 1 hidden unit')\n",
    "        if self.epochs < 1:\n",
    "            raise ValueError('Must train for at least 1 epoch')\n",
    "        #Is it a max of 1 also??\n",
    "        if self.learning_rate <=0:\n",
    "            raise ValueError('Learning rate must be greater than 0')\n",
    "    \n",
    "    def tan_h_deriv(self, x):\n",
    "        return 1 - (x**2)\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        sig = (1 / (1 + np.exp(-x)))\n",
    "        if deriv is True:\n",
    "            return x * (1-x)\n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "     \n",
    "    def myLogLoss(self, deriv=False):\n",
    "        #epsilon is to avoid divide by zero errors\n",
    "        epsilon = 1e-5\n",
    "        if deriv is True:\n",
    "            return -(self.y/self.output) + ((1-self.y)/(1-self.output))\n",
    "        return (1/self.num_inputs) * np.sum(-((self.y * np.log(self.output+epsilon)) + (1 - self.y)  * np.log(1 - self.output + epsilon)))\n",
    "    \n",
    " \n",
    "    def forward(self):\n",
    "        self.z1 = self.X@self.w1 + self.b1\n",
    "        self.a1 = np.tanh(self.z1)\n",
    "        self.z2 = self.a1@self.w2 + self.b2\n",
    "        self.output = self.sigmoid(self.z2)\n",
    "   \n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss = self.myLogLoss()\n",
    "        d_output = self.myLogLoss(deriv=True) * self.sigmoid(self.output, deriv=True)\n",
    "        d_w2 = (1/self.num_inputs) * (self.a1.T @ d_output)\n",
    "        d_b2 = (1/self.num_inputs) * (np.sum(d_output, axis = 0, keepdims=True))\n",
    "        d_z1 = (d_output@self.w2.T) * self.tan_h_deriv(self.a1)\n",
    "        d_w1 = (1/self.num_inputs) * (self.X.T@d_z1)\n",
    "        d_b1 = (1/self.num_inputs) * (np.sum(d_z1, axis=0, keepdims=True))\n",
    "\n",
    "        self.w1 -= (self.learning_rate * d_w1)\n",
    "        self.w2 -= (self.learning_rate * d_w2)\n",
    "        self.b1 -= (self.learning_rate * d_b1)\n",
    "        self.b2 -= (self.learning_rate * d_b2)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.checkParameters()\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        #Xavier initialization to train model to converge faster\n",
    "        self.w1 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.num_inputs+self.hidden_units)),\n",
    "                                size = (self.num_inputs, self.hidden_units))\n",
    "        self.w2 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.hidden_units+self.num_outputs)),\n",
    "                                size = (self.hidden_units, self.num_outputs))\n",
    "        self.b1 = np.zeros((1,self.hidden_units))       \n",
    "        self.b2 = np.zeros((1,self.num_outputs))\n",
    "        for i in range (self.epochs):\n",
    "            self.forward()\n",
    "        #    print(\"Epoch {} Loss is {}\".format(i+1, self.loss))\n",
    "            self.backward()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.X = x\n",
    "        self.forward()\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(([0, 1],[1,0], [1,1], [0,0]))\n",
    "y = np.array(([1],[1],[0],[0]))\n",
    "test = MLP(x,y,4,random_state=0, epochs=100000)\n",
    "test.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99985229],\n",
       "       [0.99998968],\n",
       "       [0.00014796],\n",
       "       [0.00009289]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "test.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "y_data = []\n",
    "for n in range(100):\n",
    "    data.append(np.random.uniform(low=-1.0,high=1.0, size=(4, 1)))\n",
    "    y_data.append(np.sin(data[-1][0] - data[-1][1] + data[-1][2] - data[-1][3]))\n",
    "y_data = np.array(y_data)\n",
    "X_data = np.array(data)\n",
    "X_data = X_data.reshape(100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=0, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998459796152872\n",
      "-0.9996706301937582\n"
     ]
    }
   ],
   "source": [
    "print(np.max(y_data))\n",
    "print(np.min(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, X, y, hidden_units=3, epochs=100, learning_rate=.1, random_state=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.hidden_units = hidden_units\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def checkParameters(self):\n",
    "        self.num_inputs = self.X.shape[1]\n",
    "        self.num_outputs = self.y.shape[1]\n",
    "        if self.X.shape[0] != self.y.shape[0]:\n",
    "            raise ValueError('X and Y have mismatched shapes')\n",
    "        if self.num_inputs < 1:\n",
    "            raise ValueError('Must have at least 1 input')\n",
    "        if self.num_outputs < 1:\n",
    "            raise ValueError('Must have at least 1 output')\n",
    "        if self.hidden_units < 1:\n",
    "            raise ValueError('Must have at least 1 hidden unit')\n",
    "        if self.epochs < 1:\n",
    "            raise ValueError('Must train for at least 1 epoch')\n",
    "        #Is it a max of 1 also??\n",
    "        if self.learning_rate <=0:\n",
    "            raise ValueError('Learning rate must be greater than 0')\n",
    "\n",
    "\n",
    "    def sigmoid(self, x, deriv=False):\n",
    "        if deriv is True:\n",
    "            return x * (1-x)\n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "    def myLogLoss(self, deriv=False):\n",
    "        #epsilon is to avoid divide by zero errors\n",
    "        epsilon = 1e-5\n",
    "    \n",
    "        if deriv is True:\n",
    "            return -(self.y/self.output) + ((1-self.y)/(1-self.output))\n",
    "        return (1/self.num_inputs) * np.sum(-((self.y * np.log(self.output+epsilon)) + (1 - self.y)  * np.log(1 - self.output + epsilon)))\n",
    "    \n",
    "    def MSE(self, deriv=False):\n",
    "        if deriv == True:\n",
    "            return -2 * (self.y - self.output)\n",
    "        return (np.square(self.y - self.output).mean())\n",
    "\n",
    "    def forward(self):\n",
    "        self.z1 = self.X@self.w1 + self.b1\n",
    "        self.a1 = np.tanh(self.z1)\n",
    "        self.z2 = self.a1@self.w2 + self.b2\n",
    "        self.output = np.tanh(self.z2)\n",
    "    \n",
    "    def tan_h_deriv(self, x):\n",
    "        return 1 - (x**2)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss = self.MSE()\n",
    "        #added the times F'() see results four. Without it resutlts1\n",
    "      #  d_output = (self.output - self.y) * (1-(self.output**2))\n",
    "        d_output = self.MSE(deriv=True) * self.tan_h_deriv(self.output)\n",
    "        d_w2 = (1/self.num_inputs) * (self.a1.T @ d_output)\n",
    "        d_b2 = (1/self.num_inputs) * (np.sum(d_output, axis = 0, keepdims=True))\n",
    "        d_z1 = (d_output@self.w2.T) * self.tan_h_deriv(self.a1)\n",
    "        d_w1 = (1/self.num_inputs) * (self.X.T@d_z1)\n",
    "        d_b1 = (1/self.num_inputs) * (np.sum(d_z1, axis=0, keepdims=True))\n",
    "\n",
    "        self.w1 -= (self.learning_rate * d_w1)\n",
    "        self.w2 -= (self.learning_rate * d_w2)\n",
    "        self.b1 -= (self.learning_rate * d_b1)\n",
    "        self.b2 -= (self.learning_rate * d_b2)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.checkParameters()\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "#         Xavier initialization to train model to converge faster\n",
    "        self.w1 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.num_inputs+self.hidden_units)),\n",
    "                                size = (self.num_inputs, self.hidden_units))\n",
    "        self.w2 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.hidden_units+self.num_outputs)),\n",
    "                                size = (self.hidden_units, self.num_outputs))\n",
    "        self.b1 = np.zeros((1,self.hidden_units))\n",
    "        self.b2 = np.zeros((1,self.num_outputs))\n",
    "        for i in range (self.epochs):\n",
    "            self.forward()\n",
    "        #    print(\"Epoch {} Loss is {}\".format(i+1, self.loss))\n",
    "            self.backward()\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.X = x\n",
    "        self.forward()\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = pd.DataFrame(index=['epochs', 'hidden units', 'train_error', 'test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = pd.DataFrame(index=['epochs', 'hidden units', 'train_error', 'test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=['epochs', 'hidden units', 'train_error', 'test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame(index=['epochs', 'hidden units', 'train_error', 'test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.DataFrame(index=['epochs', 'hidden units', 'train_error', 'test_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE(predict, y):\n",
    "    return np.power((predict - y), 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epochs = [1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model 1\n",
      "testing model 2\n",
      "testing model 3\n",
      "testing model 4\n",
      "testing model 5\n",
      "testing model 6\n",
      "testing model 7\n",
      "testing model 8\n",
      "testing model 9\n",
      "testing model 10\n",
      "testing model 11\n",
      "testing model 12\n",
      "testing model 13\n",
      "testing model 14\n",
      "testing model 15\n",
      "testing model 16\n"
     ]
    }
   ],
   "source": [
    "model = 1\n",
    "for epoch in test_epochs:\n",
    "    for hidden in range(2, 6):\n",
    "        print('testing model {}'.format(model))\n",
    "        test = MLP(X_train,y_train,hidden,random_state=0, epochs=epoch)\n",
    "        test.fit(X_train, y_train)\n",
    "        train_error = SSE(test.predict(X_train), y_train)\n",
    "        test_error = SSE(test.predict(X_test), y_test)\n",
    "        results6[model] = [epoch, hidden, train_error, test_error]\n",
    "        model += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden units</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_error</th>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.02937</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.029754</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.030341</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.026067</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.015274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_error</th>\n",
       "      <td>0.042875</td>\n",
       "      <td>0.04252</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>0.029322</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.049897</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.044841</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>0.057722</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0.038916</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.070086</td>\n",
       "      <td>0.063890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1           2            3            4             5   \\\n",
       "epochs        1000.000000  1000.00000  1000.000000  1000.000000  10000.000000   \n",
       "hidden units     2.000000     3.00000     4.000000     5.000000      2.000000   \n",
       "train_error      0.025814     0.02937     0.015715     0.018677      0.020232   \n",
       "test_error       0.042875     0.04252     0.038239     0.029322      0.038879   \n",
       "\n",
       "                        6             7             8              9   \\\n",
       "epochs        10000.000000  10000.000000  10000.000000  100000.000000   \n",
       "hidden units      3.000000      4.000000      5.000000       2.000000   \n",
       "train_error       0.029754      0.009606      0.016511       0.020245   \n",
       "test_error        0.049897      0.051454      0.044841       0.038910   \n",
       "\n",
       "                         10             11             12              13  \\\n",
       "epochs        100000.000000  100000.000000  100000.000000  1000000.000000   \n",
       "hidden units       3.000000       4.000000       5.000000        2.000000   \n",
       "train_error        0.030341       0.006701       0.018379        0.020250   \n",
       "test_error         0.057722       0.065705       0.063738        0.038916   \n",
       "\n",
       "                          14              15              16  \n",
       "epochs        1000000.000000  1000000.000000  1000000.000000  \n",
       "hidden units        3.000000        4.000000        5.000000  \n",
       "train_error         0.026067        0.006490        0.015274  \n",
       "test_error          0.086603        0.070086        0.063890  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden units</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_error</th>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.020393</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.008962</td>\n",
       "      <td>0.008278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_error</th>\n",
       "      <td>0.035976</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>0.031125</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>0.039211</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.036524</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>0.073451</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.037489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1            2            3            4   \\\n",
       "epochs        1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "hidden units     2.000000     3.000000     4.000000     5.000000   \n",
       "train_error      0.020846     0.020371     0.012607     0.020393   \n",
       "test_error       0.035976     0.033296     0.019646     0.031125   \n",
       "\n",
       "                        5             6             7             8   \\\n",
       "epochs        10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "hidden units      2.000000      3.000000      4.000000      5.000000   \n",
       "train_error       0.018232      0.012038      0.008561      0.009684   \n",
       "test_error        0.040651      0.030903      0.039211      0.027347   \n",
       "\n",
       "                         9              10             11             12  \\\n",
       "epochs        100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "hidden units       2.000000       3.000000       4.000000       5.000000   \n",
       "train_error        0.017248       0.009807       0.008554       0.005275   \n",
       "test_error         0.040230       0.036524       0.046355       0.025387   \n",
       "\n",
       "                          13              14              15              16  \n",
       "epochs        1000000.000000  1000000.000000  1000000.000000  1000000.000000  \n",
       "hidden units        2.000000        3.000000        4.000000        5.000000  \n",
       "train_error         0.017128        0.009162        0.008962        0.008278  \n",
       "test_error          0.040174        0.073451        0.048800        0.037489  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden units</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_error</th>\n",
       "      <td>0.020790</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>0.021659</td>\n",
       "      <td>0.020244</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.014162</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.022054</td>\n",
       "      <td>0.016973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_error</th>\n",
       "      <td>0.036388</td>\n",
       "      <td>0.037338</td>\n",
       "      <td>0.038756</td>\n",
       "      <td>0.047729</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.067977</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.037888</td>\n",
       "      <td>0.159024</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.157637</td>\n",
       "      <td>0.081951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1            2            3            4   \\\n",
       "epochs        1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "hidden units     2.000000     3.000000     4.000000     5.000000   \n",
       "train_error      0.020790     0.020523     0.021659     0.020244   \n",
       "test_error       0.036388     0.037338     0.038756     0.047729   \n",
       "\n",
       "                        5             6             7             8   \\\n",
       "epochs        10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "hidden units      2.000000      3.000000      4.000000      5.000000   \n",
       "train_error       0.020394      0.020078      0.014162      0.015391   \n",
       "test_error        0.037215      0.036336      0.093349      0.067977   \n",
       "\n",
       "                         9              10             11             12  \\\n",
       "epochs        100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "hidden units       2.000000       3.000000       4.000000       5.000000   \n",
       "train_error        0.021239       0.020149       0.020396       0.017172   \n",
       "test_error         0.037460       0.037888       0.159024       0.078390   \n",
       "\n",
       "                          13              14              15              16  \n",
       "epochs        1000000.000000  1000000.000000  1000000.000000  1000000.000000  \n",
       "hidden units        2.000000        3.000000        4.000000        5.000000  \n",
       "train_error         0.021239        0.019867        0.022054        0.016973  \n",
       "test_error          0.037460        0.037601        0.157637        0.081951  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_inputs, num_outputs,\n",
    "                 hidden_units=3, epochs=100, learning_rate=.1,\n",
    "                 random_state=None, loss='log',\n",
    "                 first_activation='sig', second_activation='sig'):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.hidden_units = hidden_units\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.loss_type = loss\n",
    "        self.a_func_1 = first_activation\n",
    "        self.a_func_2 = second_activation\n",
    "        \n",
    "    def checkParameters(self):\n",
    "        activations = ['sig', 'tanh', 'softmax', 'relu']\n",
    "        self.num_inputs = self.X.shape[1]\n",
    "        self.num_outputs = self.y.shape[1]\n",
    "        if self.X.shape[0] != self.y.shape[0]:\n",
    "            raise ValueError('X and Y have mismatched shapes')\n",
    "        if self.num_inputs < 1:\n",
    "            raise ValueError('Must have at least 1 input')\n",
    "        if self.num_outputs < 1:\n",
    "            raise ValueError('Must have at least 1 output')\n",
    "        if self.hidden_units < 1:\n",
    "            raise ValueError('Must have at least 1 hidden unit')\n",
    "        if self.epochs < 1:\n",
    "            raise ValueError('Must train for at least 1 epoch')\n",
    "        #Is it a max of 1 also??\n",
    "        if self.learning_rate <=0:\n",
    "            raise ValueError('Learning rate must be greater than 0')\n",
    "        if self.loss_type not in ['log', 'mse']:\n",
    "            raise ValueError('Unknown loss function {}'.format(self.loss_type))\n",
    "        if self.a_func_1 not in activations:\n",
    "            raise ValueError('Unknown activation function {}'.format(self.a_func_1))\n",
    "        if self.a_func_2 not in activations:\n",
    "            raise ValueError('Unknown activation function {}'.format(self.a_func_2))\n",
    "\n",
    "        \n",
    "    def setActivation(self, active):\n",
    "        if active == 'sig':\n",
    "            def active(x, deriv=False):\n",
    "                sig = (1 / (1 + np.exp(-x)))\n",
    "                if deriv is True:\n",
    "                    return sig * (1-sig)\n",
    "                return sig\n",
    "        \n",
    "        elif active == 'tanh':\n",
    "            def active(x, deriv=False):\n",
    "                if deriv is True:\n",
    "                    return 1 - (x**2)\n",
    "                return np.tanh(x)\n",
    "        \n",
    "        elif active == 'softmax':\n",
    "            # from https://mlfromscratch.com/neural-network-tutorial/#/\n",
    "            def active(x, deriv=False):\n",
    "                # for numerical stability, values are normalised\n",
    "                exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "                if deriv is True:\n",
    "                    return exps / np.sum(exps) * (1 - exps / np.sum(exps))\n",
    "                return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "        \n",
    "        else: # RELU\n",
    "            def active(x, deriv=False):\n",
    "                if deriv is True:\n",
    "                    return np.where(x >= 0, 1, 0)\n",
    "                return np.maximum(x, 0)\n",
    "        \n",
    "        return active\n",
    "\n",
    "    def setLossFunction(self, loss):\n",
    "        if loss == 'log':\n",
    "            def loss(deriv=False):\n",
    "                epsilon = 1e-5\n",
    "                if deriv is True:\n",
    "                    return -(self.y/self.output) + ((1-self.y)/(1-self.output))\n",
    "                return (1/self.num_inputs) * np.sum(-((self.y * np.log(self.output+epsilon)) + (1 - self.y)  * np.log(1 - self.output + epsilon)))\n",
    "        else:\n",
    "            def loss(deriv=False):\n",
    "                if deriv == True:\n",
    "                    return -2 * (self.y - self.output)\n",
    "                return (np.square(self.y - self.output).mean())\n",
    "        return loss\n",
    "        \n",
    "    def forward(self):\n",
    "        self.z1 = self.X@self.w1 + self.b1\n",
    "        self.a1 = self.a_func_1(self.z1)\n",
    "        self.z2 = self.a1@self.w2 + self.b2\n",
    "        self.output = self.a_func_2(self.z2)\n",
    "    \n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss = self.LossFunction()\n",
    "        #added the times F'() see results four. Without it resutlts1\n",
    "      #  d_output = (self.output - self.y) * (1-(self.output**2))\n",
    "        d_output = self.LossFunction(deriv=True) * self.a_func_2(self.output, deriv=True)\n",
    "        d_w2 = (1/self.num_inputs) * (self.a1.T @ d_output)\n",
    "        d_b2 = (1/self.num_inputs) * (np.sum(d_output, axis = 0, keepdims=True))\n",
    "        d_z1 = (d_output@self.w2.T) * self.a_func_1(self.a1, deriv=True)\n",
    "        d_w1 = (1/self.num_inputs) * (self.X.T@d_z1)\n",
    "        d_b1 = (1/self.num_inputs) * (np.sum(d_z1, axis=0, keepdims=True))\n",
    "\n",
    "        self.w1 -= (self.learning_rate * d_w1)\n",
    "        self.w2 -= (self.learning_rate * d_w2)\n",
    "        self.b1 -= (self.learning_rate * d_b1)\n",
    "        self.b2 -= (self.learning_rate * d_b2)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        self.checkParameters()\n",
    "        self.LossFunction = self.setLossFunction(self.loss_type)\n",
    "        self.a_func_1 = self.setActivation(self.a_func_1)\n",
    "        self.a_func_2 = self.setActivation(self.a_func_2)\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "#         Xavier initialization to train model to converge faster\n",
    "        self.w1 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.num_inputs+self.hidden_units)),\n",
    "                                size = (self.num_inputs, self.hidden_units))\n",
    "        self.w2 = np.random.normal(loc=0.0,\n",
    "                                scale=np.sqrt(2/(self.hidden_units+self.num_outputs)),\n",
    "                                size = (self.hidden_units, self.num_outputs))\n",
    "        self.b1 = np.zeros((1,self.hidden_units))\n",
    "        self.b2 = np.zeros((1,self.num_outputs))\n",
    "        for i in range (self.epochs):\n",
    "            self.forward()\n",
    "            self.backward()\n",
    "            print(\"Epoch {} Loss is {}\".format(i+1, self.loss))\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.X = x\n",
    "        self.forward()\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv('letter-recognition.data', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array(X_data.pop(X_data.columns[0]))\n",
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.astype(dtype='<U1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_data, return_counts=True)\n",
    "values = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 789,\n",
       " 'B': 766,\n",
       " 'C': 736,\n",
       " 'D': 805,\n",
       " 'E': 768,\n",
       " 'F': 775,\n",
       " 'G': 773,\n",
       " 'H': 734,\n",
       " 'I': 755,\n",
       " 'J': 747,\n",
       " 'K': 739,\n",
       " 'L': 761,\n",
       " 'M': 792,\n",
       " 'N': 783,\n",
       " 'O': 753,\n",
       " 'P': 803,\n",
       " 'Q': 783,\n",
       " 'R': 758,\n",
       " 'S': 748,\n",
       " 'T': 795,\n",
       " 'U': 813,\n",
       " 'V': 764,\n",
       " 'W': 752,\n",
       " 'X': 787,\n",
       " 'Y': 786,\n",
       " 'Z': 734}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 16) (19999,)\n"
     ]
    }
   ],
   "source": [
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array(y_data.view(np.uint32)) - 65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_data, return_counts=True)\n",
    "values = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to return numbers to letters\n",
    "#np.char.mod('%c', y_data+65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 789,\n",
       " 1: 766,\n",
       " 2: 736,\n",
       " 3: 805,\n",
       " 4: 768,\n",
       " 5: 775,\n",
       " 6: 773,\n",
       " 7: 734,\n",
       " 8: 755,\n",
       " 9: 747,\n",
       " 10: 739,\n",
       " 11: 761,\n",
       " 12: 792,\n",
       " 13: 783,\n",
       " 14: 753,\n",
       " 15: 803,\n",
       " 16: 783,\n",
       " 17: 758,\n",
       " 18: 748,\n",
       " 19: 795,\n",
       " 20: 813,\n",
       " 21: 764,\n",
       " 22: 752,\n",
       " 23: 787,\n",
       " 24: 786,\n",
       " 25: 734}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=0, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_wide = to_categorical(y_train)\n",
    "y_test_wide = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(X_train.shape[1], y_train_wide.shape[1],\n",
    "          hidden_units=26,\n",
    "          epochs=100000,\n",
    "          learning_rate=.2, loss='log', \n",
    "           first_activation = 'sig', second_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss is 4202.957703703221\n",
      "Epoch 2 Loss is 4189.523785720581\n",
      "Epoch 3 Loss is 4177.244475875908\n",
      "Epoch 4 Loss is 4165.962084674516\n",
      "Epoch 5 Loss is 4155.546512711668\n",
      "Epoch 6 Loss is 4145.890372920188\n",
      "Epoch 7 Loss is 4136.904861018071\n",
      "Epoch 8 Loss is 4128.51633748303\n",
      "Epoch 9 Loss is 4120.663560561732\n",
      "Epoch 10 Loss is 4113.295383704429\n",
      "Epoch 11 Loss is 4106.368805293907\n",
      "Epoch 12 Loss is 4099.84740671534\n",
      "Epoch 13 Loss is 4093.7000682072776\n",
      "Epoch 14 Loss is 4087.899888139447\n",
      "Epoch 15 Loss is 4082.423364078522\n",
      "Epoch 16 Loss is 4077.2496690084677\n",
      "Epoch 17 Loss is 4072.3600821914647\n",
      "Epoch 18 Loss is 4067.7375540416238\n",
      "Epoch 19 Loss is 4063.3663564034273\n",
      "Epoch 20 Loss is 4059.2318453626362\n",
      "Epoch 21 Loss is 4055.320257469828\n",
      "Epoch 22 Loss is 4051.6185808030095\n",
      "Epoch 23 Loss is 4048.1144498243984\n",
      "Epoch 24 Loss is 4044.79608902051\n",
      "Epoch 25 Loss is 4041.65227155283\n",
      "Epoch 26 Loss is 4038.672287922152\n",
      "Epoch 27 Loss is 4035.8459405311755\n",
      "Epoch 28 Loss is 4033.1635333964864\n",
      "Epoch 29 Loss is 4030.6158662062358\n",
      "Epoch 30 Loss is 4028.194231288278\n",
      "Epoch 31 Loss is 4025.8904041651717\n",
      "Epoch 32 Loss is 4023.6966389611075\n",
      "Epoch 33 Loss is 4021.605650636985\n",
      "Epoch 34 Loss is 4019.6106075489547\n",
      "Epoch 35 Loss is 4017.705114648582\n",
      "Epoch 36 Loss is 4015.883195190811\n",
      "Epoch 37 Loss is 4014.139273148212\n",
      "Epoch 38 Loss is 4012.468155108252\n",
      "Epoch 39 Loss is 4010.865010003264\n",
      "Epoch 40 Loss is 4009.3253433435625\n",
      "Epoch 41 Loss is 4007.844981365672\n",
      "Epoch 42 Loss is 4006.4200500324205\n",
      "Epoch 43 Loss is 4005.0469558932537\n",
      "Epoch 44 Loss is 4003.722364316073\n",
      "Epoch 45 Loss is 4002.443183810857\n",
      "Epoch 46 Loss is 4001.206548543658\n",
      "Epoch 47 Loss is 4000.009799994112\n",
      "Epoch 48 Loss is 3998.850472839268\n",
      "Epoch 49 Loss is 3997.726280641845\n",
      "Epoch 50 Loss is 3996.635102340537\n",
      "Epoch 51 Loss is 3995.5749683173062\n",
      "Epoch 52 Loss is 3994.5440495373123\n",
      "Epoch 53 Loss is 3993.54064607646\n",
      "Epoch 54 Loss is 3992.563178322839\n",
      "Epoch 55 Loss is 3991.610177434346\n",
      "Epoch 56 Loss is 3990.680274849948\n",
      "Epoch 57 Loss is 3989.7721954448866\n",
      "Epoch 58 Loss is 3988.8847516861656\n",
      "Epoch 59 Loss is 3988.016835888117\n",
      "Epoch 60 Loss is 3987.1674137248983\n",
      "Epoch 61 Loss is 3986.335520095608\n",
      "Epoch 62 Loss is 3985.5202530412225\n",
      "Epoch 63 Loss is 3984.720767391642\n",
      "Epoch 64 Loss is 3983.9362712854836\n",
      "Epoch 65 Loss is 3983.1660233854377\n",
      "Epoch 66 Loss is 3982.409328195463\n",
      "Epoch 67 Loss is 3981.66553274728\n",
      "Epoch 68 Loss is 3980.9340236738753\n",
      "Epoch 69 Loss is 3980.214225095643\n",
      "Epoch 70 Loss is 3979.505594877346\n",
      "Epoch 71 Loss is 3978.80762267226\n",
      "Epoch 72 Loss is 3978.1198277693975\n",
      "Epoch 73 Loss is 3977.4417564907594\n",
      "Epoch 74 Loss is 3976.7729810088263\n",
      "Epoch 75 Loss is 3976.11309785136\n",
      "Epoch 76 Loss is 3975.461725480862\n",
      "Epoch 77 Loss is 3974.8185027956506\n",
      "Epoch 78 Loss is 3974.183088165609\n",
      "Epoch 79 Loss is 3973.5551583118136\n",
      "Epoch 80 Loss is 3972.9344071731466\n",
      "Epoch 81 Loss is 3972.3205449734505\n",
      "Epoch 82 Loss is 3971.713297121245\n",
      "Epoch 83 Loss is 3971.112402622424\n",
      "Epoch 84 Loss is 3970.517613671651\n",
      "Epoch 85 Loss is 3969.9286952344096\n",
      "Epoch 86 Loss is 3969.345423830077\n",
      "Epoch 87 Loss is 3968.767587340916\n",
      "Epoch 88 Loss is 3968.1949843723164\n",
      "Epoch 89 Loss is 3967.627422910085\n",
      "Epoch 90 Loss is 3967.0647207536144\n",
      "Epoch 91 Loss is 3966.50670436695\n",
      "Epoch 92 Loss is 3965.9532080385434\n",
      "Epoch 93 Loss is 3965.404073819037\n",
      "Epoch 94 Loss is 3964.859151524945\n",
      "Epoch 95 Loss is 3964.318298085432\n",
      "Epoch 96 Loss is 3963.781377433337\n",
      "Epoch 97 Loss is 3963.248259340061\n",
      "Epoch 98 Loss is 3962.7188195198605\n",
      "Epoch 99 Loss is 3962.192939696665\n",
      "Epoch 100 Loss is 3961.670507620059\n",
      "Epoch 101 Loss is 3961.1514157903584\n",
      "Epoch 102 Loss is 3960.6355621302782\n",
      "Epoch 103 Loss is 3960.122849072328\n",
      "Epoch 104 Loss is 3959.613183572421\n",
      "Epoch 105 Loss is 3959.1064768681317\n",
      "Epoch 106 Loss is 3958.602644481892\n",
      "Epoch 107 Loss is 3958.101605694889\n",
      "Epoch 108 Loss is 3957.603283717614\n",
      "Epoch 109 Loss is 3957.107605861661\n",
      "Epoch 110 Loss is 3956.614502416566\n",
      "Epoch 111 Loss is 3956.1239069646654\n",
      "Epoch 112 Loss is 3955.635756688811\n",
      "Epoch 113 Loss is 3955.1499913715984\n",
      "Epoch 114 Loss is 3954.6665538068883\n",
      "Epoch 115 Loss is 3954.185389426845\n",
      "Epoch 116 Loss is 3953.706446339949\n",
      "Epoch 117 Loss is 3953.2296754610647\n",
      "Epoch 118 Loss is 3952.7550301275837\n",
      "Epoch 119 Loss is 3952.2824661166146\n",
      "Epoch 120 Loss is 3951.8119415036676\n",
      "Epoch 121 Loss is 3951.3434164172177\n",
      "Epoch 122 Loss is 3950.8768531200953\n",
      "Epoch 123 Loss is 3950.4122155526393\n",
      "Epoch 124 Loss is 3949.9494699957304\n",
      "Epoch 125 Loss is 3949.4885843746115\n",
      "Epoch 126 Loss is 3949.0295283207406\n",
      "Epoch 127 Loss is 3948.5722731753854\n",
      "Epoch 128 Loss is 3948.1167917005178\n",
      "Epoch 129 Loss is 3947.6630581415966\n",
      "Epoch 130 Loss is 3947.211048447147\n",
      "Epoch 131 Loss is 3946.760740159013\n",
      "Epoch 132 Loss is 3946.3121119988823\n",
      "Epoch 133 Loss is 3945.865143667971\n",
      "Epoch 134 Loss is 3945.4198159642683\n",
      "Epoch 135 Loss is 3944.976110883624\n",
      "Epoch 136 Loss is 3944.534012049255\n",
      "Epoch 137 Loss is 3944.093503871633\n",
      "Epoch 138 Loss is 3943.654571092576\n",
      "Epoch 139 Loss is 3943.2171997961295\n",
      "Epoch 140 Loss is 3942.7813770990756\n",
      "Epoch 141 Loss is 3942.3470909305615\n",
      "Epoch 142 Loss is 3941.914330074708\n",
      "Epoch 143 Loss is 3941.483083982652\n",
      "Epoch 144 Loss is 3941.053342993327\n",
      "Epoch 145 Loss is 3940.6250982207066\n",
      "Epoch 146 Loss is 3940.198341256683\n",
      "Epoch 147 Loss is 3939.773064337779\n",
      "Epoch 148 Loss is 3939.349260063099\n",
      "Epoch 149 Loss is 3938.9269216126204\n",
      "Epoch 150 Loss is 3938.5060427211224\n",
      "Epoch 151 Loss is 3938.086617511872\n",
      "Epoch 152 Loss is 3937.6686407155817\n",
      "Epoch 153 Loss is 3937.2521072912855\n",
      "Epoch 154 Loss is 3936.837012658813\n",
      "Epoch 155 Loss is 3936.423352230292\n",
      "Epoch 156 Loss is 3936.0111216974674\n",
      "Epoch 157 Loss is 3935.60031740211\n",
      "Epoch 158 Loss is 3935.1909361562684\n",
      "Epoch 159 Loss is 3934.782974688584\n",
      "Epoch 160 Loss is 3934.376430198515\n",
      "Epoch 161 Loss is 3933.9713001262257\n",
      "Epoch 162 Loss is 3933.56758217874\n",
      "Epoch 163 Loss is 3933.1652742568554\n",
      "Epoch 164 Loss is 3932.764374377398\n",
      "Epoch 165 Loss is 3932.3648807075056\n",
      "Epoch 166 Loss is 3931.9667913570725\n",
      "Epoch 167 Loss is 3931.5701047484145\n",
      "Epoch 168 Loss is 3931.174819383209\n",
      "Epoch 169 Loss is 3930.780933850749\n",
      "Epoch 170 Loss is 3930.388446892119\n",
      "Epoch 171 Loss is 3929.997357270443\n",
      "Epoch 172 Loss is 3929.6076638467102\n",
      "Epoch 173 Loss is 3929.219365484857\n",
      "Epoch 174 Loss is 3928.832461094201\n",
      "Epoch 175 Loss is 3928.446949592709\n",
      "Epoch 176 Loss is 3928.0628300536496\n",
      "Epoch 177 Loss is 3927.6801016458226\n",
      "Epoch 178 Loss is 3927.298763556732\n",
      "Epoch 179 Loss is 3926.9188148868107\n",
      "Epoch 180 Loss is 3926.540254537059\n",
      "Epoch 181 Loss is 3926.163081654426\n",
      "Epoch 182 Loss is 3925.787295495213\n",
      "Epoch 183 Loss is 3925.412895088985\n",
      "Epoch 184 Loss is 3925.0398796599543\n",
      "Epoch 185 Loss is 3924.6682483797313\n",
      "Epoch 186 Loss is 3924.298000410251\n",
      "Epoch 187 Loss is 3923.9291348101506\n",
      "Epoch 188 Loss is 3923.561650728781\n",
      "Epoch 189 Loss is 3923.1955471335536\n",
      "Epoch 190 Loss is 3922.8308230547395\n",
      "Epoch 191 Loss is 3922.4674775882936\n",
      "Epoch 192 Loss is 3922.1055097134895\n",
      "Epoch 193 Loss is 3921.7449185206888\n",
      "Epoch 194 Loss is 3921.385703134545\n",
      "Epoch 195 Loss is 3921.0278623226377\n",
      "Epoch 196 Loss is 3920.6713948959205\n",
      "Epoch 197 Loss is 3920.3162998441944\n",
      "Epoch 198 Loss is 3919.9625759908868\n",
      "Epoch 199 Loss is 3919.6102219491668\n",
      "Epoch 200 Loss is 3919.2592364303837\n",
      "Epoch 201 Loss is 3918.909618113757\n",
      "Epoch 202 Loss is 3918.561365515302\n",
      "Epoch 203 Loss is 3918.2144773285063\n",
      "Epoch 204 Loss is 3917.868952278578\n",
      "Epoch 205 Loss is 3917.52478897007\n",
      "Epoch 206 Loss is 3917.1819859551065\n",
      "Epoch 207 Loss is 3916.84054190393\n",
      "Epoch 208 Loss is 3916.5004554427583\n",
      "Epoch 209 Loss is 3916.161725270632\n",
      "Epoch 210 Loss is 3915.8243501086586\n",
      "Epoch 211 Loss is 3915.4883283456716\n",
      "Epoch 212 Loss is 3915.1536582586095\n",
      "Epoch 213 Loss is 3914.820337740101\n",
      "Epoch 214 Loss is 3914.488364905719\n",
      "Epoch 215 Loss is 3914.157738048486\n",
      "Epoch 216 Loss is 3913.828455467154\n",
      "Epoch 217 Loss is 3913.5005154892374\n",
      "Epoch 218 Loss is 3913.1739163852562\n",
      "Epoch 219 Loss is 3912.8486560791207\n",
      "Epoch 220 Loss is 3912.5247326368285\n",
      "Epoch 221 Loss is 3912.202144044827\n",
      "Epoch 222 Loss is 3911.8808882050994\n",
      "Epoch 223 Loss is 3911.560963019549\n",
      "Epoch 224 Loss is 3911.2423663121754\n",
      "Epoch 225 Loss is 3910.9250959133956\n",
      "Epoch 226 Loss is 3910.609149647591\n",
      "Epoch 227 Loss is 3910.2945252202576\n",
      "Epoch 228 Loss is 3909.98122044781\n",
      "Epoch 229 Loss is 3909.6692330716405\n",
      "Epoch 230 Loss is 3909.3585608513285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231 Loss is 3909.049201380781\n",
      "Epoch 232 Loss is 3908.7411522731754\n",
      "Epoch 233 Loss is 3908.434411061101\n",
      "Epoch 234 Loss is 3908.128975081377\n",
      "Epoch 235 Loss is 3907.824841938806\n",
      "Epoch 236 Loss is 3907.5220091430974\n",
      "Epoch 237 Loss is 3907.2204741044034\n",
      "Epoch 238 Loss is 3906.9202343421866\n",
      "Epoch 239 Loss is 3906.621287293382\n",
      "Epoch 240 Loss is 3906.3236303286412\n",
      "Epoch 241 Loss is 3906.027260644524\n",
      "Epoch 242 Loss is 3905.7321755720286\n",
      "Epoch 243 Loss is 3905.438372310626\n",
      "Epoch 244 Loss is 3905.145847886729\n",
      "Epoch 245 Loss is 3904.854599330042\n",
      "Epoch 246 Loss is 3904.564623735474\n",
      "Epoch 247 Loss is 3904.2759179681516\n",
      "Epoch 248 Loss is 3903.9884790703672\n",
      "Epoch 249 Loss is 3903.702304037433\n",
      "Epoch 250 Loss is 3903.41738985133\n",
      "Epoch 251 Loss is 3903.1337334329146\n",
      "Epoch 252 Loss is 3902.8513317707334\n",
      "Epoch 253 Loss is 3902.570181843662\n",
      "Epoch 254 Loss is 3902.2902806785173\n",
      "Epoch 255 Loss is 3902.0116250991123\n",
      "Epoch 256 Loss is 3901.734211877681\n",
      "Epoch 257 Loss is 3901.4580378223905\n",
      "Epoch 258 Loss is 3901.183099583126\n",
      "Epoch 259 Loss is 3900.909393731723\n",
      "Epoch 260 Loss is 3900.6369170777543\n",
      "Epoch 261 Loss is 3900.3656662706417\n",
      "Epoch 262 Loss is 3900.0956378552914\n",
      "Epoch 263 Loss is 3899.8268283429616\n",
      "Epoch 264 Loss is 3899.5592342767436\n",
      "Epoch 265 Loss is 3899.292852027533\n",
      "Epoch 266 Loss is 3899.027677996326\n",
      "Epoch 267 Loss is 3898.7637085049078\n",
      "Epoch 268 Loss is 3898.5009399365963\n",
      "Epoch 269 Loss is 3898.239368576763\n",
      "Epoch 270 Loss is 3897.9789908202306\n",
      "Epoch 271 Loss is 3897.7198030909944\n",
      "Epoch 272 Loss is 3897.461801784452\n",
      "Epoch 273 Loss is 3897.204983131133\n",
      "Epoch 274 Loss is 3896.9493433062494\n",
      "Epoch 275 Loss is 3896.694878404347\n",
      "Epoch 276 Loss is 3896.441584528295\n",
      "Epoch 277 Loss is 3896.189457752763\n",
      "Epoch 278 Loss is 3895.938494098437\n",
      "Epoch 279 Loss is 3895.6886895818393\n",
      "Epoch 280 Loss is 3895.4400400947816\n",
      "Epoch 281 Loss is 3895.192541617977\n",
      "Epoch 282 Loss is 3894.9461901945756\n",
      "Epoch 283 Loss is 3894.7009816831023\n",
      "Epoch 284 Loss is 3894.4569119215116\n",
      "Epoch 285 Loss is 3894.213976818788\n",
      "Epoch 286 Loss is 3893.972172328097\n",
      "Epoch 287 Loss is 3893.73149424926\n",
      "Epoch 288 Loss is 3893.4919382205258\n",
      "Epoch 289 Loss is 3893.253500019478\n",
      "Epoch 290 Loss is 3893.0161755638237\n",
      "Epoch 291 Loss is 3892.77996070019\n",
      "Epoch 292 Loss is 3892.5448513805454\n",
      "Epoch 293 Loss is 3892.3108433039392\n",
      "Epoch 294 Loss is 3892.0779321652376\n",
      "Epoch 295 Loss is 3891.8461135670636\n",
      "Epoch 296 Loss is 3891.6153830748754\n",
      "Epoch 297 Loss is 3891.3857362888866\n",
      "Epoch 298 Loss is 3891.1571688475497\n",
      "Epoch 299 Loss is 3890.9296764586834\n",
      "Epoch 300 Loss is 3890.703254644817\n",
      "Epoch 301 Loss is 3890.477898923583\n",
      "Epoch 302 Loss is 3890.253604929041\n",
      "Epoch 303 Loss is 3890.030368209178\n",
      "Epoch 304 Loss is 3889.808184099457\n",
      "Epoch 305 Loss is 3889.5870480479316\n",
      "Epoch 306 Loss is 3889.3669553116965\n",
      "Epoch 307 Loss is 3889.1479010870585\n",
      "Epoch 308 Loss is 3888.929880681434\n",
      "Epoch 309 Loss is 3888.7128895192786\n",
      "Epoch 310 Loss is 3888.4969229940884\n",
      "Epoch 311 Loss is 3888.2819764040564\n",
      "Epoch 312 Loss is 3888.068045049459\n",
      "Epoch 313 Loss is 3887.8551241748096\n",
      "Epoch 314 Loss is 3887.643209045526\n",
      "Epoch 315 Loss is 3887.4322949201223\n",
      "Epoch 316 Loss is 3887.222377089186\n",
      "Epoch 317 Loss is 3887.013450735373\n",
      "Epoch 318 Loss is 3886.8055110991286\n",
      "Epoch 319 Loss is 3886.5985534334554\n",
      "Epoch 320 Loss is 3886.3925728957297\n",
      "Epoch 321 Loss is 3886.1875646965127\n",
      "Epoch 322 Loss is 3885.9835242124327\n",
      "Epoch 323 Loss is 3885.7804466498924\n",
      "Epoch 324 Loss is 3885.5783271412865\n",
      "Epoch 325 Loss is 3885.3771608628385\n",
      "Epoch 326 Loss is 3885.1769429705914\n",
      "Epoch 327 Loss is 3884.977668527415\n",
      "Epoch 328 Loss is 3884.779332700014\n",
      "Epoch 329 Loss is 3884.5819306383764\n",
      "Epoch 330 Loss is 3884.385457499426\n",
      "Epoch 331 Loss is 3884.1899083453736\n",
      "Epoch 332 Loss is 3883.9952782009877\n",
      "Epoch 333 Loss is 3883.8015621690124\n",
      "Epoch 334 Loss is 3883.608755212853\n",
      "Epoch 335 Loss is 3883.41685235311\n",
      "Epoch 336 Loss is 3883.2258486793644\n",
      "Epoch 337 Loss is 3883.0357391309103\n",
      "Epoch 338 Loss is 3882.8465188115415\n",
      "Epoch 339 Loss is 3882.658182880206\n",
      "Epoch 340 Loss is 3882.4707263752184\n",
      "Epoch 341 Loss is 3882.2841443236684\n",
      "Epoch 342 Loss is 3882.098431698076\n",
      "Epoch 343 Loss is 3881.9135835375732\n",
      "Epoch 344 Loss is 3881.7295949058575\n",
      "Epoch 345 Loss is 3881.546461001838\n",
      "Epoch 346 Loss is 3881.3641768642847\n",
      "Epoch 347 Loss is 3881.1827374612067\n",
      "Epoch 348 Loss is 3881.002137776274\n",
      "Epoch 349 Loss is 3880.822372808824\n",
      "Epoch 350 Loss is 3880.643437698397\n",
      "Epoch 351 Loss is 3880.465327442956\n",
      "Epoch 352 Loss is 3880.2880370945754\n",
      "Epoch 353 Loss is 3880.1115617800087\n",
      "Epoch 354 Loss is 3879.9358966076024\n",
      "Epoch 355 Loss is 3879.7610364623506\n",
      "Epoch 356 Loss is 3879.586976363255\n",
      "Epoch 357 Loss is 3879.4137112427934\n",
      "Epoch 358 Loss is 3879.241236115304\n",
      "Epoch 359 Loss is 3879.0695460388574\n",
      "Epoch 360 Loss is 3878.898636254176\n",
      "Epoch 361 Loss is 3878.7285018369976\n",
      "Epoch 362 Loss is 3878.5591378611844\n",
      "Epoch 363 Loss is 3878.390539355093\n",
      "Epoch 364 Loss is 3878.222701331115\n",
      "Epoch 365 Loss is 3878.0556188444493\n",
      "Epoch 366 Loss is 3877.889287014805\n",
      "Epoch 367 Loss is 3877.723700856251\n",
      "Epoch 368 Loss is 3877.558855413097\n",
      "Epoch 369 Loss is 3877.394745783183\n",
      "Epoch 370 Loss is 3877.231367083515\n",
      "Epoch 371 Loss is 3877.068714416661\n",
      "Epoch 372 Loss is 3876.906782851011\n",
      "Epoch 373 Loss is 3876.7455674654307\n",
      "Epoch 374 Loss is 3876.5850632682636\n",
      "Epoch 375 Loss is 3876.4252654621996\n",
      "Epoch 376 Loss is 3876.2661692074676\n",
      "Epoch 377 Loss is 3876.1077696737443\n",
      "Epoch 378 Loss is 3875.9500620298\n",
      "Epoch 379 Loss is 3875.793041483552\n",
      "Epoch 380 Loss is 3875.636703210706\n",
      "Epoch 381 Loss is 3875.4810423052027\n",
      "Epoch 382 Loss is 3875.3260539425337\n",
      "Epoch 383 Loss is 3875.171733210012\n",
      "Epoch 384 Loss is 3875.018075239723\n",
      "Epoch 385 Loss is 3874.865075199981\n",
      "Epoch 386 Loss is 3874.712728268945\n",
      "Epoch 387 Loss is 3874.5610296368804\n",
      "Epoch 388 Loss is 3874.409974547393\n",
      "Epoch 389 Loss is 3874.259558228399\n",
      "Epoch 390 Loss is 3874.1097758434253\n",
      "Epoch 391 Loss is 3873.960622528548\n",
      "Epoch 392 Loss is 3873.812093389172\n",
      "Epoch 393 Loss is 3873.6641836065983\n",
      "Epoch 394 Loss is 3873.5168885950775\n",
      "Epoch 395 Loss is 3873.3702037648886\n",
      "Epoch 396 Loss is 3873.2241243453664\n",
      "Epoch 397 Loss is 3873.0786456284904\n",
      "Epoch 398 Loss is 3872.933763000022\n",
      "Epoch 399 Loss is 3872.7894718046505\n",
      "Epoch 400 Loss is 3872.6457675130723\n",
      "Epoch 401 Loss is 3872.502645428056\n",
      "Epoch 402 Loss is 3872.3601010198886\n",
      "Epoch 403 Loss is 3872.218129783099\n",
      "Epoch 404 Loss is 3872.076727087422\n",
      "Epoch 405 Loss is 3871.9358882693837\n",
      "Epoch 406 Loss is 3871.795608654564\n",
      "Epoch 407 Loss is 3871.6558835761193\n",
      "Epoch 408 Loss is 3871.516708481015\n",
      "Epoch 409 Loss is 3871.3780787619235\n",
      "Epoch 410 Loss is 3871.2399898633216\n",
      "Epoch 411 Loss is 3871.1024372933493\n",
      "Epoch 412 Loss is 3870.9654165100224\n",
      "Epoch 413 Loss is 3870.828922990228\n",
      "Epoch 414 Loss is 3870.692952162171\n",
      "Epoch 415 Loss is 3870.5574994970966\n",
      "Epoch 416 Loss is 3870.4225604968888\n",
      "Epoch 417 Loss is 3870.2881307210773\n",
      "Epoch 418 Loss is 3870.1542058677\n",
      "Epoch 419 Loss is 3870.0207816582197\n",
      "Epoch 420 Loss is 3869.887853844797\n",
      "Epoch 421 Loss is 3869.75541803073\n",
      "Epoch 422 Loss is 3869.623469948229\n",
      "Epoch 423 Loss is 3869.492005330215\n",
      "Epoch 424 Loss is 3869.361019876539\n",
      "Epoch 425 Loss is 3869.2305093351247\n",
      "Epoch 426 Loss is 3869.100469501782\n",
      "Epoch 427 Loss is 3868.9708961199503\n",
      "Epoch 428 Loss is 3868.8417849119996\n",
      "Epoch 429 Loss is 3868.7131316496134\n",
      "Epoch 430 Loss is 3868.584932097712\n",
      "Epoch 431 Loss is 3868.4571821100776\n",
      "Epoch 432 Loss is 3868.329877512961\n",
      "Epoch 433 Loss is 3868.2030142250806\n",
      "Epoch 434 Loss is 3868.076588145069\n",
      "Epoch 435 Loss is 3867.950595108278\n",
      "Epoch 436 Loss is 3867.825030977887\n",
      "Epoch 437 Loss is 3867.699891752352\n",
      "Epoch 438 Loss is 3867.5751734891337\n",
      "Epoch 439 Loss is 3867.4508721651027\n",
      "Epoch 440 Loss is 3867.3269837201074\n",
      "Epoch 441 Loss is 3867.203504223595\n",
      "Epoch 442 Loss is 3867.0804298177054\n",
      "Epoch 443 Loss is 3866.95775665708\n",
      "Epoch 444 Loss is 3866.8354808213116\n",
      "Epoch 445 Loss is 3866.713598518432\n",
      "Epoch 446 Loss is 3866.5921058874333\n",
      "Epoch 447 Loss is 3866.4709991130662\n",
      "Epoch 448 Loss is 3866.3502744450097\n",
      "Epoch 449 Loss is 3866.229928109589\n",
      "Epoch 450 Loss is 3866.1099563081616\n",
      "Epoch 451 Loss is 3865.990355314568\n",
      "Epoch 452 Loss is 3865.871121464063\n",
      "Epoch 453 Loss is 3865.75225120319\n",
      "Epoch 454 Loss is 3865.633740841275\n",
      "Epoch 455 Loss is 3865.515586653676\n",
      "Epoch 456 Loss is 3865.3977850597767\n",
      "Epoch 457 Loss is 3865.2803324104966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458 Loss is 3865.1632250460525\n",
      "Epoch 459 Loss is 3865.0464593725974\n",
      "Epoch 460 Loss is 3864.930031821365\n",
      "Epoch 461 Loss is 3864.8139389446874\n",
      "Epoch 462 Loss is 3864.6981772609215\n",
      "Epoch 463 Loss is 3864.5827432690976\n",
      "Epoch 464 Loss is 3864.4676335363392\n",
      "Epoch 465 Loss is 3864.3528445794786\n",
      "Epoch 466 Loss is 3864.238372908283\n",
      "Epoch 467 Loss is 3864.1242151381384\n",
      "Epoch 468 Loss is 3864.0103678867877\n",
      "Epoch 469 Loss is 3863.8968277513877\n",
      "Epoch 470 Loss is 3863.7835913492313\n",
      "Epoch 471 Loss is 3863.670655406087\n",
      "Epoch 472 Loss is 3863.5580166135387\n",
      "Epoch 473 Loss is 3863.4456716638483\n",
      "Epoch 474 Loss is 3863.3336172091454\n",
      "Epoch 475 Loss is 3863.221850053131\n",
      "Epoch 476 Loss is 3863.110367079412\n",
      "Epoch 477 Loss is 3862.9991650792144\n",
      "Epoch 478 Loss is 3862.8882408711097\n",
      "Epoch 479 Loss is 3862.777591301038\n",
      "Epoch 480 Loss is 3862.6672133407783\n",
      "Epoch 481 Loss is 3862.5571039536485\n",
      "Epoch 482 Loss is 3862.447260008769\n",
      "Epoch 483 Loss is 3862.3376785029545\n",
      "Epoch 484 Loss is 3862.228356488151\n",
      "Epoch 485 Loss is 3862.119290963974\n",
      "Epoch 486 Loss is 3862.0104789317475\n",
      "Epoch 487 Loss is 3861.9019175221615\n",
      "Epoch 488 Loss is 3861.7936038977996\n",
      "Epoch 489 Loss is 3861.685535122052\n",
      "Epoch 490 Loss is 3861.5777082741315\n",
      "Epoch 491 Loss is 3861.47012051088\n",
      "Epoch 492 Loss is 3861.3627689997047\n",
      "Epoch 493 Loss is 3861.255650921852\n",
      "Epoch 494 Loss is 3861.1487634697764\n",
      "Epoch 495 Loss is 3861.042103873551\n",
      "Epoch 496 Loss is 3860.9356693267587\n",
      "Epoch 497 Loss is 3860.829457077325\n",
      "Epoch 498 Loss is 3860.7234643846123\n",
      "Epoch 499 Loss is 3860.6176886120275\n",
      "Epoch 500 Loss is 3860.512127072233\n",
      "Epoch 501 Loss is 3860.406777066193\n",
      "Epoch 502 Loss is 3860.3016359360167\n",
      "Epoch 503 Loss is 3860.1967010061508\n",
      "Epoch 504 Loss is 3860.091969665668\n",
      "Epoch 505 Loss is 3859.987439378499\n",
      "Epoch 506 Loss is 3859.8831076565943\n",
      "Epoch 507 Loss is 3859.7789719214543\n",
      "Epoch 508 Loss is 3859.675029679941\n",
      "Epoch 509 Loss is 3859.571278439467\n",
      "Epoch 510 Loss is 3859.467715729741\n",
      "Epoch 511 Loss is 3859.364339091531\n",
      "Epoch 512 Loss is 3859.2611461137026\n",
      "Epoch 513 Loss is 3859.15813438098\n",
      "Epoch 514 Loss is 3859.0553014816055\n",
      "Epoch 515 Loss is 3858.952644941226\n",
      "Epoch 516 Loss is 3858.850162299757\n",
      "Epoch 517 Loss is 3858.747851199801\n",
      "Epoch 518 Loss is 3858.645709387655\n",
      "Epoch 519 Loss is 3858.543734539772\n",
      "Epoch 520 Loss is 3858.441924299942\n",
      "Epoch 521 Loss is 3858.3402763748545\n",
      "Epoch 522 Loss is 3858.2387884554255\n",
      "Epoch 523 Loss is 3858.1374582216754\n",
      "Epoch 524 Loss is 3858.03628344113\n",
      "Epoch 525 Loss is 3857.935261843909\n",
      "Epoch 526 Loss is 3857.8343912742757\n",
      "Epoch 527 Loss is 3857.733669573336\n",
      "Epoch 528 Loss is 3857.6330945925056\n",
      "Epoch 529 Loss is 3857.5326642568934\n",
      "Epoch 530 Loss is 3857.432376433392\n",
      "Epoch 531 Loss is 3857.3322289846083\n",
      "Epoch 532 Loss is 3857.2322198509323\n",
      "Epoch 533 Loss is 3857.132347006523\n",
      "Epoch 534 Loss is 3857.0326084570065\n",
      "Epoch 535 Loss is 3856.933002223764\n",
      "Epoch 536 Loss is 3856.8335263799886\n",
      "Epoch 537 Loss is 3856.734178945958\n",
      "Epoch 538 Loss is 3856.6349579844614\n",
      "Epoch 539 Loss is 3856.5358615840946\n",
      "Epoch 540 Loss is 3856.4368878070495\n",
      "Epoch 541 Loss is 3856.3380347605125\n",
      "Epoch 542 Loss is 3856.2393006086336\n",
      "Epoch 543 Loss is 3856.140683524124\n",
      "Epoch 544 Loss is 3856.042181658508\n",
      "Epoch 545 Loss is 3855.94379321774\n",
      "Epoch 546 Loss is 3855.845516354433\n",
      "Epoch 547 Loss is 3855.747349207491\n",
      "Epoch 548 Loss is 3855.6492899622126\n",
      "Epoch 549 Loss is 3855.551336812529\n",
      "Epoch 550 Loss is 3855.453488012293\n",
      "Epoch 551 Loss is 3855.35574192053\n",
      "Epoch 552 Loss is 3855.258096816291\n",
      "Epoch 553 Loss is 3855.1605510421778\n",
      "Epoch 554 Loss is 3855.063102916305\n",
      "Epoch 555 Loss is 3854.965750833858\n",
      "Epoch 556 Loss is 3854.8684931399107\n",
      "Epoch 557 Loss is 3854.7713281330475\n",
      "Epoch 558 Loss is 3854.6742541543417\n",
      "Epoch 559 Loss is 3854.5772695210067\n",
      "Epoch 560 Loss is 3854.4803725495613\n",
      "Epoch 561 Loss is 3854.383561552884\n",
      "Epoch 562 Loss is 3854.286834881626\n",
      "Epoch 563 Loss is 3854.190190874433\n",
      "Epoch 564 Loss is 3854.0936279370744\n",
      "Epoch 565 Loss is 3853.9971444454263\n",
      "Epoch 566 Loss is 3853.900738795505\n",
      "Epoch 567 Loss is 3853.8044094178604\n",
      "Epoch 568 Loss is 3853.7081548286305\n",
      "Epoch 569 Loss is 3853.611973519151\n",
      "Epoch 570 Loss is 3853.515863984218\n",
      "Epoch 571 Loss is 3853.4198248261923\n",
      "Epoch 572 Loss is 3853.3238546152193\n",
      "Epoch 573 Loss is 3853.2279518910627\n",
      "Epoch 574 Loss is 3853.1321151594025\n",
      "Epoch 575 Loss is 3853.036343007284\n",
      "Epoch 576 Loss is 3852.9406340673067\n",
      "Epoch 577 Loss is 3852.8449869398273\n",
      "Epoch 578 Loss is 3852.7494002600006\n",
      "Epoch 579 Loss is 3852.6538726509625\n",
      "Epoch 580 Loss is 3852.558402625363\n",
      "Epoch 581 Loss is 3852.4629887830765\n",
      "Epoch 582 Loss is 3852.367629806568\n",
      "Epoch 583 Loss is 3852.2723243086693\n",
      "Epoch 584 Loss is 3852.1770709659722\n",
      "Epoch 585 Loss is 3852.0818684352494\n",
      "Epoch 586 Loss is 3851.9867153391533\n",
      "Epoch 587 Loss is 3851.891610328651\n",
      "Epoch 588 Loss is 3851.796552116651\n",
      "Epoch 589 Loss is 3851.701539412418\n",
      "Epoch 590 Loss is 3851.6065709364716\n",
      "Epoch 591 Loss is 3851.511645392505\n",
      "Epoch 592 Loss is 3851.4167614813505\n",
      "Epoch 593 Loss is 3851.321917955705\n",
      "Epoch 594 Loss is 3851.2271135488622\n",
      "Epoch 595 Loss is 3851.132347059443\n",
      "Epoch 596 Loss is 3851.0376173026893\n",
      "Epoch 597 Loss is 3850.9429230369915\n",
      "Epoch 598 Loss is 3850.84826305727\n",
      "Epoch 599 Loss is 3850.7536360941153\n",
      "Epoch 600 Loss is 3850.6590408743305\n",
      "Epoch 601 Loss is 3850.564476229237\n",
      "Epoch 602 Loss is 3850.4699409559885\n",
      "Epoch 603 Loss is 3850.37543386356\n",
      "Epoch 604 Loss is 3850.280953771856\n",
      "Epoch 605 Loss is 3850.1864994914195\n",
      "Epoch 606 Loss is 3850.0920698322434\n",
      "Epoch 607 Loss is 3849.9976635874646\n",
      "Epoch 608 Loss is 3849.9032795361895\n",
      "Epoch 609 Loss is 3849.8089165166125\n",
      "Epoch 610 Loss is 3849.714573320539\n",
      "Epoch 611 Loss is 3849.620248843091\n",
      "Epoch 612 Loss is 3849.5259420459106\n",
      "Epoch 613 Loss is 3849.431651799397\n",
      "Epoch 614 Loss is 3849.337377035595\n",
      "Epoch 615 Loss is 3849.243116622086\n",
      "Epoch 616 Loss is 3849.1488694253876\n",
      "Epoch 617 Loss is 3849.0546343407145\n",
      "Epoch 618 Loss is 3848.9604102505973\n",
      "Epoch 619 Loss is 3848.8661960431186\n",
      "Epoch 620 Loss is 3848.7719906204807\n",
      "Epoch 621 Loss is 3848.677792913547\n",
      "Epoch 622 Loss is 3848.583601864375\n",
      "Epoch 623 Loss is 3848.4894164043053\n",
      "Epoch 624 Loss is 3848.3952354513144\n",
      "Epoch 625 Loss is 3848.301057926007\n",
      "Epoch 626 Loss is 3848.206882691381\n",
      "Epoch 627 Loss is 3848.112708718423\n",
      "Epoch 628 Loss is 3848.018534980334\n",
      "Epoch 629 Loss is 3847.9243604797725\n",
      "Epoch 630 Loss is 3847.8301841802668\n",
      "Epoch 631 Loss is 3847.7360050757165\n",
      "Epoch 632 Loss is 3847.6418221822405\n",
      "Epoch 633 Loss is 3847.5476345355646\n",
      "Epoch 634 Loss is 3847.4534411481986\n",
      "Epoch 635 Loss is 3847.3592410361684\n",
      "Epoch 636 Loss is 3847.2650331363875\n",
      "Epoch 637 Loss is 3847.170816446737\n",
      "Epoch 638 Loss is 3847.0765898978257\n",
      "Epoch 639 Loss is 3846.9823524509748\n",
      "Epoch 640 Loss is 3846.8881030866714\n",
      "Epoch 641 Loss is 3846.793840798273\n",
      "Epoch 642 Loss is 3846.6995646549626\n",
      "Epoch 643 Loss is 3846.605273683523\n",
      "Epoch 644 Loss is 3846.51096686605\n",
      "Epoch 645 Loss is 3846.416643241907\n",
      "Epoch 646 Loss is 3846.322301836156\n",
      "Epoch 647 Loss is 3846.2279417416876\n",
      "Epoch 648 Loss is 3846.133562062553\n",
      "Epoch 649 Loss is 3846.0391618028248\n",
      "Epoch 650 Loss is 3845.9447399919677\n",
      "Epoch 651 Loss is 3845.850295662285\n",
      "Epoch 652 Loss is 3845.7558278197425\n",
      "Epoch 653 Loss is 3845.661335419083\n",
      "Epoch 654 Loss is 3845.566817460894\n",
      "Epoch 655 Loss is 3845.472272968382\n",
      "Epoch 656 Loss is 3845.377700970952\n",
      "Epoch 657 Loss is 3845.2831005063276\n",
      "Epoch 658 Loss is 3845.188470560667\n",
      "Epoch 659 Loss is 3845.0938101141805\n",
      "Epoch 660 Loss is 3844.9991181477762\n",
      "Epoch 661 Loss is 3844.90439371343\n",
      "Epoch 662 Loss is 3844.80963578417\n",
      "Epoch 663 Loss is 3844.714843384285\n",
      "Epoch 664 Loss is 3844.620015483365\n",
      "Epoch 665 Loss is 3844.5251510638154\n",
      "Epoch 666 Loss is 3844.4302491730496\n",
      "Epoch 667 Loss is 3844.335308817573\n",
      "Epoch 668 Loss is 3844.240328970391\n",
      "Epoch 669 Loss is 3844.1453086399606\n",
      "Epoch 670 Loss is 3844.0502468627733\n",
      "Epoch 671 Loss is 3843.955142621643\n",
      "Epoch 672 Loss is 3843.8599948904903\n",
      "Epoch 673 Loss is 3843.7648026608954\n",
      "Epoch 674 Loss is 3843.669564908599\n",
      "Epoch 675 Loss is 3843.574280647168\n",
      "Epoch 676 Loss is 3843.478948841213\n",
      "Epoch 677 Loss is 3843.3835684652295\n",
      "Epoch 678 Loss is 3843.288138476618\n",
      "Epoch 679 Loss is 3843.1926578642033\n",
      "Epoch 680 Loss is 3843.097125596904\n",
      "Epoch 681 Loss is 3843.001540580491\n",
      "Epoch 682 Loss is 3842.905901747823\n",
      "Epoch 683 Loss is 3842.810208014414\n",
      "Epoch 684 Loss is 3842.714458311098\n",
      "Epoch 685 Loss is 3842.618651521046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686 Loss is 3842.5227865148054\n",
      "Epoch 687 Loss is 3842.4268621863184\n",
      "Epoch 688 Loss is 3842.330877393973\n",
      "Epoch 689 Loss is 3842.234830992088\n",
      "Epoch 690 Loss is 3842.1387218511527\n",
      "Epoch 691 Loss is 3842.042548792017\n",
      "Epoch 692 Loss is 3841.946310614245\n",
      "Epoch 693 Loss is 3841.850006194119\n",
      "Epoch 694 Loss is 3841.7536344244077\n",
      "Epoch 695 Loss is 3841.657194176415\n",
      "Epoch 696 Loss is 3841.560684284896\n",
      "Epoch 697 Loss is 3841.4641036151734\n",
      "Epoch 698 Loss is 3841.3674509658003\n",
      "Epoch 699 Loss is 3841.2707251202933\n",
      "Epoch 700 Loss is 3841.1739248753784\n",
      "Epoch 701 Loss is 3841.077049008044\n",
      "Epoch 702 Loss is 3840.980096358779\n",
      "Epoch 703 Loss is 3840.8830656978776\n",
      "Epoch 704 Loss is 3840.785955787035\n",
      "Epoch 705 Loss is 3840.6887654091165\n",
      "Epoch 706 Loss is 3840.5914932887285\n",
      "Epoch 707 Loss is 3840.494138142757\n",
      "Epoch 708 Loss is 3840.3966987119784\n",
      "Epoch 709 Loss is 3840.2991736756812\n",
      "Epoch 710 Loss is 3840.2015617339052\n",
      "Epoch 711 Loss is 3840.1038615837547\n",
      "Epoch 712 Loss is 3840.006071878688\n",
      "Epoch 713 Loss is 3839.9081912542347\n",
      "Epoch 714 Loss is 3839.810218382127\n",
      "Epoch 715 Loss is 3839.712151941743\n",
      "Epoch 716 Loss is 3839.613990558524\n",
      "Epoch 717 Loss is 3839.5157328672135\n",
      "Epoch 718 Loss is 3839.4173775947133\n",
      "Epoch 719 Loss is 3839.3189233656585\n",
      "Epoch 720 Loss is 3839.2203688379673\n",
      "Epoch 721 Loss is 3839.121712668214\n",
      "Epoch 722 Loss is 3839.0229535173225\n",
      "Epoch 723 Loss is 3838.924090014343\n",
      "Epoch 724 Loss is 3838.8251207443172\n",
      "Epoch 725 Loss is 3838.726044300266\n",
      "Epoch 726 Loss is 3838.6268593114182\n",
      "Epoch 727 Loss is 3838.5275643611676\n",
      "Epoch 728 Loss is 3838.428158059735\n",
      "Epoch 729 Loss is 3838.3286390086587\n",
      "Epoch 730 Loss is 3838.229005785024\n",
      "Epoch 731 Loss is 3838.12925698373\n",
      "Epoch 732 Loss is 3838.0293912565016\n",
      "Epoch 733 Loss is 3837.929407168746\n",
      "Epoch 734 Loss is 3837.829303326557\n",
      "Epoch 735 Loss is 3837.7290783394637\n",
      "Epoch 736 Loss is 3837.6287307903563\n",
      "Epoch 737 Loss is 3837.5282592515287\n",
      "Epoch 738 Loss is 3837.4276623187384\n",
      "Epoch 739 Loss is 3837.3269385769727\n",
      "Epoch 740 Loss is 3837.2260866077677\n",
      "Epoch 741 Loss is 3837.1251050236892\n",
      "Epoch 742 Loss is 3837.023992422126\n",
      "Epoch 743 Loss is 3836.9227474177405\n",
      "Epoch 744 Loss is 3836.8213686408803\n",
      "Epoch 745 Loss is 3836.7198547576077\n",
      "Epoch 746 Loss is 3836.61820443472\n",
      "Epoch 747 Loss is 3836.5164163182044\n",
      "Epoch 748 Loss is 3836.4144891174124\n",
      "Epoch 749 Loss is 3836.3124215868243\n",
      "Epoch 750 Loss is 3836.210212472239\n",
      "Epoch 751 Loss is 3836.1078605358357\n",
      "Epoch 752 Loss is 3836.005364611551\n",
      "Epoch 753 Loss is 3835.9027235271324\n",
      "Epoch 754 Loss is 3835.7999360830145\n",
      "Epoch 755 Loss is 3835.697001080397\n",
      "Epoch 756 Loss is 3835.593917355557\n",
      "Epoch 757 Loss is 3835.4906837327735\n",
      "Epoch 758 Loss is 3835.387299164477\n",
      "Epoch 759 Loss is 3835.2837626065116\n",
      "Epoch 760 Loss is 3835.1800730685136\n",
      "Epoch 761 Loss is 3835.076229553299\n",
      "Epoch 762 Loss is 3834.972231059885\n",
      "Epoch 763 Loss is 3834.8680765945755\n",
      "Epoch 764 Loss is 3834.7637652141907\n",
      "Epoch 765 Loss is 3834.6592960277294\n",
      "Epoch 766 Loss is 3834.5546682303666\n",
      "Epoch 767 Loss is 3834.4498811084386\n",
      "Epoch 768 Loss is 3834.344933870065\n",
      "Epoch 769 Loss is 3834.2398257985305\n",
      "Epoch 770 Loss is 3834.134556325662\n",
      "Epoch 771 Loss is 3834.029124856118\n",
      "Epoch 772 Loss is 3833.92353084573\n",
      "Epoch 773 Loss is 3833.817773843804\n",
      "Epoch 774 Loss is 3833.7118533643625\n",
      "Epoch 775 Loss is 3833.6057690035154\n",
      "Epoch 776 Loss is 3833.4995204857228\n",
      "Epoch 777 Loss is 3833.393107586328\n",
      "Epoch 778 Loss is 3833.28653014229\n",
      "Epoch 779 Loss is 3833.179787987036\n",
      "Epoch 780 Loss is 3833.0728810533965\n",
      "Epoch 781 Loss is 3832.9658092970462\n",
      "Epoch 782 Loss is 3832.8585727249756\n",
      "Epoch 783 Loss is 3832.7511713682106\n",
      "Epoch 784 Loss is 3832.6436054141823\n",
      "Epoch 785 Loss is 3832.5358751167946\n",
      "Epoch 786 Loss is 3832.4279808408073\n",
      "Epoch 787 Loss is 3832.3199229892016\n",
      "Epoch 788 Loss is 3832.211702057882\n",
      "Epoch 789 Loss is 3832.103318597626\n",
      "Epoch 790 Loss is 3831.994773208224\n",
      "Epoch 791 Loss is 3831.8860666118844\n",
      "Epoch 792 Loss is 3831.7771994973773\n",
      "Epoch 793 Loss is 3831.6681726540905\n",
      "Epoch 794 Loss is 3831.5589869340524\n",
      "Epoch 795 Loss is 3831.4496432161764\n",
      "Epoch 796 Loss is 3831.3401425321867\n",
      "Epoch 797 Loss is 3831.2304860063887\n",
      "Epoch 798 Loss is 3831.12067490843\n",
      "Epoch 799 Loss is 3831.010710463216\n",
      "Epoch 800 Loss is 3830.9005938944006\n",
      "Epoch 801 Loss is 3830.7903265680993\n",
      "Epoch 802 Loss is 3830.679909933398\n",
      "Epoch 803 Loss is 3830.5693454883053\n",
      "Epoch 804 Loss is 3830.4586347746977\n",
      "Epoch 805 Loss is 3830.3477794268406\n",
      "Epoch 806 Loss is 3830.2367810795663\n",
      "Epoch 807 Loss is 3830.1256414328986\n",
      "Epoch 808 Loss is 3830.014362223952\n",
      "Epoch 809 Loss is 3829.902945388884\n",
      "Epoch 810 Loss is 3829.7913928957637\n",
      "Epoch 811 Loss is 3829.679706757481\n",
      "Epoch 812 Loss is 3829.5678889925616\n",
      "Epoch 813 Loss is 3829.4559416280013\n",
      "Epoch 814 Loss is 3829.3438668242934\n",
      "Epoch 815 Loss is 3829.231666861129\n",
      "Epoch 816 Loss is 3829.119343976643\n",
      "Epoch 817 Loss is 3829.0069004089687\n",
      "Epoch 818 Loss is 3828.894338560171\n",
      "Epoch 819 Loss is 3828.7816609245547\n",
      "Epoch 820 Loss is 3828.6688699453666\n",
      "Epoch 821 Loss is 3828.5559681331147\n",
      "Epoch 822 Loss is 3828.4429580205406\n",
      "Epoch 823 Loss is 3828.3298421131394\n",
      "Epoch 824 Loss is 3828.2166230665207\n",
      "Epoch 825 Loss is 3828.1033035266196\n",
      "Epoch 826 Loss is 3827.989886124068\n",
      "Epoch 827 Loss is 3827.8763734397785\n",
      "Epoch 828 Loss is 3827.7627680933447\n",
      "Epoch 829 Loss is 3827.6490727783294\n",
      "Epoch 830 Loss is 3827.535290203516\n",
      "Epoch 831 Loss is 3827.421423110746\n",
      "Epoch 832 Loss is 3827.3074742381104\n",
      "Epoch 833 Loss is 3827.1934462184354\n",
      "Epoch 834 Loss is 3827.0793417005475\n",
      "Epoch 835 Loss is 3826.965163372636\n",
      "Epoch 836 Loss is 3826.850913888894\n",
      "Epoch 837 Loss is 3826.736595930408\n",
      "Epoch 838 Loss is 3826.6222123097223\n",
      "Epoch 839 Loss is 3826.5077657799143\n",
      "Epoch 840 Loss is 3826.393258979128\n",
      "Epoch 841 Loss is 3826.278694524739\n",
      "Epoch 842 Loss is 3826.16407526417\n",
      "Epoch 843 Loss is 3826.049403937486\n",
      "Epoch 844 Loss is 3825.934683194082\n",
      "Epoch 845 Loss is 3825.8199157022646\n",
      "Epoch 846 Loss is 3825.705104384195\n",
      "Epoch 847 Loss is 3825.59025200783\n",
      "Epoch 848 Loss is 3825.475361240589\n",
      "Epoch 849 Loss is 3825.3604346087795\n",
      "Epoch 850 Loss is 3825.2454747906845\n",
      "Epoch 851 Loss is 3825.130484399326\n",
      "Epoch 852 Loss is 3825.0154663133944\n",
      "Epoch 853 Loss is 3824.9004233352052\n",
      "Epoch 854 Loss is 3824.7853579055177\n",
      "Epoch 855 Loss is 3824.6702726060807\n",
      "Epoch 856 Loss is 3824.555169871068\n",
      "Epoch 857 Loss is 3824.440052051814\n",
      "Epoch 858 Loss is 3824.324921433873\n",
      "Epoch 859 Loss is 3824.209780326068\n",
      "Epoch 860 Loss is 3824.094631123301\n",
      "Epoch 861 Loss is 3823.97947614624\n",
      "Epoch 862 Loss is 3823.8643176548535\n",
      "Epoch 863 Loss is 3823.7491579060356\n",
      "Epoch 864 Loss is 3823.633999295882\n",
      "Epoch 865 Loss is 3823.5188439879207\n",
      "Epoch 866 Loss is 3823.4036942227453\n",
      "Epoch 867 Loss is 3823.288552145176\n",
      "Epoch 868 Loss is 3823.1734198825347\n",
      "Epoch 869 Loss is 3823.058299368292\n",
      "Epoch 870 Loss is 3822.943192533311\n",
      "Epoch 871 Loss is 3822.8281013658575\n",
      "Epoch 872 Loss is 3822.7130278476457\n",
      "Epoch 873 Loss is 3822.597973770355\n",
      "Epoch 874 Loss is 3822.4829412230324\n",
      "Epoch 875 Loss is 3822.367932054243\n",
      "Epoch 876 Loss is 3822.2529481757415\n",
      "Epoch 877 Loss is 3822.137991285122\n",
      "Epoch 878 Loss is 3822.023063182866\n",
      "Epoch 879 Loss is 3821.9081656656986\n",
      "Epoch 880 Loss is 3821.7933007088614\n",
      "Epoch 881 Loss is 3821.6784698777424\n",
      "Epoch 882 Loss is 3821.5636749930845\n",
      "Epoch 883 Loss is 3821.4489176206393\n",
      "Epoch 884 Loss is 3821.334199201871\n",
      "Epoch 885 Loss is 3821.219521250359\n",
      "Epoch 886 Loss is 3821.1048854341707\n",
      "Epoch 887 Loss is 3820.9902933279527\n",
      "Epoch 888 Loss is 3820.875746524892\n",
      "Epoch 889 Loss is 3820.7612465753677\n",
      "Epoch 890 Loss is 3820.646794777941\n",
      "Epoch 891 Loss is 3820.532392466622\n",
      "Epoch 892 Loss is 3820.41804117649\n",
      "Epoch 893 Loss is 3820.303742229173\n",
      "Epoch 894 Loss is 3820.189497078177\n",
      "Epoch 895 Loss is 3820.0753069837706\n",
      "Epoch 896 Loss is 3819.9611730291663\n",
      "Epoch 897 Loss is 3819.847096391862\n",
      "Epoch 898 Loss is 3819.7330782460685\n",
      "Epoch 899 Loss is 3819.6191198400447\n",
      "Epoch 900 Loss is 3819.5052223196462\n",
      "Epoch 901 Loss is 3819.3913867346055\n",
      "Epoch 902 Loss is 3819.2776141044365\n",
      "Epoch 903 Loss is 3819.1639056321937\n",
      "Epoch 904 Loss is 3819.0502626907246\n",
      "Epoch 905 Loss is 3818.936686146421\n",
      "Epoch 906 Loss is 3818.823176886876\n",
      "Epoch 907 Loss is 3818.709736039507\n",
      "Epoch 908 Loss is 3818.5963646354776\n",
      "Epoch 909 Loss is 3818.483063455895\n",
      "Epoch 910 Loss is 3818.3698335812187\n",
      "Epoch 911 Loss is 3818.256675807492\n",
      "Epoch 912 Loss is 3818.143590778939\n",
      "Epoch 913 Loss is 3818.030579104778\n",
      "Epoch 914 Loss is 3817.9176415565335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915 Loss is 3817.804778554136\n",
      "Epoch 916 Loss is 3817.691990525376\n",
      "Epoch 917 Loss is 3817.5792778350824\n",
      "Epoch 918 Loss is 3817.4666408286375\n",
      "Epoch 919 Loss is 3817.3540799947086\n",
      "Epoch 920 Loss is 3817.2415957147086\n",
      "Epoch 921 Loss is 3817.1291882898886\n",
      "Epoch 922 Loss is 3817.0168579238375\n",
      "Epoch 923 Loss is 3816.9046049561416\n",
      "Epoch 924 Loss is 3816.792429477756\n",
      "Epoch 925 Loss is 3816.680331835825\n",
      "Epoch 926 Loss is 3816.568312150105\n",
      "Epoch 927 Loss is 3816.4563709310182\n",
      "Epoch 928 Loss is 3816.344508309235\n",
      "Epoch 929 Loss is 3816.232724387316\n",
      "Epoch 930 Loss is 3816.1210192172966\n",
      "Epoch 931 Loss is 3816.009392847485\n",
      "Epoch 932 Loss is 3815.89784526893\n",
      "Epoch 933 Loss is 3815.786376382632\n",
      "Epoch 934 Loss is 3815.6749861034577\n",
      "Epoch 935 Loss is 3815.563674348578\n",
      "Epoch 936 Loss is 3815.452441180973\n",
      "Epoch 937 Loss is 3815.3412865425194\n",
      "Epoch 938 Loss is 3815.230210231475\n",
      "Epoch 939 Loss is 3815.119212058159\n",
      "Epoch 940 Loss is 3815.0082918576513\n",
      "Epoch 941 Loss is 3814.897449464163\n",
      "Epoch 942 Loss is 3814.7866846661104\n",
      "Epoch 943 Loss is 3814.675997219812\n",
      "Epoch 944 Loss is 3814.5653869563266\n",
      "Epoch 945 Loss is 3814.454853451559\n",
      "Epoch 946 Loss is 3814.3443962017523\n",
      "Epoch 947 Loss is 3814.2340146944725\n",
      "Epoch 948 Loss is 3814.123708480007\n",
      "Epoch 949 Loss is 3814.013477013237\n",
      "Epoch 950 Loss is 3813.9033199293995\n",
      "Epoch 951 Loss is 3813.7932367883186\n",
      "Epoch 952 Loss is 3813.6832269875044\n",
      "Epoch 953 Loss is 3813.5732898593646\n",
      "Epoch 954 Loss is 3813.4634248741127\n",
      "Epoch 955 Loss is 3813.3536313700533\n",
      "Epoch 956 Loss is 3813.2439086391537\n",
      "Epoch 957 Loss is 3813.1342560430544\n",
      "Epoch 958 Loss is 3813.0246728225648\n",
      "Epoch 959 Loss is 3812.9151582156624\n",
      "Epoch 960 Loss is 3812.8057114101925\n",
      "Epoch 961 Loss is 3812.6963317565555\n",
      "Epoch 962 Loss is 3812.5870185249096\n",
      "Epoch 963 Loss is 3812.477771025766\n",
      "Epoch 964 Loss is 3812.368588437326\n",
      "Epoch 965 Loss is 3812.259470042455\n",
      "Epoch 966 Loss is 3812.150415127977\n",
      "Epoch 967 Loss is 3812.041422878337\n",
      "Epoch 968 Loss is 3811.9324927804855\n",
      "Epoch 969 Loss is 3811.823624058159\n",
      "Epoch 970 Loss is 3811.714816095516\n",
      "Epoch 971 Loss is 3811.6060681354297\n",
      "Epoch 972 Loss is 3811.497379456264\n",
      "Epoch 973 Loss is 3811.3887491829028\n",
      "Epoch 974 Loss is 3811.2801765359472\n",
      "Epoch 975 Loss is 3811.1716608276674\n",
      "Epoch 976 Loss is 3811.0632013811633\n",
      "Epoch 977 Loss is 3810.9547973799263\n",
      "Epoch 978 Loss is 3810.846448113945\n",
      "Epoch 979 Loss is 3810.738152839687\n",
      "Epoch 980 Loss is 3810.6299108054977\n",
      "Epoch 981 Loss is 3810.521721231475\n",
      "Epoch 982 Loss is 3810.4135832958636\n",
      "Epoch 983 Loss is 3810.3054961635335\n",
      "Epoch 984 Loss is 3810.1974590428395\n",
      "Epoch 985 Loss is 3810.08947116075\n",
      "Epoch 986 Loss is 3809.9815316704403\n",
      "Epoch 987 Loss is 3809.8736397762864\n",
      "Epoch 988 Loss is 3809.765794704744\n",
      "Epoch 989 Loss is 3809.6579956349788\n",
      "Epoch 990 Loss is 3809.5502417705443\n",
      "Epoch 991 Loss is 3809.4425322528996\n",
      "Epoch 992 Loss is 3809.3348662947137\n",
      "Epoch 993 Loss is 3809.227243216103\n",
      "Epoch 994 Loss is 3809.1196624506483\n",
      "Epoch 995 Loss is 3809.0121231773546\n",
      "Epoch 996 Loss is 3808.90462459828\n",
      "Epoch 997 Loss is 3808.7971658932424\n",
      "Epoch 998 Loss is 3808.689746245548\n",
      "Epoch 999 Loss is 3808.582364793279\n",
      "Epoch 1000 Loss is 3808.4750207636034\n",
      "Epoch 1001 Loss is 3808.3677134766426\n",
      "Epoch 1002 Loss is 3808.2604421649457\n",
      "Epoch 1003 Loss is 3808.1532061080306\n",
      "Epoch 1004 Loss is 3808.0460045629584\n",
      "Epoch 1005 Loss is 3807.9388367982574\n",
      "Epoch 1006 Loss is 3807.831702187512\n",
      "Epoch 1007 Loss is 3807.72460014087\n",
      "Epoch 1008 Loss is 3807.6175299270108\n",
      "Epoch 1009 Loss is 3807.5104907821774\n",
      "Epoch 1010 Loss is 3807.4034817867705\n",
      "Epoch 1011 Loss is 3807.2965021593072\n",
      "Epoch 1012 Loss is 3807.189551320785\n",
      "Epoch 1013 Loss is 3807.0826285619064\n",
      "Epoch 1014 Loss is 3806.975733295493\n",
      "Epoch 1015 Loss is 3806.8688647672434\n",
      "Epoch 1016 Loss is 3806.762022341298\n",
      "Epoch 1017 Loss is 3806.655205388061\n",
      "Epoch 1018 Loss is 3806.548413196679\n",
      "Epoch 1019 Loss is 3806.441645008548\n",
      "Epoch 1020 Loss is 3806.3349000831035\n",
      "Epoch 1021 Loss is 3806.228177742503\n",
      "Epoch 1022 Loss is 3806.121477360296\n",
      "Epoch 1023 Loss is 3806.0147984092637\n",
      "Epoch 1024 Loss is 3805.9081401548124\n",
      "Epoch 1025 Loss is 3805.8015018115047\n",
      "Epoch 1026 Loss is 3805.694882564623\n",
      "Epoch 1027 Loss is 3805.5882816603403\n",
      "Epoch 1028 Loss is 3805.4816983272663\n",
      "Epoch 1029 Loss is 3805.3751318176764\n",
      "Epoch 1030 Loss is 3805.2685814126817\n",
      "Epoch 1031 Loss is 3805.1620463952713\n",
      "Epoch 1032 Loss is 3805.0555260617966\n",
      "Epoch 1033 Loss is 3804.9490196735114\n",
      "Epoch 1034 Loss is 3804.8425265140418\n",
      "Epoch 1035 Loss is 3804.736045962883\n",
      "Epoch 1036 Loss is 3804.629577457767\n",
      "Epoch 1037 Loss is 3804.523120346796\n",
      "Epoch 1038 Loss is 3804.416673932072\n",
      "Epoch 1039 Loss is 3804.3102374769087\n",
      "Epoch 1040 Loss is 3804.203810258328\n",
      "Epoch 1041 Loss is 3804.0973915714007\n",
      "Epoch 1042 Loss is 3803.990980812415\n",
      "Epoch 1043 Loss is 3803.8845772705904\n",
      "Epoch 1044 Loss is 3803.7781802727022\n",
      "Epoch 1045 Loss is 3803.6717891039407\n",
      "Epoch 1046 Loss is 3803.5654031145905\n",
      "Epoch 1047 Loss is 3803.4590216092874\n",
      "Epoch 1048 Loss is 3803.3526438594263\n",
      "Epoch 1049 Loss is 3803.246269155827\n",
      "Epoch 1050 Loss is 3803.139896880403\n",
      "Epoch 1051 Loss is 3803.033526318573\n",
      "Epoch 1052 Loss is 3802.9271567547166\n",
      "Epoch 1053 Loss is 3802.820787480352\n",
      "Epoch 1054 Loss is 3802.714417771481\n",
      "Epoch 1055 Loss is 3802.6080468670652\n",
      "Epoch 1056 Loss is 3802.5016739947664\n",
      "Epoch 1057 Loss is 3802.395298432669\n",
      "Epoch 1058 Loss is 3802.2889194551426\n",
      "Epoch 1059 Loss is 3802.182536319774\n",
      "Epoch 1060 Loss is 3802.0761483244555\n",
      "Epoch 1061 Loss is 3801.96975476481\n",
      "Epoch 1062 Loss is 3801.8633549288074\n",
      "Epoch 1063 Loss is 3801.7569480364664\n",
      "Epoch 1064 Loss is 3801.65053337147\n",
      "Epoch 1065 Loss is 3801.5441101535466\n",
      "Epoch 1066 Loss is 3801.4376776388012\n",
      "Epoch 1067 Loss is 3801.3312351100126\n",
      "Epoch 1068 Loss is 3801.2247818954115\n",
      "Epoch 1069 Loss is 3801.1183173202685\n",
      "Epoch 1070 Loss is 3801.0118406338433\n",
      "Epoch 1071 Loss is 3800.9053511019138\n",
      "Epoch 1072 Loss is 3800.7988480211247\n",
      "Epoch 1073 Loss is 3800.692330680397\n",
      "Epoch 1074 Loss is 3800.585798247775\n",
      "Epoch 1075 Loss is 3800.479249964728\n",
      "Epoch 1076 Loss is 3800.372685001914\n",
      "Epoch 1077 Loss is 3800.2661026112182\n",
      "Epoch 1078 Loss is 3800.159502041548\n",
      "Epoch 1079 Loss is 3800.052882555446\n",
      "Epoch 1080 Loss is 3799.946243445336\n",
      "Epoch 1081 Loss is 3799.839583983626\n",
      "Epoch 1082 Loss is 3799.732903428188\n",
      "Epoch 1083 Loss is 3799.626201012833\n",
      "Epoch 1084 Loss is 3799.5194759556057\n",
      "Epoch 1085 Loss is 3799.4127274777525\n",
      "Epoch 1086 Loss is 3799.3059549228797\n",
      "Epoch 1087 Loss is 3799.199157470921\n",
      "Epoch 1088 Loss is 3799.0923343608297\n",
      "Epoch 1089 Loss is 3798.985484808169\n",
      "Epoch 1090 Loss is 3798.8786080447594\n",
      "Epoch 1091 Loss is 3798.7717033536487\n",
      "Epoch 1092 Loss is 3798.6647698853903\n",
      "Epoch 1093 Loss is 3798.557806720618\n",
      "Epoch 1094 Loss is 3798.4508129835654\n",
      "Epoch 1095 Loss is 3798.3437878752807\n",
      "Epoch 1096 Loss is 3798.236730584172\n",
      "Epoch 1097 Loss is 3798.1296402946155\n",
      "Epoch 1098 Loss is 3798.022516079501\n",
      "Epoch 1099 Loss is 3797.9153570058675\n",
      "Epoch 1100 Loss is 3797.8081621853767\n",
      "Epoch 1101 Loss is 3797.700930731401\n",
      "Epoch 1102 Loss is 3797.593661826943\n",
      "Epoch 1103 Loss is 3797.486354567239\n",
      "Epoch 1104 Loss is 3797.3790080206\n",
      "Epoch 1105 Loss is 3797.271621294758\n",
      "Epoch 1106 Loss is 3797.164193474694\n",
      "Epoch 1107 Loss is 3797.056723602958\n",
      "Epoch 1108 Loss is 3796.949210661087\n",
      "Epoch 1109 Loss is 3796.8416536478403\n",
      "Epoch 1110 Loss is 3796.7340515857877\n",
      "Epoch 1111 Loss is 3796.6264035412087\n",
      "Epoch 1112 Loss is 3796.518708672553\n",
      "Epoch 1113 Loss is 3796.410966063733\n",
      "Epoch 1114 Loss is 3796.303174740534\n",
      "Epoch 1115 Loss is 3796.1953337425566\n",
      "Epoch 1116 Loss is 3796.0874421571234\n",
      "Epoch 1117 Loss is 3795.979499036929\n",
      "Epoch 1118 Loss is 3795.8715034499432\n",
      "Epoch 1119 Loss is 3795.7634544404887\n",
      "Epoch 1120 Loss is 3795.6553510567564\n",
      "Epoch 1121 Loss is 3795.547192304064\n",
      "Epoch 1122 Loss is 3795.438977191637\n",
      "Epoch 1123 Loss is 3795.330704754259\n",
      "Epoch 1124 Loss is 3795.222373986356\n",
      "Epoch 1125 Loss is 3795.113983922339\n",
      "Epoch 1126 Loss is 3795.0055336251753\n",
      "Epoch 1127 Loss is 3794.8970220897995\n",
      "Epoch 1128 Loss is 3794.788448347142\n",
      "Epoch 1129 Loss is 3794.6798114022995\n",
      "Epoch 1130 Loss is 3794.5711102781956\n",
      "Epoch 1131 Loss is 3794.4623439190277\n",
      "Epoch 1132 Loss is 3794.3535112636578\n",
      "Epoch 1133 Loss is 3794.2446111959775\n",
      "Epoch 1134 Loss is 3794.1356426967172\n",
      "Epoch 1135 Loss is 3794.026604647654\n",
      "Epoch 1136 Loss is 3793.9174959438933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1137 Loss is 3793.8083154828746\n",
      "Epoch 1138 Loss is 3793.6990621316045\n",
      "Epoch 1139 Loss is 3793.589734740442\n",
      "Epoch 1140 Loss is 3793.4803321709774\n",
      "Epoch 1141 Loss is 3793.3708532762266\n",
      "Epoch 1142 Loss is 3793.26129692646\n",
      "Epoch 1143 Loss is 3793.1516619788426\n",
      "Epoch 1144 Loss is 3793.041947389914\n",
      "Epoch 1145 Loss is 3792.9321520384847\n",
      "Epoch 1146 Loss is 3792.8222747764717\n",
      "Epoch 1147 Loss is 3792.712314477794\n",
      "Epoch 1148 Loss is 3792.6022700202107\n",
      "Epoch 1149 Loss is 3792.4921402258383\n",
      "Epoch 1150 Loss is 3792.3819239613695\n",
      "Epoch 1151 Loss is 3792.271620050291\n",
      "Epoch 1152 Loss is 3792.1612273571436\n",
      "Epoch 1153 Loss is 3792.050744718606\n",
      "Epoch 1154 Loss is 3791.9401709624876\n",
      "Epoch 1155 Loss is 3791.8295049352964\n",
      "Epoch 1156 Loss is 3791.718745465825\n",
      "Epoch 1157 Loss is 3791.6078913755855\n",
      "Epoch 1158 Loss is 3791.4969415431015\n",
      "Epoch 1159 Loss is 3791.385894791309\n",
      "Epoch 1160 Loss is 3791.274749983805\n",
      "Epoch 1161 Loss is 3791.1635059981345\n",
      "Epoch 1162 Loss is 3791.052161627254\n",
      "Epoch 1163 Loss is 3790.940715737005\n",
      "Epoch 1164 Loss is 3790.829167204468\n",
      "Epoch 1165 Loss is 3790.717514926738\n",
      "Epoch 1166 Loss is 3790.6057577795373\n",
      "Epoch 1167 Loss is 3790.4938946068146\n",
      "Epoch 1168 Loss is 3790.3819242549685\n",
      "Epoch 1169 Loss is 3790.269845612765\n",
      "Epoch 1170 Loss is 3790.157657580491\n",
      "Epoch 1171 Loss is 3790.045358995952\n",
      "Epoch 1172 Loss is 3789.9329486449096\n",
      "Epoch 1173 Loss is 3789.8204252933083\n",
      "Epoch 1174 Loss is 3789.7077877852053\n",
      "Epoch 1175 Loss is 3789.5950349687\n",
      "Epoch 1176 Loss is 3789.482165687461\n",
      "Epoch 1177 Loss is 3789.3691787768344\n",
      "Epoch 1178 Loss is 3789.256073086257\n",
      "Epoch 1179 Loss is 3789.1428475348066\n",
      "Epoch 1180 Loss is 3789.0295009537504\n",
      "Epoch 1181 Loss is 3788.9160321808295\n",
      "Epoch 1182 Loss is 3788.802440150582\n",
      "Epoch 1183 Loss is 3788.6887237810793\n",
      "Epoch 1184 Loss is 3788.5748819361465\n",
      "Epoch 1185 Loss is 3788.4609134572747\n",
      "Epoch 1186 Loss is 3788.346817218942\n",
      "Epoch 1187 Loss is 3788.232592110334\n",
      "Epoch 1188 Loss is 3788.11823702837\n",
      "Epoch 1189 Loss is 3788.003750894612\n",
      "Epoch 1190 Loss is 3787.889132623123\n",
      "Epoch 1191 Loss is 3787.7743811586565\n",
      "Epoch 1192 Loss is 3787.659495420762\n",
      "Epoch 1193 Loss is 3787.544474351018\n",
      "Epoch 1194 Loss is 3787.4293169429816\n",
      "Epoch 1195 Loss is 3787.314022167495\n",
      "Epoch 1196 Loss is 3787.198589012712\n",
      "Epoch 1197 Loss is 3787.0830165120497\n",
      "Epoch 1198 Loss is 3786.967303674002\n",
      "Epoch 1199 Loss is 3786.8514495221966\n",
      "Epoch 1200 Loss is 3786.7354531080828\n",
      "Epoch 1201 Loss is 3786.6193135374115\n",
      "Epoch 1202 Loss is 3786.503029858401\n",
      "Epoch 1203 Loss is 3786.386601139649\n",
      "Epoch 1204 Loss is 3786.270026486656\n",
      "Epoch 1205 Loss is 3786.153305005682\n",
      "Epoch 1206 Loss is 3786.0364358611023\n",
      "Epoch 1207 Loss is 3785.919418192158\n",
      "Epoch 1208 Loss is 3785.802251105935\n",
      "Epoch 1209 Loss is 3785.6849337389676\n",
      "Epoch 1210 Loss is 3785.567465253328\n",
      "Epoch 1211 Loss is 3785.4498448171307\n",
      "Epoch 1212 Loss is 3785.3320716381013\n",
      "Epoch 1213 Loss is 3785.2141448923935\n",
      "Epoch 1214 Loss is 3785.096063766754\n",
      "Epoch 1215 Loss is 3784.977827501662\n",
      "Epoch 1216 Loss is 3784.85943532092\n",
      "Epoch 1217 Loss is 3784.7408864898543\n",
      "Epoch 1218 Loss is 3784.6221802773184\n",
      "Epoch 1219 Loss is 3784.503315944059\n",
      "Epoch 1220 Loss is 3784.3842927726296\n",
      "Epoch 1221 Loss is 3784.2651100490075\n",
      "Epoch 1222 Loss is 3784.1457671158378\n",
      "Epoch 1223 Loss is 3784.0262633334687\n",
      "Epoch 1224 Loss is 3783.9065980871906\n",
      "Epoch 1225 Loss is 3783.786770775446\n",
      "Epoch 1226 Loss is 3783.6667808159723\n",
      "Epoch 1227 Loss is 3783.5466276727793\n",
      "Epoch 1228 Loss is 3783.4263108270015\n",
      "Epoch 1229 Loss is 3783.305829749965\n",
      "Epoch 1230 Loss is 3783.185183930597\n",
      "Epoch 1231 Loss is 3783.064372915768\n",
      "Epoch 1232 Loss is 3782.9433962495477\n",
      "Epoch 1233 Loss is 3782.8222535122777\n",
      "Epoch 1234 Loss is 3782.7009443153274\n",
      "Epoch 1235 Loss is 3782.5794682533447\n",
      "Epoch 1236 Loss is 3782.4578249141737\n",
      "Epoch 1237 Loss is 3782.336013932302\n",
      "Epoch 1238 Loss is 3782.214034991528\n",
      "Epoch 1239 Loss is 3782.091887780057\n",
      "Epoch 1240 Loss is 3781.9695720202003\n",
      "Epoch 1241 Loss is 3781.847087431365\n",
      "Epoch 1242 Loss is 3781.724433751515\n",
      "Epoch 1243 Loss is 3781.601610700672\n",
      "Epoch 1244 Loss is 3781.4786180651486\n",
      "Epoch 1245 Loss is 3781.355455662034\n",
      "Epoch 1246 Loss is 3781.2321233034463\n",
      "Epoch 1247 Loss is 3781.1086208184374\n",
      "Epoch 1248 Loss is 3780.984948079273\n",
      "Epoch 1249 Loss is 3780.861104982697\n",
      "Epoch 1250 Loss is 3780.737091463226\n",
      "Epoch 1251 Loss is 3780.6129074798087\n",
      "Epoch 1252 Loss is 3780.488553019687\n",
      "Epoch 1253 Loss is 3780.3640280370328\n",
      "Epoch 1254 Loss is 3780.2393325490516\n",
      "Epoch 1255 Loss is 3780.114466602764\n",
      "Epoch 1256 Loss is 3779.9894302347516\n",
      "Epoch 1257 Loss is 3779.864223472259\n",
      "Epoch 1258 Loss is 3779.738846422767\n",
      "Epoch 1259 Loss is 3779.613299223901\n",
      "Epoch 1260 Loss is 3779.4875820108664\n",
      "Epoch 1261 Loss is 3779.3616949490715\n",
      "Epoch 1262 Loss is 3779.235638242859\n",
      "Epoch 1263 Loss is 3779.1094121250703\n",
      "Epoch 1264 Loss is 3778.9830168700596\n",
      "Epoch 1265 Loss is 3778.856452771905\n",
      "Epoch 1266 Loss is 3778.7297200983908\n",
      "Epoch 1267 Loss is 3778.6028191780383\n",
      "Epoch 1268 Loss is 3778.475750358167\n",
      "Epoch 1269 Loss is 3778.3485140009197\n",
      "Epoch 1270 Loss is 3778.2211105074243\n",
      "Epoch 1271 Loss is 3778.093540268128\n",
      "Epoch 1272 Loss is 3777.965803680832\n",
      "Epoch 1273 Loss is 3777.837901200539\n",
      "Epoch 1274 Loss is 3777.709833277353\n",
      "Epoch 1275 Loss is 3777.5816004013936\n",
      "Epoch 1276 Loss is 3777.4532030970504\n",
      "Epoch 1277 Loss is 3777.3246419009965\n",
      "Epoch 1278 Loss is 3777.1959173156597\n",
      "Epoch 1279 Loss is 3777.0670298773066\n",
      "Epoch 1280 Loss is 3776.9379801525697\n",
      "Epoch 1281 Loss is 3776.8087687474076\n",
      "Epoch 1282 Loss is 3776.6793962850957\n",
      "Epoch 1283 Loss is 3776.549863419366\n",
      "Epoch 1284 Loss is 3776.4201707873217\n",
      "Epoch 1285 Loss is 3776.290319055589\n",
      "Epoch 1286 Loss is 3776.1603089503587\n",
      "Epoch 1287 Loss is 3776.03014117103\n",
      "Epoch 1288 Loss is 3775.8998163988454\n",
      "Epoch 1289 Loss is 3775.7693353588948\n",
      "Epoch 1290 Loss is 3775.63869880009\n",
      "Epoch 1291 Loss is 3775.5079074956593\n",
      "Epoch 1292 Loss is 3775.3769622164878\n",
      "Epoch 1293 Loss is 3775.2458637655245\n",
      "Epoch 1294 Loss is 3775.114612992993\n",
      "Epoch 1295 Loss is 3774.983210744092\n",
      "Epoch 1296 Loss is 3774.851657864299\n",
      "Epoch 1297 Loss is 3774.7199552064326\n",
      "Epoch 1298 Loss is 3774.588103630015\n",
      "Epoch 1299 Loss is 3774.456104009172\n",
      "Epoch 1300 Loss is 3774.323957226304\n",
      "Epoch 1301 Loss is 3774.191664208301\n",
      "Epoch 1302 Loss is 3774.059225877663\n",
      "Epoch 1303 Loss is 3773.926643161439\n",
      "Epoch 1304 Loss is 3773.7939170003774\n",
      "Epoch 1305 Loss is 3773.661048311952\n",
      "Epoch 1306 Loss is 3773.528038060392\n",
      "Epoch 1307 Loss is 3773.394887213554\n",
      "Epoch 1308 Loss is 3773.261596739966\n",
      "Epoch 1309 Loss is 3773.128167625583\n",
      "Epoch 1310 Loss is 3772.9946008630263\n",
      "Epoch 1311 Loss is 3772.8608974531326\n",
      "Epoch 1312 Loss is 3772.7270584194503\n",
      "Epoch 1313 Loss is 3772.5930847958\n",
      "Epoch 1314 Loss is 3772.4589776397765\n",
      "Epoch 1315 Loss is 3772.3247380002394\n",
      "Epoch 1316 Loss is 3772.190366908579\n",
      "Epoch 1317 Loss is 3772.0558654079887\n",
      "Epoch 1318 Loss is 3771.921234566762\n",
      "Epoch 1319 Loss is 3771.7864754500415\n",
      "Epoch 1320 Loss is 3771.651589131439\n",
      "Epoch 1321 Loss is 3771.5165766882446\n",
      "Epoch 1322 Loss is 3771.381439185658\n",
      "Epoch 1323 Loss is 3771.2461777128083\n",
      "Epoch 1324 Loss is 3771.1107933334483\n",
      "Epoch 1325 Loss is 3770.9752870944503\n",
      "Epoch 1326 Loss is 3770.8396600726946\n",
      "Epoch 1327 Loss is 3770.7039133350954\n",
      "Epoch 1328 Loss is 3770.568047974133\n",
      "Epoch 1329 Loss is 3770.4320650884706\n",
      "Epoch 1330 Loss is 3770.295965774464\n",
      "Epoch 1331 Loss is 3770.159751103955\n",
      "Epoch 1332 Loss is 3770.0234221476776\n",
      "Epoch 1333 Loss is 3769.8869799673244\n",
      "Epoch 1334 Loss is 3769.7504256708057\n",
      "Epoch 1335 Loss is 3769.6137603737798\n",
      "Epoch 1336 Loss is 3769.476985174409\n",
      "Epoch 1337 Loss is 3769.340101138352\n",
      "Epoch 1338 Loss is 3769.203109320057\n",
      "Epoch 1339 Loss is 3769.066010761754\n",
      "Epoch 1340 Loss is 3768.9288065038736\n",
      "Epoch 1341 Loss is 3768.7914976009847\n",
      "Epoch 1342 Loss is 3768.6540851057616\n",
      "Epoch 1343 Loss is 3768.5165700622224\n",
      "Epoch 1344 Loss is 3768.378953494228\n",
      "Epoch 1345 Loss is 3768.2412364458414\n",
      "Epoch 1346 Loss is 3768.103419980425\n",
      "Epoch 1347 Loss is 3767.965505132032\n",
      "Epoch 1348 Loss is 3767.8274929213967\n",
      "Epoch 1349 Loss is 3767.6893843665093\n",
      "Epoch 1350 Loss is 3767.551180489341\n",
      "Epoch 1351 Loss is 3767.412882316302\n",
      "Epoch 1352 Loss is 3767.2744908764003\n",
      "Epoch 1353 Loss is 3767.1360071515173\n",
      "Epoch 1354 Loss is 3766.997432126883\n",
      "Epoch 1355 Loss is 3766.85876679899\n",
      "Epoch 1356 Loss is 3766.720012142816\n",
      "Epoch 1357 Loss is 3766.581169103679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1358 Loss is 3766.442238619711\n",
      "Epoch 1359 Loss is 3766.303221639547\n",
      "Epoch 1360 Loss is 3766.1641190906134\n",
      "Epoch 1361 Loss is 3766.0249318897136\n",
      "Epoch 1362 Loss is 3765.885660960628\n",
      "Epoch 1363 Loss is 3765.7463071980233\n",
      "Epoch 1364 Loss is 3765.6068714912863\n",
      "Epoch 1365 Loss is 3765.467354727216\n",
      "Epoch 1366 Loss is 3765.327757798549\n",
      "Epoch 1367 Loss is 3765.1880815536924\n",
      "Epoch 1368 Loss is 3765.0483268205894\n",
      "Epoch 1369 Loss is 3764.9084944136857\n",
      "Epoch 1370 Loss is 3764.7685851465058\n",
      "Epoch 1371 Loss is 3764.628599835929\n",
      "Epoch 1372 Loss is 3764.4885392617775\n",
      "Epoch 1373 Loss is 3764.3484042119962\n",
      "Epoch 1374 Loss is 3764.2081954728487\n",
      "Epoch 1375 Loss is 3764.0679138237792\n",
      "Epoch 1376 Loss is 3763.927560026963\n",
      "Epoch 1377 Loss is 3763.787134831051\n",
      "Epoch 1378 Loss is 3763.646638975482\n",
      "Epoch 1379 Loss is 3763.5060731509247\n",
      "Epoch 1380 Loss is 3763.3654380329954\n",
      "Epoch 1381 Loss is 3763.224734309322\n",
      "Epoch 1382 Loss is 3763.0839626313928\n",
      "Epoch 1383 Loss is 3762.943123645696\n",
      "Epoch 1384 Loss is 3762.802217972519\n",
      "Epoch 1385 Loss is 3762.6612462584576\n",
      "Epoch 1386 Loss is 3762.5202091081305\n",
      "Epoch 1387 Loss is 3762.3791070889984\n",
      "Epoch 1388 Loss is 3762.2379408020897\n",
      "Epoch 1389 Loss is 3762.09671081037\n",
      "Epoch 1390 Loss is 3761.955417629695\n",
      "Epoch 1391 Loss is 3761.8140617716062\n",
      "Epoch 1392 Loss is 3761.6726437057896\n",
      "Epoch 1393 Loss is 3761.5311639259025\n",
      "Epoch 1394 Loss is 3761.3896229407173\n",
      "Epoch 1395 Loss is 3761.248021244639\n",
      "Epoch 1396 Loss is 3761.1063593118997\n",
      "Epoch 1397 Loss is 3760.964637561643\n",
      "Epoch 1398 Loss is 3760.822856422298\n",
      "Epoch 1399 Loss is 3760.681016314648\n",
      "Epoch 1400 Loss is 3760.5391176089747\n",
      "Epoch 1401 Loss is 3760.397160663793\n",
      "Epoch 1402 Loss is 3760.255145813406\n",
      "Epoch 1403 Loss is 3760.1130734106987\n",
      "Epoch 1404 Loss is 3759.970943773622\n",
      "Epoch 1405 Loss is 3759.828757212455\n",
      "Epoch 1406 Loss is 3759.6865140370055\n",
      "Epoch 1407 Loss is 3759.5442145328493\n",
      "Epoch 1408 Loss is 3759.4018589411207\n",
      "Epoch 1409 Loss is 3759.2594475031974\n",
      "Epoch 1410 Loss is 3759.1169804529513\n",
      "Epoch 1411 Loss is 3758.9744580227257\n",
      "Epoch 1412 Loss is 3758.8318804264036\n",
      "Epoch 1413 Loss is 3758.6892478568625\n",
      "Epoch 1414 Loss is 3758.546560486852\n",
      "Epoch 1415 Loss is 3758.403818479267\n",
      "Epoch 1416 Loss is 3758.2610219666403\n",
      "Epoch 1417 Loss is 3758.118171071734\n",
      "Epoch 1418 Loss is 3757.9752659124133\n",
      "Epoch 1419 Loss is 3757.8323065625755\n",
      "Epoch 1420 Loss is 3757.68929308881\n",
      "Epoch 1421 Loss is 3757.5462255768107\n",
      "Epoch 1422 Loss is 3757.403104088013\n",
      "Epoch 1423 Loss is 3757.2599286573436\n",
      "Epoch 1424 Loss is 3757.116699322266\n",
      "Epoch 1425 Loss is 3756.973416065548\n",
      "Epoch 1426 Loss is 3756.830078875135\n",
      "Epoch 1427 Loss is 3756.6866877269576\n",
      "Epoch 1428 Loss is 3756.5432425864515\n",
      "Epoch 1429 Loss is 3756.3997434277644\n",
      "Epoch 1430 Loss is 3756.2561901904005\n",
      "Epoch 1431 Loss is 3756.1125827522255\n",
      "Epoch 1432 Loss is 3755.9689210026695\n",
      "Epoch 1433 Loss is 3755.8252048504924\n",
      "Epoch 1434 Loss is 3755.681434202065\n",
      "Epoch 1435 Loss is 3755.5376089130423\n",
      "Epoch 1436 Loss is 3755.393728855735\n",
      "Epoch 1437 Loss is 3755.2497939113928\n",
      "Epoch 1438 Loss is 3755.105803931881\n",
      "Epoch 1439 Loss is 3754.9617587452803\n",
      "Epoch 1440 Loss is 3754.8176581816647\n",
      "Epoch 1441 Loss is 3754.67350203911\n",
      "Epoch 1442 Loss is 3754.5292901032103\n",
      "Epoch 1443 Loss is 3754.38502214069\n",
      "Epoch 1444 Loss is 3754.240697897301\n",
      "Epoch 1445 Loss is 3754.0963171497347\n",
      "Epoch 1446 Loss is 3753.9518796261686\n",
      "Epoch 1447 Loss is 3753.8073850578\n",
      "Epoch 1448 Loss is 3753.6628332092296\n",
      "Epoch 1449 Loss is 3753.51822378132\n",
      "Epoch 1450 Loss is 3753.373556458021\n",
      "Epoch 1451 Loss is 3753.2288309040528\n",
      "Epoch 1452 Loss is 3753.0840467921903\n",
      "Epoch 1453 Loss is 3752.9392038058577\n",
      "Epoch 1454 Loss is 3752.7943015840406\n",
      "Epoch 1455 Loss is 3752.6493397530357\n",
      "Epoch 1456 Loss is 3752.5043179449067\n",
      "Epoch 1457 Loss is 3752.3592357684774\n",
      "Epoch 1458 Loss is 3752.214092865665\n",
      "Epoch 1459 Loss is 3752.068888842154\n",
      "Epoch 1460 Loss is 3751.923623265071\n",
      "Epoch 1461 Loss is 3751.7782957171453\n",
      "Epoch 1462 Loss is 3751.632905785741\n",
      "Epoch 1463 Loss is 3751.487453030614\n",
      "Epoch 1464 Loss is 3751.341937018696\n",
      "Epoch 1465 Loss is 3751.1963573181974\n",
      "Epoch 1466 Loss is 3751.050713473311\n",
      "Epoch 1467 Loss is 3750.905005046465\n",
      "Epoch 1468 Loss is 3750.7592315578654\n",
      "Epoch 1469 Loss is 3750.6133925130707\n",
      "Epoch 1470 Loss is 3750.4674874153347\n",
      "Epoch 1471 Loss is 3750.3215158031535\n",
      "Epoch 1472 Loss is 3750.17547714876\n",
      "Epoch 1473 Loss is 3750.0293709251687\n",
      "Epoch 1474 Loss is 3749.883196598481\n",
      "Epoch 1475 Loss is 3749.736953654136\n",
      "Epoch 1476 Loss is 3749.5906415704467\n",
      "Epoch 1477 Loss is 3749.444259799889\n",
      "Epoch 1478 Loss is 3749.2978078015376\n",
      "Epoch 1479 Loss is 3749.1512850545\n",
      "Epoch 1480 Loss is 3749.0046910180567\n",
      "Epoch 1481 Loss is 3748.858025128356\n",
      "Epoch 1482 Loss is 3748.7112868114973\n",
      "Epoch 1483 Loss is 3748.564475465399\n",
      "Epoch 1484 Loss is 3748.4175905006314\n",
      "Epoch 1485 Loss is 3748.2706313461276\n",
      "Epoch 1486 Loss is 3748.123597414428\n",
      "Epoch 1487 Loss is 3747.9764880849225\n",
      "Epoch 1488 Loss is 3747.829302777629\n",
      "Epoch 1489 Loss is 3747.682040891108\n",
      "Epoch 1490 Loss is 3747.5347018031803\n",
      "Epoch 1491 Loss is 3747.387284929811\n",
      "Epoch 1492 Loss is 3747.239789680352\n",
      "Epoch 1493 Loss is 3747.0922154570876\n",
      "Epoch 1494 Loss is 3746.944561663316\n",
      "Epoch 1495 Loss is 3746.7968277007276\n",
      "Epoch 1496 Loss is 3746.6490129599697\n",
      "Epoch 1497 Loss is 3746.501116857469\n",
      "Epoch 1498 Loss is 3746.35313878665\n",
      "Epoch 1499 Loss is 3746.2050781401954\n",
      "Epoch 1500 Loss is 3746.0569343027414\n",
      "Epoch 1501 Loss is 3745.9087067071596\n",
      "Epoch 1502 Loss is 3745.7603947710004\n",
      "Epoch 1503 Loss is 3745.6119978985603\n",
      "Epoch 1504 Loss is 3745.4635155207484\n",
      "Epoch 1505 Loss is 3745.314947050767\n",
      "Epoch 1506 Loss is 3745.1662919146647\n",
      "Epoch 1507 Loss is 3745.0175495472045\n",
      "Epoch 1508 Loss is 3744.8687193957344\n",
      "Epoch 1509 Loss is 3744.7198008817527\n",
      "Epoch 1510 Loss is 3744.5707934484726\n",
      "Epoch 1511 Loss is 3744.4216964931716\n",
      "Epoch 1512 Loss is 3744.2725094383795\n",
      "Epoch 1513 Loss is 3744.1232317476515\n",
      "Epoch 1514 Loss is 3743.973862849546\n",
      "Epoch 1515 Loss is 3743.824402142252\n",
      "Epoch 1516 Loss is 3743.6748490981895\n",
      "Epoch 1517 Loss is 3743.525203183214\n",
      "Epoch 1518 Loss is 3743.375463851902\n",
      "Epoch 1519 Loss is 3743.2256305697747\n",
      "Epoch 1520 Loss is 3743.0757028232188\n",
      "Epoch 1521 Loss is 3742.925680108065\n",
      "Epoch 1522 Loss is 3742.7755619404516\n",
      "Epoch 1523 Loss is 3742.6253478371946\n",
      "Epoch 1524 Loss is 3742.475037296789\n",
      "Epoch 1525 Loss is 3742.324629845282\n",
      "Epoch 1526 Loss is 3742.174125019854\n",
      "Epoch 1527 Loss is 3742.0235223672075\n",
      "Epoch 1528 Loss is 3741.872821454723\n",
      "Epoch 1529 Loss is 3741.7220218460634\n",
      "Epoch 1530 Loss is 3741.5711230740294\n",
      "Epoch 1531 Loss is 3741.420124740078\n",
      "Epoch 1532 Loss is 3741.269026449005\n",
      "Epoch 1533 Loss is 3741.117827821479\n",
      "Epoch 1534 Loss is 3740.9665285171372\n",
      "Epoch 1535 Loss is 3740.815128214297\n",
      "Epoch 1536 Loss is 3740.663626584233\n",
      "Epoch 1537 Loss is 3740.5120233438647\n",
      "Epoch 1538 Loss is 3740.3603182032753\n",
      "Epoch 1539 Loss is 3740.2085108447664\n",
      "Epoch 1540 Loss is 3740.056600941513\n",
      "Epoch 1541 Loss is 3739.9045882097007\n",
      "Epoch 1542 Loss is 3739.752472411691\n",
      "Epoch 1543 Loss is 3739.6002533298615\n",
      "Epoch 1544 Loss is 3739.4479307457136\n",
      "Epoch 1545 Loss is 3739.2955045047247\n",
      "Epoch 1546 Loss is 3739.142974437256\n",
      "Epoch 1547 Loss is 3738.990340424274\n",
      "Epoch 1548 Loss is 3738.8376023061537\n",
      "Epoch 1549 Loss is 3738.6847600283\n",
      "Epoch 1550 Loss is 3738.5318135489397\n",
      "Epoch 1551 Loss is 3738.378762814724\n",
      "Epoch 1552 Loss is 3738.225607779531\n",
      "Epoch 1553 Loss is 3738.0723484178716\n",
      "Epoch 1554 Loss is 3737.918984745258\n",
      "Epoch 1555 Loss is 3737.765516803639\n",
      "Epoch 1556 Loss is 3737.6119446594776\n",
      "Epoch 1557 Loss is 3737.4582683998433\n",
      "Epoch 1558 Loss is 3737.3044880732473\n",
      "Epoch 1559 Loss is 3737.150603820659\n",
      "Epoch 1560 Loss is 3736.9966157655454\n",
      "Epoch 1561 Loss is 3736.842524046277\n",
      "Epoch 1562 Loss is 3736.6883289250704\n",
      "Epoch 1563 Loss is 3736.534030661968\n",
      "Epoch 1564 Loss is 3736.3796295169773\n",
      "Epoch 1565 Loss is 3736.2251258022284\n",
      "Epoch 1566 Loss is 3736.070519803389\n",
      "Epoch 1567 Loss is 3735.915811820549\n",
      "Epoch 1568 Loss is 3735.7610022357107\n",
      "Epoch 1569 Loss is 3735.606091447281\n",
      "Epoch 1570 Loss is 3735.4510798869815\n",
      "Epoch 1571 Loss is 3735.2959680392783\n",
      "Epoch 1572 Loss is 3735.14075647406\n",
      "Epoch 1573 Loss is 3734.985445786895\n",
      "Epoch 1574 Loss is 3734.830036551651\n",
      "Epoch 1575 Loss is 3734.674529337905\n",
      "Epoch 1576 Loss is 3734.5189247664507\n",
      "Epoch 1577 Loss is 3734.363223502013\n",
      "Epoch 1578 Loss is 3734.207426236955\n",
      "Epoch 1579 Loss is 3734.051533721047\n",
      "Epoch 1580 Loss is 3733.895546751626\n",
      "Epoch 1581 Loss is 3733.7394661332237\n",
      "Epoch 1582 Loss is 3733.5832927103374\n",
      "Epoch 1583 Loss is 3733.4270273457596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1584 Loss is 3733.27067092874\n",
      "Epoch 1585 Loss is 3733.1142244147904\n",
      "Epoch 1586 Loss is 3732.9576888209267\n",
      "Epoch 1587 Loss is 3732.8010651712407\n",
      "Epoch 1588 Loss is 3732.644354498127\n",
      "Epoch 1589 Loss is 3732.4875579246827\n",
      "Epoch 1590 Loss is 3732.3306766843143\n",
      "Epoch 1591 Loss is 3732.173712027615\n",
      "Epoch 1592 Loss is 3732.0166652021862\n",
      "Epoch 1593 Loss is 3731.859537471516\n",
      "Epoch 1594 Loss is 3731.702330183677\n",
      "Epoch 1595 Loss is 3731.545044675571\n",
      "Epoch 1596 Loss is 3731.387682353368\n",
      "Epoch 1597 Loss is 3731.230244674373\n",
      "Epoch 1598 Loss is 3731.072733107016\n",
      "Epoch 1599 Loss is 3730.9151491589737\n",
      "Epoch 1600 Loss is 3730.7574944144694\n",
      "Epoch 1601 Loss is 3730.599770522922\n",
      "Epoch 1602 Loss is 3730.441979100596\n",
      "Epoch 1603 Loss is 3730.2841217803507\n",
      "Epoch 1604 Loss is 3730.126200236749\n",
      "Epoch 1605 Loss is 3729.9682162046774\n",
      "Epoch 1606 Loss is 3729.8101714333034\n",
      "Epoch 1607 Loss is 3729.6520677447756\n",
      "Epoch 1608 Loss is 3729.4939070495648\n",
      "Epoch 1609 Loss is 3729.3356912450645\n",
      "Epoch 1610 Loss is 3729.1774222874674\n",
      "Epoch 1611 Loss is 3729.0191021166565\n",
      "Epoch 1612 Loss is 3728.860732729928\n",
      "Epoch 1613 Loss is 3728.7023161738257\n",
      "Epoch 1614 Loss is 3728.5438545010993\n",
      "Epoch 1615 Loss is 3728.385349786036\n",
      "Epoch 1616 Loss is 3728.2268042506585\n",
      "Epoch 1617 Loss is 3728.068220125166\n",
      "Epoch 1618 Loss is 3727.909599624757\n",
      "Epoch 1619 Loss is 3727.7509450239636\n",
      "Epoch 1620 Loss is 3727.592258627162\n",
      "Epoch 1621 Loss is 3727.4335428111813\n",
      "Epoch 1622 Loss is 3727.2747999437115\n",
      "Epoch 1623 Loss is 3727.1160324419357\n",
      "Epoch 1624 Loss is 3726.9572427712446\n",
      "Epoch 1625 Loss is 3726.7984334149687\n",
      "Epoch 1626 Loss is 3726.6396068842814\n",
      "Epoch 1627 Loss is 3726.4807657235524\n",
      "Epoch 1628 Loss is 3726.321912499301\n",
      "Epoch 1629 Loss is 3726.1630498338914\n",
      "Epoch 1630 Loss is 3726.00418038643\n",
      "Epoch 1631 Loss is 3725.8453068351478\n",
      "Epoch 1632 Loss is 3725.6864319307547\n",
      "Epoch 1633 Loss is 3725.527558442631\n",
      "Epoch 1634 Loss is 3725.3686891848674\n",
      "Epoch 1635 Loss is 3725.2098269660937\n",
      "Epoch 1636 Loss is 3725.050974632793\n",
      "Epoch 1637 Loss is 3724.8921350997543\n",
      "Epoch 1638 Loss is 3724.733311248248\n",
      "Epoch 1639 Loss is 3724.574505995851\n",
      "Epoch 1640 Loss is 3724.415722351154\n",
      "Epoch 1641 Loss is 3724.256963356641\n",
      "Epoch 1642 Loss is 3724.098232067773\n",
      "Epoch 1643 Loss is 3723.9395315690376\n",
      "Epoch 1644 Loss is 3723.7808649465514\n",
      "Epoch 1645 Loss is 3723.622235201842\n",
      "Epoch 1646 Loss is 3723.463645425569\n",
      "Epoch 1647 Loss is 3723.305098764052\n",
      "Epoch 1648 Loss is 3723.1465983236826\n",
      "Epoch 1649 Loss is 3722.9881472531665\n",
      "Epoch 1650 Loss is 3722.8297487348423\n",
      "Epoch 1651 Loss is 3722.6714059722485\n",
      "Epoch 1652 Loss is 3722.513122188672\n",
      "Epoch 1653 Loss is 3722.3549006491394\n",
      "Epoch 1654 Loss is 3722.1967446505837\n",
      "Epoch 1655 Loss is 3722.0386575049674\n",
      "Epoch 1656 Loss is 3721.8806425168923\n",
      "Epoch 1657 Loss is 3721.7227030084823\n",
      "Epoch 1658 Loss is 3721.564842324498\n",
      "Epoch 1659 Loss is 3721.4070638568505\n",
      "Epoch 1660 Loss is 3721.249370939588\n",
      "Epoch 1661 Loss is 3721.0917669826213\n",
      "Epoch 1662 Loss is 3720.934255366197\n",
      "Epoch 1663 Loss is 3720.7768393950096\n",
      "Epoch 1664 Loss is 3720.6195224316407\n",
      "Epoch 1665 Loss is 3720.4623078257696\n",
      "Epoch 1666 Loss is 3720.3051989149835\n",
      "Epoch 1667 Loss is 3720.1481991222836\n",
      "Epoch 1668 Loss is 3719.9913118709846\n",
      "Epoch 1669 Loss is 3719.8345406128465\n",
      "Epoch 1670 Loss is 3719.677888690697\n",
      "Epoch 1671 Loss is 3719.5213594194106\n",
      "Epoch 1672 Loss is 3719.364956130507\n",
      "Epoch 1673 Loss is 3719.2086821843586\n",
      "Epoch 1674 Loss is 3719.052540879531\n",
      "Epoch 1675 Loss is 3718.8965354940005\n",
      "Epoch 1676 Loss is 3718.740669349214\n",
      "Epoch 1677 Loss is 3718.5849457884315\n",
      "Epoch 1678 Loss is 3718.4293682144394\n",
      "Epoch 1679 Loss is 3718.2739398670437\n",
      "Epoch 1680 Loss is 3718.11866399647\n",
      "Epoch 1681 Loss is 3717.963543818568\n",
      "Epoch 1682 Loss is 3717.80858258175\n",
      "Epoch 1683 Loss is 3717.653783465229\n",
      "Epoch 1684 Loss is 3717.499149710912\n",
      "Epoch 1685 Loss is 3717.3446844827895\n",
      "Epoch 1686 Loss is 3717.190390973818\n",
      "Epoch 1687 Loss is 3717.0362723811563\n",
      "Epoch 1688 Loss is 3716.882331898871\n",
      "Epoch 1689 Loss is 3716.728572676487\n",
      "Epoch 1690 Loss is 3716.5749977265814\n",
      "Epoch 1691 Loss is 3716.421610071692\n",
      "Epoch 1692 Loss is 3716.2684127035686\n",
      "Epoch 1693 Loss is 3716.1154085535113\n",
      "Epoch 1694 Loss is 3715.96260054638\n",
      "Epoch 1695 Loss is 3715.8099916588476\n",
      "Epoch 1696 Loss is 3715.657584824992\n",
      "Epoch 1697 Loss is 3715.50538296596\n",
      "Epoch 1698 Loss is 3715.3533888955944\n",
      "Epoch 1699 Loss is 3715.2016054364767\n",
      "Epoch 1700 Loss is 3715.050035415748\n",
      "Epoch 1701 Loss is 3714.898681529487\n",
      "Epoch 1702 Loss is 3714.7475464567287\n",
      "Epoch 1703 Loss is 3714.596632846261\n",
      "Epoch 1704 Loss is 3714.4459432110125\n",
      "Epoch 1705 Loss is 3714.295480061419\n",
      "Epoch 1706 Loss is 3714.145245974225\n",
      "Epoch 1707 Loss is 3713.995243444335\n",
      "Epoch 1708 Loss is 3713.845474910476\n",
      "Epoch 1709 Loss is 3713.695942777621\n",
      "Epoch 1710 Loss is 3713.5466493745084\n",
      "Epoch 1711 Loss is 3713.397596972841\n",
      "Epoch 1712 Loss is 3713.2487877995677\n",
      "Epoch 1713 Loss is 3713.100224087918\n",
      "Epoch 1714 Loss is 3712.9519079725355\n",
      "Epoch 1715 Loss is 3712.803841564114\n",
      "Epoch 1716 Loss is 3712.65602694431\n",
      "Epoch 1717 Loss is 3712.5084660319276\n",
      "Epoch 1718 Loss is 3712.361160772822\n",
      "Epoch 1719 Loss is 3712.214113170014\n",
      "Epoch 1720 Loss is 3712.0673250449945\n",
      "Epoch 1721 Loss is 3711.920798104823\n",
      "Epoch 1722 Loss is 3711.7745340555407\n",
      "Epoch 1723 Loss is 3711.6285345289\n",
      "Epoch 1724 Loss is 3711.4828011512627\n",
      "Epoch 1725 Loss is 3711.3373354359046\n",
      "Epoch 1726 Loss is 3711.192138822821\n",
      "Epoch 1727 Loss is 3711.047212807504\n",
      "Epoch 1728 Loss is 3710.902558759617\n",
      "Epoch 1729 Loss is 3710.7581780280534\n",
      "Epoch 1730 Loss is 3710.614071902521\n",
      "Epoch 1731 Loss is 3710.4702415821916\n",
      "Epoch 1732 Loss is 3710.3266881986365\n",
      "Epoch 1733 Loss is 3710.1834127628035\n",
      "Epoch 1734 Loss is 3710.0404163595845\n",
      "Epoch 1735 Loss is 3709.897700018595\n",
      "Epoch 1736 Loss is 3709.7552646909007\n",
      "Epoch 1737 Loss is 3709.6131112374883\n",
      "Epoch 1738 Loss is 3709.4712404432835\n",
      "Epoch 1739 Loss is 3709.329653079425\n",
      "Epoch 1740 Loss is 3709.1883498276206\n",
      "Epoch 1741 Loss is 3709.0473313308567\n",
      "Epoch 1742 Loss is 3708.9065981212457\n",
      "Epoch 1743 Loss is 3708.7661506267905\n",
      "Epoch 1744 Loss is 3708.625989227383\n",
      "Epoch 1745 Loss is 3708.4861142582545\n",
      "Epoch 1746 Loss is 3708.3465260401204\n",
      "Epoch 1747 Loss is 3708.2072247353494\n",
      "Epoch 1748 Loss is 3708.068210549039\n",
      "Epoch 1749 Loss is 3707.9294836563336\n",
      "Epoch 1750 Loss is 3707.79104417073\n",
      "Epoch 1751 Loss is 3707.6528921051668\n",
      "Epoch 1752 Loss is 3707.515027411767\n",
      "Epoch 1753 Loss is 3707.377450005243\n",
      "Epoch 1754 Loss is 3707.2401597372696\n",
      "Epoch 1755 Loss is 3707.1031564214136\n",
      "Epoch 1756 Loss is 3706.9664399291696\n",
      "Epoch 1757 Loss is 3706.8300099726303\n",
      "Epoch 1758 Loss is 3706.6938661870827\n",
      "Epoch 1759 Loss is 3706.558008125595\n",
      "Epoch 1760 Loss is 3706.422435287486\n",
      "Epoch 1761 Loss is 3706.2871471441726\n",
      "Epoch 1762 Loss is 3706.1521431263254\n",
      "Epoch 1763 Loss is 3706.017422626515\n",
      "Epoch 1764 Loss is 3705.8829849859926\n",
      "Epoch 1765 Loss is 3705.7488294373925\n",
      "Epoch 1766 Loss is 3705.614955122526\n",
      "Epoch 1767 Loss is 3705.4813612532735\n",
      "Epoch 1768 Loss is 3705.3480469901547\n",
      "Epoch 1769 Loss is 3705.21501138271\n",
      "Epoch 1770 Loss is 3705.0822533939145\n",
      "Epoch 1771 Loss is 3704.9497719487595\n",
      "Epoch 1772 Loss is 3704.817565971196\n",
      "Epoch 1773 Loss is 3704.6856343631007\n",
      "Epoch 1774 Loss is 3704.5539760430765\n",
      "Epoch 1775 Loss is 3704.4225898290897\n",
      "Epoch 1776 Loss is 3704.2914744623886\n",
      "Epoch 1777 Loss is 3704.1606286664282\n",
      "Epoch 1778 Loss is 3704.030051136753\n",
      "Epoch 1779 Loss is 3703.8997405524783\n",
      "Epoch 1780 Loss is 3703.76969560844\n",
      "Epoch 1781 Loss is 3703.6399148467062\n",
      "Epoch 1782 Loss is 3703.5103968779395\n",
      "Epoch 1783 Loss is 3703.381140261074\n",
      "Epoch 1784 Loss is 3703.2521434368964\n",
      "Epoch 1785 Loss is 3703.1234048016618\n",
      "Epoch 1786 Loss is 3702.9949227729344\n",
      "Epoch 1787 Loss is 3702.866695697438\n",
      "Epoch 1788 Loss is 3702.7387219395587\n",
      "Epoch 1789 Loss is 3702.6109997924386\n",
      "Epoch 1790 Loss is 3702.483527552598\n",
      "Epoch 1791 Loss is 3702.356303527281\n",
      "Epoch 1792 Loss is 3702.22932590748\n",
      "Epoch 1793 Loss is 3702.102592941347\n",
      "Epoch 1794 Loss is 3701.976102849931\n",
      "Epoch 1795 Loss is 3701.849853774518\n",
      "Epoch 1796 Loss is 3701.7238439058906\n",
      "Epoch 1797 Loss is 3701.598071428169\n",
      "Epoch 1798 Loss is 3701.4725345428083\n",
      "Epoch 1799 Loss is 3701.3472313880548\n",
      "Epoch 1800 Loss is 3701.2221600605794\n",
      "Epoch 1801 Loss is 3701.0973186302726\n",
      "Epoch 1802 Loss is 3700.9727050952297\n",
      "Epoch 1803 Loss is 3700.848317483496\n",
      "Epoch 1804 Loss is 3700.7241538361022\n",
      "Epoch 1805 Loss is 3700.600212211886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1806 Loss is 3700.4764906112405\n",
      "Epoch 1807 Loss is 3700.352986951121\n",
      "Epoch 1808 Loss is 3700.2296991343096\n",
      "Epoch 1809 Loss is 3700.106625173615\n",
      "Epoch 1810 Loss is 3699.9837630631255\n",
      "Epoch 1811 Loss is 3699.861110758562\n",
      "Epoch 1812 Loss is 3699.7386661933506\n",
      "Epoch 1813 Loss is 3699.616427324593\n",
      "Epoch 1814 Loss is 3699.49439214464\n",
      "Epoch 1815 Loss is 3699.372558552895\n",
      "Epoch 1816 Loss is 3699.2509244817775\n",
      "Epoch 1817 Loss is 3699.1294879540615\n",
      "Epoch 1818 Loss is 3699.0082469742138\n",
      "Epoch 1819 Loss is 3698.8871994727674\n",
      "Epoch 1820 Loss is 3698.766343434393\n",
      "Epoch 1821 Loss is 3698.645676857857\n",
      "Epoch 1822 Loss is 3698.5251977393496\n",
      "Epoch 1823 Loss is 3698.4049040503937\n",
      "Epoch 1824 Loss is 3698.284793824678\n",
      "Epoch 1825 Loss is 3698.164865063888\n",
      "Epoch 1826 Loss is 3698.045115789612\n",
      "Epoch 1827 Loss is 3697.9255440439006\n",
      "Epoch 1828 Loss is 3697.806147880449\n",
      "Epoch 1829 Loss is 3697.6869253256746\n",
      "Epoch 1830 Loss is 3697.5678744429233\n",
      "Epoch 1831 Loss is 3697.448993343156\n",
      "Epoch 1832 Loss is 3697.3302801508157\n",
      "Epoch 1833 Loss is 3697.211732973736\n",
      "Epoch 1834 Loss is 3697.093349952904\n",
      "Epoch 1835 Loss is 3696.975129303268\n",
      "Epoch 1836 Loss is 3696.857069228725\n",
      "Epoch 1837 Loss is 3696.7391679327166\n",
      "Epoch 1838 Loss is 3696.621423646501\n",
      "Epoch 1839 Loss is 3696.503834618447\n",
      "Epoch 1840 Loss is 3696.386399139303\n",
      "Epoch 1841 Loss is 3696.2691156115447\n",
      "Epoch 1842 Loss is 3696.151982545755\n",
      "Epoch 1843 Loss is 3696.0349982854973\n",
      "Epoch 1844 Loss is 3695.9181611213335\n",
      "Epoch 1845 Loss is 3695.8014694632875\n",
      "Epoch 1846 Loss is 3695.684921796355\n",
      "Epoch 1847 Loss is 3695.5685166287585\n",
      "Epoch 1848 Loss is 3695.4522524196905\n",
      "Epoch 1849 Loss is 3695.3361276349524\n",
      "Epoch 1850 Loss is 3695.220140890492\n",
      "Epoch 1851 Loss is 3695.1042907884957\n",
      "Epoch 1852 Loss is 3694.988575931049\n",
      "Epoch 1853 Loss is 3694.8729949229173\n",
      "Epoch 1854 Loss is 3694.7575464213264\n",
      "Epoch 1855 Loss is 3694.6422291554654\n",
      "Epoch 1856 Loss is 3694.52704194933\n",
      "Epoch 1857 Loss is 3694.4119835616802\n",
      "Epoch 1858 Loss is 3694.297052849523\n",
      "Epoch 1859 Loss is 3694.1822486653323\n",
      "Epoch 1860 Loss is 3694.0675698605614\n",
      "Epoch 1861 Loss is 3693.95301529922\n",
      "Epoch 1862 Loss is 3693.838583817056\n",
      "Epoch 1863 Loss is 3693.7242743204206\n",
      "Epoch 1864 Loss is 3693.610085819055\n",
      "Epoch 1865 Loss is 3693.496017257899\n",
      "Epoch 1866 Loss is 3693.3820676524274\n",
      "Epoch 1867 Loss is 3693.268236025027\n",
      "Epoch 1868 Loss is 3693.1545215319443\n",
      "Epoch 1869 Loss is 3693.0409232277557\n",
      "Epoch 1870 Loss is 3692.9274402596448\n",
      "Epoch 1871 Loss is 3692.8140718537775\n",
      "Epoch 1872 Loss is 3692.7008172870437\n",
      "Epoch 1873 Loss is 3692.5876758362124\n",
      "Epoch 1874 Loss is 3692.4746468363364\n",
      "Epoch 1875 Loss is 3692.3617296026887\n",
      "Epoch 1876 Loss is 3692.248923502212\n",
      "Epoch 1877 Loss is 3692.1362280415583\n",
      "Epoch 1878 Loss is 3692.0236427045106\n",
      "Epoch 1879 Loss is 3691.911166992494\n",
      "Epoch 1880 Loss is 3691.798800447551\n",
      "Epoch 1881 Loss is 3691.686542556369\n",
      "Epoch 1882 Loss is 3691.574392929713\n",
      "Epoch 1883 Loss is 3691.4623512073044\n",
      "Epoch 1884 Loss is 3691.35041707861\n",
      "Epoch 1885 Loss is 3691.238590269729\n",
      "Epoch 1886 Loss is 3691.126870560707\n",
      "Epoch 1887 Loss is 3691.0152577173762\n",
      "Epoch 1888 Loss is 3690.903751574233\n",
      "Epoch 1889 Loss is 3690.792351942283\n",
      "Epoch 1890 Loss is 3690.6810587939794\n",
      "Epoch 1891 Loss is 3690.569872078976\n",
      "Epoch 1892 Loss is 3690.4587916580276\n",
      "Epoch 1893 Loss is 3690.34781766743\n",
      "Epoch 1894 Loss is 3690.2369502162883\n",
      "Epoch 1895 Loss is 3690.1261894385198\n",
      "Epoch 1896 Loss is 3690.0155355307534\n",
      "Epoch 1897 Loss is 3689.90498854831\n",
      "Epoch 1898 Loss is 3689.7945485894193\n",
      "Epoch 1899 Loss is 3689.684215769445\n",
      "Epoch 1900 Loss is 3689.5739902505597\n",
      "Epoch 1901 Loss is 3689.463872270465\n",
      "Epoch 1902 Loss is 3689.353862073682\n",
      "Epoch 1903 Loss is 3689.2439599254058\n",
      "Epoch 1904 Loss is 3689.1341660634143\n",
      "Epoch 1905 Loss is 3689.0244807901836\n",
      "Epoch 1906 Loss is 3688.9149045047843\n",
      "Epoch 1907 Loss is 3688.8054376421383\n",
      "Epoch 1908 Loss is 3688.6960806147563\n",
      "Epoch 1909 Loss is 3688.586833683964\n",
      "Epoch 1910 Loss is 3688.477697208322\n",
      "Epoch 1911 Loss is 3688.3686715678955\n",
      "Epoch 1912 Loss is 3688.2597572140266\n",
      "Epoch 1913 Loss is 3688.150954626264\n",
      "Epoch 1914 Loss is 3688.0422642838157\n",
      "Epoch 1915 Loss is 3687.9336866349545\n",
      "Epoch 1916 Loss is 3687.8252222218002\n",
      "Epoch 1917 Loss is 3687.716871609411\n",
      "Epoch 1918 Loss is 3687.6086354462345\n",
      "Epoch 1919 Loss is 3687.5005143900426\n",
      "Epoch 1920 Loss is 3687.392508954818\n",
      "Epoch 1921 Loss is 3687.2846198856714\n",
      "Epoch 1922 Loss is 3687.1768479262073\n",
      "Epoch 1923 Loss is 3687.06919376417\n",
      "Epoch 1924 Loss is 3686.961658069257\n",
      "Epoch 1925 Loss is 3686.8542415216198\n",
      "Epoch 1926 Loss is 3686.7469448010643\n",
      "Epoch 1927 Loss is 3686.6397685411725\n",
      "Epoch 1928 Loss is 3686.532713343007\n",
      "Epoch 1929 Loss is 3686.4257798165377\n",
      "Epoch 1930 Loss is 3686.318968579795\n",
      "Epoch 1931 Loss is 3686.2122802726235\n",
      "Epoch 1932 Loss is 3686.105715478083\n",
      "Epoch 1933 Loss is 3685.999274887308\n",
      "Epoch 1934 Loss is 3685.8929593433854\n",
      "Epoch 1935 Loss is 3685.7867695027844\n",
      "Epoch 1936 Loss is 3685.680706082877\n",
      "Epoch 1937 Loss is 3685.5747697714746\n",
      "Epoch 1938 Loss is 3685.4689612839406\n",
      "Epoch 1939 Loss is 3685.3632813813333\n",
      "Epoch 1940 Loss is 3685.2577307422625\n",
      "Epoch 1941 Loss is 3685.152310038703\n",
      "Epoch 1942 Loss is 3685.0470200102905\n",
      "Epoch 1943 Loss is 3684.941861231735\n",
      "Epoch 1944 Loss is 3684.836834445213\n",
      "Epoch 1945 Loss is 3684.731940414527\n",
      "Epoch 1946 Loss is 3684.6271796669967\n",
      "Epoch 1947 Loss is 3684.522552792029\n",
      "Epoch 1948 Loss is 3684.418060363298\n",
      "Epoch 1949 Loss is 3684.3137029681966\n",
      "Epoch 1950 Loss is 3684.2094812605587\n",
      "Epoch 1951 Loss is 3684.105395885604\n",
      "Epoch 1952 Loss is 3684.001447403307\n",
      "Epoch 1953 Loss is 3683.897636261988\n",
      "Epoch 1954 Loss is 3683.7939628113045\n",
      "Epoch 1955 Loss is 3683.690427356201\n",
      "Epoch 1956 Loss is 3683.5870303119195\n",
      "Epoch 1957 Loss is 3683.483772091446\n",
      "Epoch 1958 Loss is 3683.380652966035\n",
      "Epoch 1959 Loss is 3683.277673088409\n",
      "Epoch 1960 Loss is 3683.174832681421\n",
      "Epoch 1961 Loss is 3683.072131865434\n",
      "Epoch 1962 Loss is 3682.9695708392296\n",
      "Epoch 1963 Loss is 3682.8671498876793\n",
      "Epoch 1964 Loss is 3682.7648690975434\n",
      "Epoch 1965 Loss is 3682.6627285715285\n",
      "Epoch 1966 Loss is 3682.5607283773443\n",
      "Epoch 1967 Loss is 3682.458868676679\n",
      "Epoch 1968 Loss is 3682.357149545206\n",
      "Epoch 1969 Loss is 3682.255570801644\n",
      "Epoch 1970 Loss is 3682.154132278153\n",
      "Epoch 1971 Loss is 3682.052833800007\n",
      "Epoch 1972 Loss is 3681.951675183648\n",
      "Epoch 1973 Loss is 3681.8506563484175\n",
      "Epoch 1974 Loss is 3681.749777220046\n",
      "Epoch 1975 Loss is 3681.649037550155\n",
      "Epoch 1976 Loss is 3681.54843693985\n",
      "Epoch 1977 Loss is 3681.4479750670725\n",
      "Epoch 1978 Loss is 3681.347651795775\n",
      "Epoch 1979 Loss is 3681.2474667586666\n",
      "Epoch 1980 Loss is 3681.1474194986313\n",
      "Epoch 1981 Loss is 3681.047509535551\n",
      "Epoch 1982 Loss is 3680.947736429776\n",
      "Epoch 1983 Loss is 3680.848099812545\n",
      "Epoch 1984 Loss is 3680.748599005937\n",
      "Epoch 1985 Loss is 3680.6492333048745\n",
      "Epoch 1986 Loss is 3680.5500019620254\n",
      "Epoch 1987 Loss is 3680.4509042486293\n",
      "Epoch 1988 Loss is 3680.3519393466618\n",
      "Epoch 1989 Loss is 3680.2531063172923\n",
      "Epoch 1990 Loss is 3680.154404359058\n",
      "Epoch 1991 Loss is 3680.0558324988233\n",
      "Epoch 1992 Loss is 3679.9573896786583\n",
      "Epoch 1993 Loss is 3679.8590747104763\n",
      "Epoch 1994 Loss is 3679.7608863397304\n",
      "Epoch 1995 Loss is 3679.6628233672814\n",
      "Epoch 1996 Loss is 3679.56488451446\n",
      "Epoch 1997 Loss is 3679.467068437358\n",
      "Epoch 1998 Loss is 3679.3693737950193\n",
      "Epoch 1999 Loss is 3679.271799253732\n",
      "Epoch 2000 Loss is 3679.1743434524483\n",
      "Epoch 2001 Loss is 3679.0770049728917\n",
      "Epoch 2002 Loss is 3678.979782242098\n",
      "Epoch 2003 Loss is 3678.882673669146\n",
      "Epoch 2004 Loss is 3678.785677637314\n",
      "Epoch 2005 Loss is 3678.688792435891\n",
      "Epoch 2006 Loss is 3678.5920163683636\n",
      "Epoch 2007 Loss is 3678.4953476093915\n",
      "Epoch 2008 Loss is 3678.3987843085956\n",
      "Epoch 2009 Loss is 3678.302324597154\n",
      "Epoch 2010 Loss is 3678.2059664707986\n",
      "Epoch 2011 Loss is 3678.1097078808402\n",
      "Epoch 2012 Loss is 3678.0135466761444\n",
      "Epoch 2013 Loss is 3677.9174806308156\n",
      "Epoch 2014 Loss is 3677.8215074723466\n",
      "Epoch 2015 Loss is 3677.725624864479\n",
      "Epoch 2016 Loss is 3677.629830447238\n",
      "Epoch 2017 Loss is 3677.534121911761\n",
      "Epoch 2018 Loss is 3677.4384969056055\n",
      "Epoch 2019 Loss is 3677.3429530463222\n",
      "Epoch 2020 Loss is 3677.2474877716204\n",
      "Epoch 2021 Loss is 3677.152098542985\n",
      "Epoch 2022 Loss is 3677.056782696638\n",
      "Epoch 2023 Loss is 3676.9615375879557\n",
      "Epoch 2024 Loss is 3676.8663605812685\n",
      "Epoch 2025 Loss is 3676.7712488898123\n",
      "Epoch 2026 Loss is 3676.6761996618184\n",
      "Epoch 2027 Loss is 3676.5812099712207\n",
      "Epoch 2028 Loss is 3676.486276864869\n",
      "Epoch 2029 Loss is 3676.391397249054\n",
      "Epoch 2030 Loss is 3676.2965679523013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2031 Loss is 3676.201785916\n",
      "Epoch 2032 Loss is 3676.1070479930804\n",
      "Epoch 2033 Loss is 3676.0123509157543\n",
      "Epoch 2034 Loss is 3675.917691352106\n",
      "Epoch 2035 Loss is 3675.8230659611427\n",
      "Epoch 2036 Loss is 3675.7284713467725\n",
      "Epoch 2037 Loss is 3675.633903971586\n",
      "Epoch 2038 Loss is 3675.539360304514\n",
      "Epoch 2039 Loss is 3675.4448367622294\n",
      "Epoch 2040 Loss is 3675.3503296699932\n",
      "Epoch 2041 Loss is 3675.2558353194763\n",
      "Epoch 2042 Loss is 3675.161350073016\n",
      "Epoch 2043 Loss is 3675.0668702441926\n",
      "Epoch 2044 Loss is 3674.972392041632\n",
      "Epoch 2045 Loss is 3674.8779116948326\n",
      "Epoch 2046 Loss is 3674.7834252878583\n",
      "Epoch 2047 Loss is 3674.6889288172515\n",
      "Epoch 2048 Loss is 3674.59441829767\n",
      "Epoch 2049 Loss is 3674.4998896035377\n",
      "Epoch 2050 Loss is 3674.4053385509137\n",
      "Epoch 2051 Loss is 3674.3107609526196\n",
      "Epoch 2052 Loss is 3674.216152498892\n",
      "Epoch 2053 Loss is 3674.12150895488\n",
      "Epoch 2054 Loss is 3674.02682607552\n",
      "Epoch 2055 Loss is 3673.9320995225917\n",
      "Epoch 2056 Loss is 3673.8373247831155\n",
      "Epoch 2057 Loss is 3673.74249733699\n",
      "Epoch 2058 Loss is 3673.6476125781933\n",
      "Epoch 2059 Loss is 3673.5526658473004\n",
      "Epoch 2060 Loss is 3673.4576524316817\n",
      "Epoch 2061 Loss is 3673.362567535884\n",
      "Epoch 2062 Loss is 3673.267406314004\n",
      "Epoch 2063 Loss is 3673.1721638808813\n",
      "Epoch 2064 Loss is 3673.0768352575383\n",
      "Epoch 2065 Loss is 3672.9814154088435\n",
      "Epoch 2066 Loss is 3672.88589936479\n",
      "Epoch 2067 Loss is 3672.790282097208\n",
      "Epoch 2068 Loss is 3672.69455838459\n",
      "Epoch 2069 Loss is 3672.598722948743\n",
      "Epoch 2070 Loss is 3672.5027705219736\n",
      "Epoch 2071 Loss is 3672.4066958917233\n",
      "Epoch 2072 Loss is 3672.3104936875366\n",
      "Epoch 2073 Loss is 3672.214158597632\n",
      "Epoch 2074 Loss is 3672.1176852241833\n",
      "Epoch 2075 Loss is 3672.021068118206\n",
      "Epoch 2076 Loss is 3671.9243019513015\n",
      "Epoch 2077 Loss is 3671.8273812552707\n",
      "Epoch 2078 Loss is 3671.7303005805397\n",
      "Epoch 2079 Loss is 3671.633054425868\n",
      "Epoch 2080 Loss is 3671.535637173978\n",
      "Epoch 2081 Loss is 3671.4380432432513\n",
      "Epoch 2082 Loss is 3671.3402670376095\n",
      "Epoch 2083 Loss is 3671.2423029602032\n",
      "Epoch 2084 Loss is 3671.144145405763\n",
      "Epoch 2085 Loss is 3671.0457886099484\n",
      "Epoch 2086 Loss is 3670.947226802955\n",
      "Epoch 2087 Loss is 3670.848454269229\n",
      "Epoch 2088 Loss is 3670.7494652936766\n",
      "Epoch 2089 Loss is 3670.6502541432606\n",
      "Epoch 2090 Loss is 3670.5508150835685\n",
      "Epoch 2091 Loss is 3670.4511425349315\n",
      "Epoch 2092 Loss is 3670.3512308488616\n",
      "Epoch 2093 Loss is 3670.2510744084957\n",
      "Epoch 2094 Loss is 3670.1506676909926\n",
      "Epoch 2095 Loss is 3670.050005124799\n",
      "Epoch 2096 Loss is 3669.949081180321\n",
      "Epoch 2097 Loss is 3669.8478903524815\n",
      "Epoch 2098 Loss is 3669.746427142084\n",
      "Epoch 2099 Loss is 3669.6446861305935\n",
      "Epoch 2100 Loss is 3669.5426619788136\n",
      "Epoch 2101 Loss is 3669.4403493679933\n",
      "Epoch 2102 Loss is 3669.337743095594\n",
      "Epoch 2103 Loss is 3669.2348379930613\n",
      "Epoch 2104 Loss is 3669.1316289210126\n",
      "Epoch 2105 Loss is 3669.028110891087\n",
      "Epoch 2106 Loss is 3668.9242790086837\n",
      "Epoch 2107 Loss is 3668.820128406702\n",
      "Epoch 2108 Loss is 3668.7156543939573\n",
      "Epoch 2109 Loss is 3668.6108523551557\n",
      "Epoch 2110 Loss is 3668.5057177819\n",
      "Epoch 2111 Loss is 3668.4002462886647\n",
      "Epoch 2112 Loss is 3668.2944335297498\n",
      "Epoch 2113 Loss is 3668.188275340979\n",
      "Epoch 2114 Loss is 3668.081767756214\n",
      "Epoch 2115 Loss is 3667.9749068593323\n",
      "Epoch 2116 Loss is 3667.8676889527346\n",
      "Epoch 2117 Loss is 3667.7601104519545\n",
      "Epoch 2118 Loss is 3667.652167868505\n",
      "Epoch 2119 Loss is 3667.5438579523543\n",
      "Epoch 2120 Loss is 3667.4351775694445\n",
      "Epoch 2121 Loss is 3667.3261238213104\n",
      "Epoch 2122 Loss is 3667.2166939702975\n",
      "Epoch 2123 Loss is 3667.1068854563964\n",
      "Epoch 2124 Loss is 3666.996695954739\n",
      "Epoch 2125 Loss is 3666.8861232708846\n",
      "Epoch 2126 Loss is 3666.7751654606304\n",
      "Epoch 2127 Loss is 3666.6638207622805\n",
      "Epoch 2128 Loss is 3666.5520876972714\n",
      "Epoch 2129 Loss is 3666.439964921027\n",
      "Epoch 2130 Loss is 3666.3274512907583\n",
      "Epoch 2131 Loss is 3666.214545868743\n",
      "Epoch 2132 Loss is 3666.1012479317124\n",
      "Epoch 2133 Loss is 3665.987556943786\n",
      "Epoch 2134 Loss is 3665.8734726451603\n",
      "Epoch 2135 Loss is 3665.7589949975845\n",
      "Epoch 2136 Loss is 3665.6441242034643\n",
      "Epoch 2137 Loss is 3665.5288607506695\n",
      "Epoch 2138 Loss is 3665.4132053228795\n",
      "Epoch 2139 Loss is 3665.297158762729\n",
      "Epoch 2140 Loss is 3665.1807221896447\n",
      "Epoch 2141 Loss is 3665.063896948518\n",
      "Epoch 2142 Loss is 3664.946684597492\n",
      "Epoch 2143 Loss is 3664.829086979862\n",
      "Epoch 2144 Loss is 3664.711106146662\n",
      "Epoch 2145 Loss is 3664.592744350669\n",
      "Epoch 2146 Loss is 3664.474004088556\n",
      "Epoch 2147 Loss is 3664.354888086324\n",
      "Epoch 2148 Loss is 3664.2353993203\n",
      "Epoch 2149 Loss is 3664.115540987042\n",
      "Epoch 2150 Loss is 3663.9953165445518\n",
      "Epoch 2151 Loss is 3663.8747296256047\n",
      "Epoch 2152 Loss is 3663.753784109328\n",
      "Epoch 2153 Loss is 3663.6324840524658\n",
      "Epoch 2154 Loss is 3663.510833673642\n",
      "Epoch 2155 Loss is 3663.388837440102\n",
      "Epoch 2156 Loss is 3663.2665000109405\n",
      "Epoch 2157 Loss is 3663.143826238883\n",
      "Epoch 2158 Loss is 3663.020821182896\n",
      "Epoch 2159 Loss is 3662.8974900233534\n",
      "Epoch 2160 Loss is 3662.7738380585574\n",
      "Epoch 2161 Loss is 3662.6498708794916\n",
      "Epoch 2162 Loss is 3662.5255942276835\n",
      "Epoch 2163 Loss is 3662.40101398226\n",
      "Epoch 2164 Loss is 3662.276136210465\n",
      "Epoch 2165 Loss is 3662.150967087615\n",
      "Epoch 2166 Loss is 3662.0255129757666\n",
      "Epoch 2167 Loss is 3661.899780358509\n",
      "Epoch 2168 Loss is 3661.7737758786016\n",
      "Epoch 2169 Loss is 3661.647506289107\n",
      "Epoch 2170 Loss is 3661.520978523938\n",
      "Epoch 2171 Loss is 3661.3941995896353\n",
      "Epoch 2172 Loss is 3661.267176653228\n",
      "Epoch 2173 Loss is 3661.139916977397\n",
      "Epoch 2174 Loss is 3661.0124278955636\n",
      "Epoch 2175 Loss is 3660.8847168487714\n",
      "Epoch 2176 Loss is 3660.7567914091082\n",
      "Epoch 2177 Loss is 3660.628659275161\n",
      "Epoch 2178 Loss is 3660.500328212469\n",
      "Epoch 2179 Loss is 3660.3718059665525\n",
      "Epoch 2180 Loss is 3660.2431002946682\n",
      "Epoch 2181 Loss is 3660.114218974386\n",
      "Epoch 2182 Loss is 3659.9851699339533\n",
      "Epoch 2183 Loss is 3659.8559611158344\n",
      "Epoch 2184 Loss is 3659.7266004835847\n",
      "Epoch 2185 Loss is 3659.5970960275317\n",
      "Epoch 2186 Loss is 3659.4674557600338\n",
      "Epoch 2187 Loss is 3659.3376877636765\n",
      "Epoch 2188 Loss is 3659.20780006558\n",
      "Epoch 2189 Loss is 3659.0778008191637\n",
      "Epoch 2190 Loss is 3658.9476981518765\n",
      "Epoch 2191 Loss is 3658.8175001770246\n",
      "Epoch 2192 Loss is 3658.687215016736\n",
      "Epoch 2193 Loss is 3658.5568507551316\n",
      "Epoch 2194 Loss is 3658.4264155386245\n",
      "Epoch 2195 Loss is 3658.295917447636\n",
      "Epoch 2196 Loss is 3658.1653645215065\n",
      "Epoch 2197 Loss is 3658.034764784863\n",
      "Epoch 2198 Loss is 3657.9041262813\n",
      "Epoch 2199 Loss is 3657.773457006944\n",
      "Epoch 2200 Loss is 3657.6427649128336\n",
      "Epoch 2201 Loss is 3657.5120579403997\n",
      "Epoch 2202 Loss is 3657.3813439276046\n",
      "Epoch 2203 Loss is 3657.250630663078\n",
      "Epoch 2204 Loss is 3657.11992597698\n",
      "Epoch 2205 Loss is 3656.989237582654\n",
      "Epoch 2206 Loss is 3656.858573132419\n",
      "Epoch 2207 Loss is 3656.7279401911283\n",
      "Epoch 2208 Loss is 3656.597346237834\n",
      "Epoch 2209 Loss is 3656.466798728821\n",
      "Epoch 2210 Loss is 3656.336304985382\n",
      "Epoch 2211 Loss is 3656.2058722757765\n",
      "Epoch 2212 Loss is 3656.0755077920594\n",
      "Epoch 2213 Loss is 3655.9452186913804\n",
      "Epoch 2214 Loss is 3655.8150120374094\n",
      "Epoch 2215 Loss is 3655.6848948276443\n",
      "Epoch 2216 Loss is 3655.554873950103\n",
      "Epoch 2217 Loss is 3655.4249562219593\n",
      "Epoch 2218 Loss is 3655.295148365171\n",
      "Epoch 2219 Loss is 3655.165457038824\n",
      "Epoch 2220 Loss is 3655.035888788351\n",
      "Epoch 2221 Loss is 3654.9064501063426\n",
      "Epoch 2222 Loss is 3654.7771474041233\n",
      "Epoch 2223 Loss is 3654.6479869734935\n",
      "Epoch 2224 Loss is 3654.5189750019463\n",
      "Epoch 2225 Loss is 3654.3901176214617\n",
      "Epoch 2226 Loss is 3654.2614208824007\n",
      "Epoch 2227 Loss is 3654.132890727208\n",
      "Epoch 2228 Loss is 3654.0045330240455\n",
      "Epoch 2229 Loss is 3653.8763536611154\n",
      "Epoch 2230 Loss is 3653.7483582347168\n",
      "Epoch 2231 Loss is 3653.6205523603526\n",
      "Epoch 2232 Loss is 3653.4929415301067\n",
      "Epoch 2233 Loss is 3653.3655311323\n",
      "Epoch 2234 Loss is 3653.238326429832\n",
      "Epoch 2235 Loss is 3653.111332625491\n",
      "Epoch 2236 Loss is 3652.9845548087574\n",
      "Epoch 2237 Loss is 3652.8579980044296\n",
      "Epoch 2238 Loss is 3652.7316671577373\n",
      "Epoch 2239 Loss is 3652.6055671261106\n",
      "Epoch 2240 Loss is 3652.479702696302\n",
      "Epoch 2241 Loss is 3652.3540786166095\n",
      "Epoch 2242 Loss is 3652.2286995673717\n",
      "Epoch 2243 Loss is 3652.1035701314545\n",
      "Epoch 2244 Loss is 3651.9786947077646\n",
      "Epoch 2245 Loss is 3651.8540776845534\n",
      "Epoch 2246 Loss is 3651.729723351775\n",
      "Epoch 2247 Loss is 3651.6056360087982\n",
      "Epoch 2248 Loss is 3651.481819844292\n",
      "Epoch 2249 Loss is 3651.358278967523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2250 Loss is 3651.2350173244554\n",
      "Epoch 2251 Loss is 3651.112038778041\n",
      "Epoch 2252 Loss is 3650.9893472900458\n",
      "Epoch 2253 Loss is 3650.866946831402\n",
      "Epoch 2254 Loss is 3650.7448411806413\n",
      "Epoch 2255 Loss is 3650.6230340732136\n",
      "Epoch 2256 Loss is 3650.5015291096383\n",
      "Epoch 2257 Loss is 3650.3803298206562\n",
      "Epoch 2258 Loss is 3650.2594396946315\n",
      "Epoch 2259 Loss is 3650.138862131012\n",
      "Epoch 2260 Loss is 3650.0186005113455\n",
      "Epoch 2261 Loss is 3649.898658150849\n",
      "Epoch 2262 Loss is 3649.7790383722618\n",
      "Epoch 2263 Loss is 3649.6597444446047\n",
      "Epoch 2264 Loss is 3649.54077957547\n",
      "Epoch 2265 Loss is 3649.4221469092145\n",
      "Epoch 2266 Loss is 3649.303849597497\n",
      "Epoch 2267 Loss is 3649.185890648123\n",
      "Epoch 2268 Loss is 3649.068273069182\n",
      "Epoch 2269 Loss is 3648.9509998203434\n",
      "Epoch 2270 Loss is 3648.834073727143\n",
      "Epoch 2271 Loss is 3648.71749759862\n",
      "Epoch 2272 Loss is 3648.6012743042\n",
      "Epoch 2273 Loss is 3648.4854066466314\n",
      "Epoch 2274 Loss is 3648.369897388841\n",
      "Epoch 2275 Loss is 3648.254749307696\n",
      "Epoch 2276 Loss is 3648.1399651025017\n",
      "Epoch 2277 Loss is 3648.0255474907126\n",
      "Epoch 2278 Loss is 3647.9114991574875\n",
      "Epoch 2279 Loss is 3647.7978227154586\n",
      "Epoch 2280 Loss is 3647.684520791608\n",
      "Epoch 2281 Loss is 3647.5715959071567\n",
      "Epoch 2282 Loss is 3647.4590505570336\n",
      "Epoch 2283 Loss is 3647.346887192237\n",
      "Epoch 2284 Loss is 3647.235108318391\n",
      "Epoch 2285 Loss is 3647.123716444474\n",
      "Epoch 2286 Loss is 3647.012714086378\n",
      "Epoch 2287 Loss is 3646.9021037380585\n",
      "Epoch 2288 Loss is 3646.791887916888\n",
      "Epoch 2289 Loss is 3646.6820690128734\n",
      "Epoch 2290 Loss is 3646.572649387669\n",
      "Epoch 2291 Loss is 3646.463631434056\n",
      "Epoch 2292 Loss is 3646.3550174579664\n",
      "Epoch 2293 Loss is 3646.2468097886226\n",
      "Epoch 2294 Loss is 3646.1390108300047\n",
      "Epoch 2295 Loss is 3646.0316229821337\n",
      "Epoch 2296 Loss is 3645.9246485273934\n",
      "Epoch 2297 Loss is 3645.8180897766074\n",
      "Epoch 2298 Loss is 3645.7119490974446\n",
      "Epoch 2299 Loss is 3645.6062287685245\n",
      "Epoch 2300 Loss is 3645.500931103641\n",
      "Epoch 2301 Loss is 3645.3960583511735\n",
      "Epoch 2302 Loss is 3645.291612890258\n",
      "Epoch 2303 Loss is 3645.1875970712613\n",
      "Epoch 2304 Loss is 3645.0840131724776\n",
      "Epoch 2305 Loss is 3644.9808635883305\n",
      "Epoch 2306 Loss is 3644.87815061204\n",
      "Epoch 2307 Loss is 3644.7758765530125\n",
      "Epoch 2308 Loss is 3644.674043798007\n",
      "Epoch 2309 Loss is 3644.5726546993187\n",
      "Epoch 2310 Loss is 3644.471711602013\n",
      "Epoch 2311 Loss is 3644.3712169011465\n",
      "Epoch 2312 Loss is 3644.271172915389\n",
      "Epoch 2313 Loss is 3644.1715821093735\n",
      "Epoch 2314 Loss is 3644.072446946997\n",
      "Epoch 2315 Loss is 3643.9737698651707\n",
      "Epoch 2316 Loss is 3643.8755533114845\n",
      "Epoch 2317 Loss is 3643.7777998783085\n",
      "Epoch 2318 Loss is 3643.6805119926503\n",
      "Epoch 2319 Loss is 3643.583692159525\n",
      "Epoch 2320 Loss is 3643.487342811282\n",
      "Epoch 2321 Loss is 3643.3914664372396\n",
      "Epoch 2322 Loss is 3643.2960655240354\n",
      "Epoch 2323 Loss is 3643.2011425045066\n",
      "Epoch 2324 Loss is 3643.1066999066443\n",
      "Epoch 2325 Loss is 3643.01274023758\n",
      "Epoch 2326 Loss is 3642.9192659354885\n",
      "Epoch 2327 Loss is 3642.826279536444\n",
      "Epoch 2328 Loss is 3642.733783487663\n",
      "Epoch 2329 Loss is 3642.641780321361\n",
      "Epoch 2330 Loss is 3642.55027258004\n",
      "Epoch 2331 Loss is 3642.4592627904017\n",
      "Epoch 2332 Loss is 3642.368753514178\n",
      "Epoch 2333 Loss is 3642.278747335315\n",
      "Epoch 2334 Loss is 3642.1892469754225\n",
      "Epoch 2335 Loss is 3642.1002550773496\n",
      "Epoch 2336 Loss is 3642.0117742955636\n",
      "Epoch 2337 Loss is 3641.923807329417\n",
      "Epoch 2338 Loss is 3641.8363568727377\n",
      "Epoch 2339 Loss is 3641.7494257256144\n",
      "Epoch 2340 Loss is 3641.6630166376763\n",
      "Epoch 2341 Loss is 3641.5771323146632\n",
      "Epoch 2342 Loss is 3641.4917754845574\n",
      "Epoch 2343 Loss is 3641.406948908279\n",
      "Epoch 2344 Loss is 3641.3226553795635\n",
      "Epoch 2345 Loss is 3641.2388975882195\n",
      "Epoch 2346 Loss is 3641.155678328826\n",
      "Epoch 2347 Loss is 3641.073000447692\n",
      "Epoch 2348 Loss is 3640.9908668679764\n",
      "Epoch 2349 Loss is 3640.90928053005\n",
      "Epoch 2350 Loss is 3640.8282443050707\n",
      "Epoch 2351 Loss is 3640.7477610632495\n",
      "Epoch 2352 Loss is 3640.667833746446\n",
      "Epoch 2353 Loss is 3640.588465343589\n",
      "Epoch 2354 Loss is 3640.5096588129686\n",
      "Epoch 2355 Loss is 3640.431417180967\n",
      "Epoch 2356 Loss is 3640.3537435539492\n",
      "Epoch 2357 Loss is 3640.276641000427\n",
      "Epoch 2358 Loss is 3640.2001125339775\n",
      "Epoch 2359 Loss is 3640.1241611826395\n",
      "Epoch 2360 Loss is 3640.0487899338577\n",
      "Epoch 2361 Loss is 3639.974001852367\n",
      "Epoch 2362 Loss is 3639.8997999309413\n",
      "Epoch 2363 Loss is 3639.8261871696036\n",
      "Epoch 2364 Loss is 3639.753166694423\n",
      "Epoch 2365 Loss is 3639.6807416312768\n",
      "Epoch 2366 Loss is 3639.6089150759562\n",
      "Epoch 2367 Loss is 3639.537690202661\n",
      "Epoch 2368 Loss is 3639.467070111418\n",
      "Epoch 2369 Loss is 3639.3970578884864\n",
      "Epoch 2370 Loss is 3639.327656537313\n",
      "Epoch 2371 Loss is 3639.258869144851\n",
      "Epoch 2372 Loss is 3639.190698764016\n",
      "Epoch 2373 Loss is 3639.123148484517\n",
      "Epoch 2374 Loss is 3639.056221417496\n",
      "Epoch 2375 Loss is 3638.989920729884\n",
      "Epoch 2376 Loss is 3638.9242495662324\n",
      "Epoch 2377 Loss is 3638.859211072217\n",
      "Epoch 2378 Loss is 3638.7948084422087\n",
      "Epoch 2379 Loss is 3638.7310448524368\n",
      "Epoch 2380 Loss is 3638.6679235277406\n",
      "Epoch 2381 Loss is 3638.6054476177324\n",
      "Epoch 2382 Loss is 3638.5436203205236\n",
      "Epoch 2383 Loss is 3638.4824447831693\n",
      "Epoch 2384 Loss is 3638.4219241595833\n",
      "Epoch 2385 Loss is 3638.3620616605554\n",
      "Epoch 2386 Loss is 3638.3028603796984\n",
      "Epoch 2387 Loss is 3638.2443234044044\n",
      "Epoch 2388 Loss is 3638.1864538038335\n",
      "Epoch 2389 Loss is 3638.129254683834\n",
      "Epoch 2390 Loss is 3638.0727290769682\n",
      "Epoch 2391 Loss is 3638.0168801191226\n",
      "Epoch 2392 Loss is 3637.961710952195\n",
      "Epoch 2393 Loss is 3637.907224618624\n",
      "Epoch 2394 Loss is 3637.853424196951\n",
      "Epoch 2395 Loss is 3637.8003127491434\n",
      "Epoch 2396 Loss is 3637.7478934088263\n",
      "Epoch 2397 Loss is 3637.6961693501416\n",
      "Epoch 2398 Loss is 3637.645143709572\n",
      "Epoch 2399 Loss is 3637.594819473581\n",
      "Epoch 2400 Loss is 3637.545199687188\n",
      "Epoch 2401 Loss is 3637.496287368447\n",
      "Epoch 2402 Loss is 3637.4480855121333\n",
      "Epoch 2403 Loss is 3637.4005971284237\n",
      "Epoch 2404 Loss is 3637.3538251285577\n",
      "Epoch 2405 Loss is 3637.3077724262384\n",
      "Epoch 2406 Loss is 3637.2624420136735\n",
      "Epoch 2407 Loss is 3637.2178368128593\n",
      "Epoch 2408 Loss is 3637.1739597594587\n",
      "Epoch 2409 Loss is 3637.1308136549133\n",
      "Epoch 2410 Loss is 3637.0884013040413\n",
      "Epoch 2411 Loss is 3637.0467255324875\n",
      "Epoch 2412 Loss is 3637.0057890709513\n",
      "Epoch 2413 Loss is 3636.965594579744\n",
      "Epoch 2414 Loss is 3636.9261447799886\n",
      "Epoch 2415 Loss is 3636.8874424041\n",
      "Epoch 2416 Loss is 3636.8494901604745\n",
      "Epoch 2417 Loss is 3636.8122907232805\n",
      "Epoch 2418 Loss is 3636.7758466979994\n",
      "Epoch 2419 Loss is 3636.7401606022104\n",
      "Epoch 2420 Loss is 3636.7052349740634\n",
      "Epoch 2421 Loss is 3636.6710723441306\n",
      "Epoch 2422 Loss is 3636.6376752255064\n",
      "Epoch 2423 Loss is 3636.6050460701176\n",
      "Epoch 2424 Loss is 3636.5731872785564\n",
      "Epoch 2425 Loss is 3636.542101277648\n",
      "Epoch 2426 Loss is 3636.511790384632\n",
      "Epoch 2427 Loss is 3636.4822569672056\n",
      "Epoch 2428 Loss is 3636.453503230327\n",
      "Epoch 2429 Loss is 3636.425531420485\n",
      "Epoch 2430 Loss is 3636.398343780179\n",
      "Epoch 2431 Loss is 3636.3719424294695\n",
      "Epoch 2432 Loss is 3636.346329533281\n",
      "Epoch 2433 Loss is 3636.3215072445146\n",
      "Epoch 2434 Loss is 3636.2974776602186\n",
      "Epoch 2435 Loss is 3636.274242842465\n",
      "Epoch 2436 Loss is 3636.251804823056\n",
      "Epoch 2437 Loss is 3636.230165687204\n",
      "Epoch 2438 Loss is 3636.2093273950863\n",
      "Epoch 2439 Loss is 3636.189291756425\n",
      "Epoch 2440 Loss is 3636.170060624224\n",
      "Epoch 2441 Loss is 3636.1516358754916\n",
      "Epoch 2442 Loss is 3636.1340192897105\n",
      "Epoch 2443 Loss is 3636.1172126217643\n",
      "Epoch 2444 Loss is 3636.1012175470555\n",
      "Epoch 2445 Loss is 3636.0860356791563\n",
      "Epoch 2446 Loss is 3636.0716686033898\n",
      "Epoch 2447 Loss is 3636.058117881709\n",
      "Epoch 2448 Loss is 3636.045385120092\n",
      "Epoch 2449 Loss is 3636.0334718920412\n",
      "Epoch 2450 Loss is 3636.022379766704\n",
      "Epoch 2451 Loss is 3636.0121102146095\n",
      "Epoch 2452 Loss is 3636.0026645965536\n",
      "Epoch 2453 Loss is 3635.9940442653906\n",
      "Epoch 2454 Loss is 3635.9862504744156\n",
      "Epoch 2455 Loss is 3635.9792846563723\n",
      "Epoch 2456 Loss is 3635.973148217317\n",
      "Epoch 2457 Loss is 3635.967842485333\n",
      "Epoch 2458 Loss is 3635.9633687147953\n",
      "Epoch 2459 Loss is 3635.9597280434605\n",
      "Epoch 2460 Loss is 3635.9569216304703\n",
      "Epoch 2461 Loss is 3635.9549505779764\n",
      "Epoch 2462 Loss is 3635.9538160864886\n",
      "Epoch 2463 Loss is 3635.953519195347\n",
      "Epoch 2464 Loss is 3635.9540609171804\n",
      "Epoch 2465 Loss is 3635.9554422334195\n",
      "Epoch 2466 Loss is 3635.9576641079493\n",
      "Epoch 2467 Loss is 3635.9607275462577\n",
      "Epoch 2468 Loss is 3635.9646334607664\n",
      "Epoch 2469 Loss is 3635.9693827935903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2470 Loss is 3635.974976398161\n",
      "Epoch 2471 Loss is 3635.981415157365\n",
      "Epoch 2472 Loss is 3635.9886998745887\n",
      "Epoch 2473 Loss is 3635.996831325765\n",
      "Epoch 2474 Loss is 3636.0058102812177\n",
      "Epoch 2475 Loss is 3636.015637436494\n",
      "Epoch 2476 Loss is 3636.026313532703\n",
      "Epoch 2477 Loss is 3636.037839289278\n",
      "Epoch 2478 Loss is 3636.0502153922725\n",
      "Epoch 2479 Loss is 3636.0634424627715\n",
      "Epoch 2480 Loss is 3636.077521223174\n",
      "Epoch 2481 Loss is 3636.0924523919507\n",
      "Epoch 2482 Loss is 3636.1082365490574\n",
      "Epoch 2483 Loss is 3636.1248742289977\n",
      "Epoch 2484 Loss is 3636.142366062244\n",
      "Epoch 2485 Loss is 3636.160712719584\n",
      "Epoch 2486 Loss is 3636.179914947314\n",
      "Epoch 2487 Loss is 3636.1999732619142\n",
      "Epoch 2488 Loss is 3636.22088827631\n",
      "Epoch 2489 Loss is 3636.242660559854\n",
      "Epoch 2490 Loss is 3636.2652905928376\n",
      "Epoch 2491 Loss is 3636.2887788421667\n",
      "Epoch 2492 Loss is 3636.313125827986\n",
      "Epoch 2493 Loss is 3636.338332042127\n",
      "Epoch 2494 Loss is 3636.3643978082127\n",
      "Epoch 2495 Loss is 3636.3913235542373\n",
      "Epoch 2496 Loss is 3636.419109697711\n",
      "Epoch 2497 Loss is 3636.4477566006344\n",
      "Epoch 2498 Loss is 3636.4772645763896\n",
      "Epoch 2499 Loss is 3636.507633919288\n",
      "Epoch 2500 Loss is 3636.5388650930918\n",
      "Epoch 2501 Loss is 3636.5709585418385\n",
      "Epoch 2502 Loss is 3636.6039146799903\n",
      "Epoch 2503 Loss is 3636.6377338836296\n",
      "Epoch 2504 Loss is 3636.6724163959543\n",
      "Epoch 2505 Loss is 3636.7079626228583\n",
      "Epoch 2506 Loss is 3636.7443729146116\n",
      "Epoch 2507 Loss is 3636.781647653406\n",
      "Epoch 2508 Loss is 3636.819787301592\n",
      "Epoch 2509 Loss is 3636.8587921984295\n",
      "Epoch 2510 Loss is 3636.8986627408885\n",
      "Epoch 2511 Loss is 3636.939399278879\n",
      "Epoch 2512 Loss is 3636.9810022523206\n",
      "Epoch 2513 Loss is 3637.0234720551034\n",
      "Epoch 2514 Loss is 3637.066809061944\n",
      "Epoch 2515 Loss is 3637.1110135606127\n",
      "Epoch 2516 Loss is 3637.156085761915\n",
      "Epoch 2517 Loss is 3637.20202588196\n",
      "Epoch 2518 Loss is 3637.248834203664\n",
      "Epoch 2519 Loss is 3637.2965107876585\n",
      "Epoch 2520 Loss is 3637.3450558377544\n",
      "Epoch 2521 Loss is 3637.3944695215687\n",
      "Epoch 2522 Loss is 3637.4447520368412\n",
      "Epoch 2523 Loss is 3637.4959035505944\n",
      "Epoch 2524 Loss is 3637.547924162128\n",
      "Epoch 2525 Loss is 3637.6008139386063\n",
      "Epoch 2526 Loss is 3637.654572991749\n",
      "Epoch 2527 Loss is 3637.709201461186\n",
      "Epoch 2528 Loss is 3637.7646993640215\n",
      "Epoch 2529 Loss is 3637.821066812097\n",
      "Epoch 2530 Loss is 3637.878303788234\n",
      "Epoch 2531 Loss is 3637.9364102709774\n",
      "Epoch 2532 Loss is 3637.995386138217\n",
      "Epoch 2533 Loss is 3638.055231223016\n",
      "Epoch 2534 Loss is 3638.1159453035393\n",
      "Epoch 2535 Loss is 3638.177528127651\n",
      "Epoch 2536 Loss is 3638.239979400416\n",
      "Epoch 2537 Loss is 3638.3032988101995\n",
      "Epoch 2538 Loss is 3638.3674860138017\n",
      "Epoch 2539 Loss is 3638.432540561755\n",
      "Epoch 2540 Loss is 3638.498461963868\n",
      "Epoch 2541 Loss is 3638.5652496631396\n",
      "Epoch 2542 Loss is 3638.632903021138\n",
      "Epoch 2543 Loss is 3638.701421356519\n",
      "Epoch 2544 Loss is 3638.770803808779\n",
      "Epoch 2545 Loss is 3638.8410496581814\n",
      "Epoch 2546 Loss is 3638.912158035209\n",
      "Epoch 2547 Loss is 3638.9841279382968\n",
      "Epoch 2548 Loss is 3639.05695841387\n",
      "Epoch 2549 Loss is 3639.1306483296144\n",
      "Epoch 2550 Loss is 3639.2051964597435\n",
      "Epoch 2551 Loss is 3639.2806014437265\n",
      "Epoch 2552 Loss is 3639.356861859751\n",
      "Epoch 2553 Loss is 3639.4339761892884\n",
      "Epoch 2554 Loss is 3639.511942924055\n",
      "Epoch 2555 Loss is 3639.5907602624115\n",
      "Epoch 2556 Loss is 3639.6704263402694\n",
      "Epoch 2557 Loss is 3639.750939211807\n",
      "Epoch 2558 Loss is 3639.8322968660864\n",
      "Epoch 2559 Loss is 3639.9144971582828\n",
      "Epoch 2560 Loss is 3639.9975377714863\n",
      "Epoch 2561 Loss is 3640.0814163558475\n",
      "Epoch 2562 Loss is 3640.1661304461627\n",
      "Epoch 2563 Loss is 3640.251677416069\n",
      "Epoch 2564 Loss is 3640.3380545707128\n",
      "Epoch 2565 Loss is 3640.42525901178\n",
      "Epoch 2566 Loss is 3640.5132877824094\n",
      "Epoch 2567 Loss is 3640.6021377299476\n",
      "Epoch 2568 Loss is 3640.6918057729195\n",
      "Epoch 2569 Loss is 3640.782288560237\n",
      "Epoch 2570 Loss is 3640.8735826302245\n",
      "Epoch 2571 Loss is 3640.965684255577\n",
      "Epoch 2572 Loss is 3641.0585897287046\n",
      "Epoch 2573 Loss is 3641.1522951880625\n",
      "Epoch 2574 Loss is 3641.2467965170313\n",
      "Epoch 2575 Loss is 3641.3420894724245\n",
      "Epoch 2576 Loss is 3641.4381696721803\n",
      "Epoch 2577 Loss is 3641.535032620849\n",
      "Epoch 2578 Loss is 3641.632673696652\n",
      "Epoch 2579 Loss is 3641.731088186736\n",
      "Epoch 2580 Loss is 3641.830270985519\n",
      "Epoch 2581 Loss is 3641.9302168379354\n",
      "Epoch 2582 Loss is 3642.0309204783043\n",
      "Epoch 2583 Loss is 3642.132376366635\n",
      "Epoch 2584 Loss is 3642.234578838552\n",
      "Epoch 2585 Loss is 3642.3375221635597\n",
      "Epoch 2586 Loss is 3642.4412004129854\n",
      "Epoch 2587 Loss is 3642.545607626392\n",
      "Epoch 2588 Loss is 3642.650737542155\n",
      "Epoch 2589 Loss is 3642.756583756566\n",
      "Epoch 2590 Loss is 3642.8631396132846\n",
      "Epoch 2591 Loss is 3642.970398285092\n",
      "Epoch 2592 Loss is 3643.0783527161166\n",
      "Epoch 2593 Loss is 3643.186995769446\n",
      "Epoch 2594 Loss is 3643.2963202815863\n",
      "Epoch 2595 Loss is 3643.4063189011827\n",
      "Epoch 2596 Loss is 3643.5169839450073\n",
      "Epoch 2597 Loss is 3643.6283076515033\n",
      "Epoch 2598 Loss is 3643.740282015105\n",
      "Epoch 2599 Loss is 3643.8528990871096\n",
      "Epoch 2600 Loss is 3643.966150547079\n",
      "Epoch 2601 Loss is 3644.0800279029154\n",
      "Epoch 2602 Loss is 3644.1945226302087\n",
      "Epoch 2603 Loss is 3644.3096258671776\n",
      "Epoch 2604 Loss is 3644.425328557816\n",
      "Epoch 2605 Loss is 3644.541621588122\n",
      "Epoch 2606 Loss is 3644.658495524106\n",
      "Epoch 2607 Loss is 3644.7759408700103\n",
      "Epoch 2608 Loss is 3644.8939479356727\n",
      "Epoch 2609 Loss is 3645.0125068605967\n",
      "Epoch 2610 Loss is 3645.131607581255\n",
      "Epoch 2611 Loss is 3645.2512400272135\n",
      "Epoch 2612 Loss is 3645.3713940109465\n",
      "Epoch 2613 Loss is 3645.4920590059955\n",
      "Epoch 2614 Loss is 3645.613224462113\n",
      "Epoch 2615 Loss is 3645.734879509135\n",
      "Epoch 2616 Loss is 3645.857013202387\n",
      "Epoch 2617 Loss is 3645.9796144543507\n",
      "Epoch 2618 Loss is 3646.1026720258224\n",
      "Epoch 2619 Loss is 3646.2261745225637\n",
      "Epoch 2620 Loss is 3646.3501102596542\n",
      "Epoch 2621 Loss is 3646.474467427015\n",
      "Epoch 2622 Loss is 3646.5992341043057\n",
      "Epoch 2623 Loss is 3646.7243981809434\n",
      "Epoch 2624 Loss is 3646.849947489089\n",
      "Epoch 2625 Loss is 3646.9758697446987\n",
      "Epoch 2626 Loss is 3647.1021523233685\n",
      "Epoch 2627 Loss is 3647.2287826537963\n",
      "Epoch 2628 Loss is 3647.355748052692\n",
      "Epoch 2629 Loss is 3647.483035716867\n",
      "Epoch 2630 Loss is 3647.6106326585345\n",
      "Epoch 2631 Loss is 3647.7385257727656\n",
      "Epoch 2632 Loss is 3647.866701808284\n",
      "Epoch 2633 Loss is 3647.995147395409\n",
      "Epoch 2634 Loss is 3648.1238490874616\n",
      "Epoch 2635 Loss is 3648.2527933074393\n",
      "Epoch 2636 Loss is 3648.3819663231284\n",
      "Epoch 2637 Loss is 3648.5113542581958\n",
      "Epoch 2638 Loss is 3648.6409431236616\n",
      "Epoch 2639 Loss is 3648.7707188060836\n",
      "Epoch 2640 Loss is 3648.9006672235314\n",
      "Epoch 2641 Loss is 3649.030774163477\n",
      "Epoch 2642 Loss is 3649.161025304683\n",
      "Epoch 2643 Loss is 3649.291406157023\n",
      "Epoch 2644 Loss is 3649.421902279895\n",
      "Epoch 2645 Loss is 3649.5524991996253\n",
      "Epoch 2646 Loss is 3649.683182308645\n",
      "Epoch 2647 Loss is 3649.813936929533\n",
      "Epoch 2648 Loss is 3649.944748357861\n",
      "Epoch 2649 Loss is 3650.0756019272567\n",
      "Epoch 2650 Loss is 3650.206482867775\n",
      "Epoch 2651 Loss is 3650.337376401153\n",
      "Epoch 2652 Loss is 3650.468267788502\n",
      "Epoch 2653 Loss is 3650.5991422334873\n",
      "Epoch 2654 Loss is 3650.7299849476617\n",
      "Epoch 2655 Loss is 3650.8607810309363\n",
      "Epoch 2656 Loss is 3650.991515627239\n",
      "Epoch 2657 Loss is 3651.1221739240095\n",
      "Epoch 2658 Loss is 3651.252741079768\n",
      "Epoch 2659 Loss is 3651.38320225323\n",
      "Epoch 2660 Loss is 3651.5135426186457\n",
      "Epoch 2661 Loss is 3651.6437473224505\n",
      "Epoch 2662 Loss is 3651.7738015846726\n",
      "Epoch 2663 Loss is 3651.903690656702\n",
      "Epoch 2664 Loss is 3652.033399794249\n",
      "Epoch 2665 Loss is 3652.1629143566915\n",
      "Epoch 2666 Loss is 3652.292219720656\n",
      "Epoch 2667 Loss is 3652.4213014009174\n",
      "Epoch 2668 Loss is 3652.55014498203\n",
      "Epoch 2669 Loss is 3652.67873610858\n",
      "Epoch 2670 Loss is 3652.807060441726\n",
      "Epoch 2671 Loss is 3652.93510364698\n",
      "Epoch 2672 Loss is 3653.062851387871\n",
      "Epoch 2673 Loss is 3653.190289415506\n",
      "Epoch 2674 Loss is 3653.317403483387\n",
      "Epoch 2675 Loss is 3653.4441794776917\n",
      "Epoch 2676 Loss is 3653.5706034460063\n",
      "Epoch 2677 Loss is 3653.6966614872927\n",
      "Epoch 2678 Loss is 3653.8223397748734\n",
      "Epoch 2679 Loss is 3653.9476246136282\n",
      "Epoch 2680 Loss is 3654.0725023985333\n",
      "Epoch 2681 Loss is 3654.1969595780465\n",
      "Epoch 2682 Loss is 3654.3209827026517\n",
      "Epoch 2683 Loss is 3654.4445583351558\n",
      "Epoch 2684 Loss is 3654.5676731320514\n",
      "Epoch 2685 Loss is 3654.690313858307\n",
      "Epoch 2686 Loss is 3654.8124674208634\n",
      "Epoch 2687 Loss is 3654.9341209050667\n",
      "Epoch 2688 Loss is 3655.0552615074957\n",
      "Epoch 2689 Loss is 3655.175876546735\n",
      "Epoch 2690 Loss is 3655.295953444412\n",
      "Epoch 2691 Loss is 3655.41547970602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2692 Loss is 3655.5344428890467\n",
      "Epoch 2693 Loss is 3655.652830587843\n",
      "Epoch 2694 Loss is 3655.770630524951\n",
      "Epoch 2695 Loss is 3655.8878305997923\n",
      "Epoch 2696 Loss is 3656.0044187622048\n",
      "Epoch 2697 Loss is 3656.1203830792188\n",
      "Epoch 2698 Loss is 3656.2357117185006\n",
      "Epoch 2699 Loss is 3656.3503929291182\n",
      "Epoch 2700 Loss is 3656.464415101865\n",
      "Epoch 2701 Loss is 3656.5777667400416\n",
      "Epoch 2702 Loss is 3656.69043641853\n",
      "Epoch 2703 Loss is 3656.8024127633184\n",
      "Epoch 2704 Loss is 3656.9136845518033\n",
      "Epoch 2705 Loss is 3657.0242407441165\n",
      "Epoch 2706 Loss is 3657.1340704032227\n",
      "Epoch 2707 Loss is 3657.243162581465\n",
      "Epoch 2708 Loss is 3657.3515064472986\n",
      "Epoch 2709 Loss is 3657.4590912413146\n",
      "Epoch 2710 Loss is 3657.565906338183\n",
      "Epoch 2711 Loss is 3657.6719411786785\n",
      "Epoch 2712 Loss is 3657.7771853647578\n",
      "Epoch 2713 Loss is 3657.881628533123\n",
      "Epoch 2714 Loss is 3657.985260482201\n",
      "Epoch 2715 Loss is 3658.088071086839\n",
      "Epoch 2716 Loss is 3658.1900503138872\n",
      "Epoch 2717 Loss is 3658.291188290422\n",
      "Epoch 2718 Loss is 3658.391475115994\n",
      "Epoch 2719 Loss is 3658.4909010470637\n",
      "Epoch 2720 Loss is 3658.5894565254443\n",
      "Epoch 2721 Loss is 3658.687132200885\n",
      "Epoch 2722 Loss is 3658.7839186864444\n",
      "Epoch 2723 Loss is 3658.8798068657584\n",
      "Epoch 2724 Loss is 3658.9747876052356\n",
      "Epoch 2725 Loss is 3659.0688519202613\n",
      "Epoch 2726 Loss is 3659.1619909471324\n",
      "Epoch 2727 Loss is 3659.254196024411\n",
      "Epoch 2728 Loss is 3659.345458527367\n",
      "Epoch 2729 Loss is 3659.435769992036\n",
      "Epoch 2730 Loss is 3659.5251221587014\n",
      "Epoch 2731 Loss is 3659.61350681799\n",
      "Epoch 2732 Loss is 3659.70091590155\n",
      "Epoch 2733 Loss is 3659.7873414918777\n",
      "Epoch 2734 Loss is 3659.8727759219005\n",
      "Epoch 2735 Loss is 3659.9572117454363\n",
      "Epoch 2736 Loss is 3660.0406415740217\n",
      "Epoch 2737 Loss is 3660.123058283001\n",
      "Epoch 2738 Loss is 3660.2044548342037\n",
      "Epoch 2739 Loss is 3660.2848244550178\n",
      "Epoch 2740 Loss is 3660.3641606357037\n",
      "Epoch 2741 Loss is 3660.442457046467\n",
      "Epoch 2742 Loss is 3660.519707633322\n",
      "Epoch 2743 Loss is 3660.595906443411\n",
      "Epoch 2744 Loss is 3660.6710478245172\n",
      "Epoch 2745 Loss is 3660.7451263900284\n",
      "Epoch 2746 Loss is 3660.8181368779356\n",
      "Epoch 2747 Loss is 3660.890074311411\n",
      "Epoch 2748 Loss is 3660.960933974036\n",
      "Epoch 2749 Loss is 3661.0307113783874\n",
      "Epoch 2750 Loss is 3661.099402332147\n",
      "Epoch 2751 Loss is 3661.1670027633095\n",
      "Epoch 2752 Loss is 3661.2335088752334\n",
      "Epoch 2753 Loss is 3661.2989171968647\n",
      "Epoch 2754 Loss is 3661.363224559707\n",
      "Epoch 2755 Loss is 3661.4264280448056\n",
      "Epoch 2756 Loss is 3661.488525084807\n",
      "Epoch 2757 Loss is 3661.5495133253953\n",
      "Epoch 2758 Loss is 3661.6093906779174\n",
      "Epoch 2759 Loss is 3661.6681553235067\n",
      "Epoch 2760 Loss is 3661.7258057316903\n",
      "Epoch 2761 Loss is 3661.782340551389\n",
      "Epoch 2762 Loss is 3661.8377587546306\n",
      "Epoch 2763 Loss is 3661.8920595574978\n",
      "Epoch 2764 Loss is 3661.945242423134\n",
      "Epoch 2765 Loss is 3661.997307109367\n",
      "Epoch 2766 Loss is 3662.048253653103\n",
      "Epoch 2767 Loss is 3662.098082311919\n",
      "Epoch 2768 Loss is 3662.1467935780843\n",
      "Epoch 2769 Loss is 3662.194388151651\n",
      "Epoch 2770 Loss is 3662.2408669382057\n",
      "Epoch 2771 Loss is 3662.2862311157583\n",
      "Epoch 2772 Loss is 3662.330482058426\n",
      "Epoch 2773 Loss is 3662.3736213245\n",
      "Epoch 2774 Loss is 3662.4156506727404\n",
      "Epoch 2775 Loss is 3662.456572086525\n",
      "Epoch 2776 Loss is 3662.4963877521586\n",
      "Epoch 2777 Loss is 3662.535099994002\n",
      "Epoch 2778 Loss is 3662.572711292843\n",
      "Epoch 2779 Loss is 3662.609224288762\n",
      "Epoch 2780 Loss is 3662.6446418145806\n",
      "Epoch 2781 Loss is 3662.6789668875567\n",
      "Epoch 2782 Loss is 3662.712202665039\n",
      "Epoch 2783 Loss is 3662.744352426316\n",
      "Epoch 2784 Loss is 3662.775419550417\n",
      "Epoch 2785 Loss is 3662.805407507031\n",
      "Epoch 2786 Loss is 3662.834319910132\n",
      "Epoch 2787 Loss is 3662.8621604649084\n",
      "Epoch 2788 Loss is 3662.888932985614\n",
      "Epoch 2789 Loss is 3662.9146413277467\n",
      "Epoch 2790 Loss is 3662.9392892945675\n",
      "Epoch 2791 Loss is 3662.9628809106744\n",
      "Epoch 2792 Loss is 3662.9854202392644\n",
      "Epoch 2793 Loss is 3663.0069114253442\n",
      "Epoch 2794 Loss is 3663.0273585962286\n",
      "Epoch 2795 Loss is 3663.046765886205\n",
      "Epoch 2796 Loss is 3663.065137483455\n",
      "Epoch 2797 Loss is 3663.0824775324177\n",
      "Epoch 2798 Loss is 3663.0987901543867\n",
      "Epoch 2799 Loss is 3663.1140794867288\n",
      "Epoch 2800 Loss is 3663.1283497138943\n",
      "Epoch 2801 Loss is 3663.1416049932836\n",
      "Epoch 2802 Loss is 3663.1538495114037\n",
      "Epoch 2803 Loss is 3663.165087393916\n",
      "Epoch 2804 Loss is 3663.175322735719\n",
      "Epoch 2805 Loss is 3663.184559596735\n",
      "Epoch 2806 Loss is 3663.192801958501\n",
      "Epoch 2807 Loss is 3663.2000537004246\n",
      "Epoch 2808 Loss is 3663.2063185929937\n",
      "Epoch 2809 Loss is 3663.2116004535415\n",
      "Epoch 2810 Loss is 3663.21590309422\n",
      "Epoch 2811 Loss is 3663.2192302028684\n",
      "Epoch 2812 Loss is 3663.221585343873\n",
      "Epoch 2813 Loss is 3663.2229720485784\n",
      "Epoch 2814 Loss is 3663.2233936799557\n",
      "Epoch 2815 Loss is 3663.222853672193\n",
      "Epoch 2816 Loss is 3663.221355345248\n",
      "Epoch 2817 Loss is 3663.218901897995\n",
      "Epoch 2818 Loss is 3663.2154963751054\n",
      "Epoch 2819 Loss is 3663.2111417328642\n",
      "Epoch 2820 Loss is 3663.2058407288773\n",
      "Epoch 2821 Loss is 3663.199596104784\n",
      "Epoch 2822 Loss is 3663.192410553117\n",
      "Epoch 2823 Loss is 3663.1842866493084\n",
      "Epoch 2824 Loss is 3663.175226880856\n",
      "Epoch 2825 Loss is 3663.1652335790573\n",
      "Epoch 2826 Loss is 3663.1543090377204\n",
      "Epoch 2827 Loss is 3663.1424553881816\n",
      "Epoch 2828 Loss is 3663.129674715842\n",
      "Epoch 2829 Loss is 3663.115968984945\n",
      "Epoch 2830 Loss is 3663.1013400138436\n",
      "Epoch 2831 Loss is 3663.085789565102\n",
      "Epoch 2832 Loss is 3663.0693193377942\n",
      "Epoch 2833 Loss is 3663.0519309458896\n",
      "Epoch 2834 Loss is 3663.033625953171\n",
      "Epoch 2835 Loss is 3663.0144058253286\n",
      "Epoch 2836 Loss is 3662.994272077211\n",
      "Epoch 2837 Loss is 3662.9732262495295\n",
      "Epoch 2838 Loss is 3662.9512697632194\n",
      "Epoch 2839 Loss is 3662.9284041521178\n",
      "Epoch 2840 Loss is 3662.9046309001988\n",
      "Epoch 2841 Loss is 3662.8799514975008\n",
      "Epoch 2842 Loss is 3662.8543675716583\n",
      "Epoch 2843 Loss is 3662.827880773642\n",
      "Epoch 2844 Loss is 3662.8004928607893\n",
      "Epoch 2845 Loss is 3662.772205769938\n",
      "Epoch 2846 Loss is 3662.7430215733166\n",
      "Epoch 2847 Loss is 3662.7129424711197\n",
      "Epoch 2848 Loss is 3662.681970933149\n",
      "Epoch 2849 Loss is 3662.6501094451155\n",
      "Epoch 2850 Loss is 3662.6173607939263\n",
      "Epoch 2851 Loss is 3662.5837279407942\n",
      "Epoch 2852 Loss is 3662.5492139853563\n",
      "Epoch 2853 Loss is 3662.513822239194\n",
      "Epoch 2854 Loss is 3662.4775562227755\n",
      "Epoch 2855 Loss is 3662.440419645373\n",
      "Epoch 2856 Loss is 3662.402416408541\n",
      "Epoch 2857 Loss is 3662.3635506176042\n",
      "Epoch 2858 Loss is 3662.3238266514677\n",
      "Epoch 2859 Loss is 3662.2832491839404\n",
      "Epoch 2860 Loss is 3662.241823009589\n",
      "Epoch 2861 Loss is 3662.199553128933\n",
      "Epoch 2862 Loss is 3662.1564448339086\n",
      "Epoch 2863 Loss is 3662.112503535728\n",
      "Epoch 2864 Loss is 3662.0677346293473\n",
      "Epoch 2865 Loss is 3662.022143807425\n",
      "Epoch 2866 Loss is 3661.975737061376\n",
      "Epoch 2867 Loss is 3661.92852036188\n",
      "Epoch 2868 Loss is 3661.880499818381\n",
      "Epoch 2869 Loss is 3661.8316818013027\n",
      "Epoch 2870 Loss is 3661.782072743271\n",
      "Epoch 2871 Loss is 3661.7316791605003\n",
      "Epoch 2872 Loss is 3661.680507703581\n",
      "Epoch 2873 Loss is 3661.6285649689416\n",
      "Epoch 2874 Loss is 3661.5758576059707\n",
      "Epoch 2875 Loss is 3661.522392361002\n",
      "Epoch 2876 Loss is 3661.4681759522623\n",
      "Epoch 2877 Loss is 3661.4132151880626\n",
      "Epoch 2878 Loss is 3661.357516819243\n",
      "Epoch 2879 Loss is 3661.301087730166\n",
      "Epoch 2880 Loss is 3661.2439347560794\n",
      "Epoch 2881 Loss is 3661.1860645909605\n",
      "Epoch 2882 Loss is 3661.127483953445\n",
      "Epoch 2883 Loss is 3661.0681995629643\n",
      "Epoch 2884 Loss is 3661.0082181410294\n",
      "Epoch 2885 Loss is 3660.9475463479785\n",
      "Epoch 2886 Loss is 3660.8861908082213\n",
      "Epoch 2887 Loss is 3660.8241581579123\n",
      "Epoch 2888 Loss is 3660.761455088506\n",
      "Epoch 2889 Loss is 3660.6980881784725\n",
      "Epoch 2890 Loss is 3660.634063996225\n",
      "Epoch 2891 Loss is 3660.56938906413\n",
      "Epoch 2892 Loss is 3660.504069868021\n",
      "Epoch 2893 Loss is 3660.4381129086146\n",
      "Epoch 2894 Loss is 3660.371524793617\n",
      "Epoch 2895 Loss is 3660.3043120982093\n",
      "Epoch 2896 Loss is 3660.2364812818337\n",
      "Epoch 2897 Loss is 3660.168038814645\n",
      "Epoch 2898 Loss is 3660.098991157475\n",
      "Epoch 2899 Loss is 3660.029344792114\n",
      "Epoch 2900 Loss is 3659.9591061881533\n",
      "Epoch 2901 Loss is 3659.8882818611205\n",
      "Epoch 2902 Loss is 3659.81687831325\n",
      "Epoch 2903 Loss is 3659.744902023694\n",
      "Epoch 2904 Loss is 3659.672359595993\n",
      "Epoch 2905 Loss is 3659.5992575528203\n",
      "Epoch 2906 Loss is 3659.525602570967\n",
      "Epoch 2907 Loss is 3659.4514014112924\n",
      "Epoch 2908 Loss is 3659.376660780452\n",
      "Epoch 2909 Loss is 3659.301387522699\n",
      "Epoch 2910 Loss is 3659.225588551183\n",
      "Epoch 2911 Loss is 3659.149270799967\n",
      "Epoch 2912 Loss is 3659.072441167742\n",
      "Epoch 2913 Loss is 3658.995106760214\n",
      "Epoch 2914 Loss is 3658.9172747162024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2915 Loss is 3658.8389522103644\n",
      "Epoch 2916 Loss is 3658.7601466005253\n",
      "Epoch 2917 Loss is 3658.6808654670785\n",
      "Epoch 2918 Loss is 3658.601117399228\n",
      "Epoch 2919 Loss is 3658.520910765007\n",
      "Epoch 2920 Loss is 3658.4402538529016\n",
      "Epoch 2921 Loss is 3658.359154776027\n",
      "Epoch 2922 Loss is 3658.277621743871\n",
      "Epoch 2923 Loss is 3658.1956629161523\n",
      "Epoch 2924 Loss is 3658.1132866161606\n",
      "Epoch 2925 Loss is 3658.0305012201047\n",
      "Epoch 2926 Loss is 3657.9473153223207\n",
      "Epoch 2927 Loss is 3657.8637376439992\n",
      "Epoch 2928 Loss is 3657.7797770814263\n",
      "Epoch 2929 Loss is 3657.695442554311\n",
      "Epoch 2930 Loss is 3657.6107431216187\n",
      "Epoch 2931 Loss is 3657.5256880476777\n",
      "Epoch 2932 Loss is 3657.4402866649016\n",
      "Epoch 2933 Loss is 3657.3545483959256\n",
      "Epoch 2934 Loss is 3657.2684828320266\n",
      "Epoch 2935 Loss is 3657.182099745217\n",
      "Epoch 2936 Loss is 3657.0954089928555\n",
      "Epoch 2937 Loss is 3657.0084205053863\n",
      "Epoch 2938 Loss is 3656.921144355958\n",
      "Epoch 2939 Loss is 3656.833590765565\n",
      "Epoch 2940 Loss is 3656.7457700239634\n",
      "Epoch 2941 Loss is 3656.6576925465474\n",
      "Epoch 2942 Loss is 3656.5693687553157\n",
      "Epoch 2943 Loss is 3656.480809101029\n",
      "Epoch 2944 Loss is 3656.392024037593\n",
      "Epoch 2945 Loss is 3656.3030241006713\n",
      "Epoch 2946 Loss is 3656.213819810227\n",
      "Epoch 2947 Loss is 3656.1244217853055\n",
      "Epoch 2948 Loss is 3656.034840672558\n",
      "Epoch 2949 Loss is 3655.9450870768665\n",
      "Epoch 2950 Loss is 3655.855171461367\n",
      "Epoch 2951 Loss is 3655.765104223547\n",
      "Epoch 2952 Loss is 3655.674895673429\n",
      "Epoch 2953 Loss is 3655.5845560721136\n",
      "Epoch 2954 Loss is 3655.494095581073\n",
      "Epoch 2955 Loss is 3655.4035242035984\n",
      "Epoch 2956 Loss is 3655.31285182479\n",
      "Epoch 2957 Loss is 3655.222088232446\n",
      "Epoch 2958 Loss is 3655.1312430927014\n",
      "Epoch 2959 Loss is 3655.0403259479554\n",
      "Epoch 2960 Loss is 3654.9493461536335\n",
      "Epoch 2961 Loss is 3654.8583128926016\n",
      "Epoch 2962 Loss is 3654.7672352157274\n",
      "Epoch 2963 Loss is 3654.6761219184546\n",
      "Epoch 2964 Loss is 3654.5849816469126\n",
      "Epoch 2965 Loss is 3654.4938228152\n",
      "Epoch 2966 Loss is 3654.40265366619\n",
      "Epoch 2967 Loss is 3654.311482247691\n",
      "Epoch 2968 Loss is 3654.220316444138\n",
      "Epoch 2969 Loss is 3654.1291640069376\n",
      "Epoch 2970 Loss is 3654.038032477791\n",
      "Epoch 2971 Loss is 3653.9469291328487\n",
      "Epoch 2972 Loss is 3653.855860949478\n",
      "Epoch 2973 Loss is 3653.764834828335\n",
      "Epoch 2974 Loss is 3653.6738573388266\n",
      "Epoch 2975 Loss is 3653.5829348128395\n",
      "Epoch 2976 Loss is 3653.4920734144225\n",
      "Epoch 2977 Loss is 3653.401279073789\n",
      "Epoch 2978 Loss is 3653.3105574947886\n",
      "Epoch 2979 Loss is 3653.2199142214777\n",
      "Epoch 2980 Loss is 3653.129354617068\n",
      "Epoch 2981 Loss is 3653.0388838097833\n",
      "Epoch 2982 Loss is 3652.94850673922\n",
      "Epoch 2983 Loss is 3652.8582281700965\n",
      "Epoch 2984 Loss is 3652.7680527214025\n",
      "Epoch 2985 Loss is 3652.6779848428646\n",
      "Epoch 2986 Loss is 3652.5880286969796\n",
      "Epoch 2987 Loss is 3652.4981882931993\n",
      "Epoch 2988 Loss is 3652.4084674678174\n",
      "Epoch 2989 Loss is 3652.3188698074523\n",
      "Epoch 2990 Loss is 3652.229398843405\n",
      "Epoch 2991 Loss is 3652.140057977229\n",
      "Epoch 2992 Loss is 3652.050850396961\n",
      "Epoch 2993 Loss is 3651.961779086855\n",
      "Epoch 2994 Loss is 3651.8728468816967\n",
      "Epoch 2995 Loss is 3651.784056476425\n",
      "Epoch 2996 Loss is 3651.695410421219\n",
      "Epoch 2997 Loss is 3651.606911095789\n",
      "Epoch 2998 Loss is 3651.518560725146\n",
      "Epoch 2999 Loss is 3651.430361420081\n",
      "Epoch 3000 Loss is 3651.342315228796\n",
      "Epoch 3001 Loss is 3651.2544240346865\n",
      "Epoch 3002 Loss is 3651.1666895340363\n",
      "Epoch 3003 Loss is 3651.079113256644\n",
      "Epoch 3004 Loss is 3650.991696628492\n",
      "Epoch 3005 Loss is 3650.9044409389076\n",
      "Epoch 3006 Loss is 3650.817347313536\n",
      "Epoch 3007 Loss is 3650.730416865597\n",
      "Epoch 3008 Loss is 3650.643650528251\n",
      "Epoch 3009 Loss is 3650.557049144982\n",
      "Epoch 3010 Loss is 3650.470613429526\n",
      "Epoch 3011 Loss is 3650.384343978965\n",
      "Epoch 3012 Loss is 3650.298241311915\n",
      "Epoch 3013 Loss is 3650.212305830931\n",
      "Epoch 3014 Loss is 3650.1265379333045\n",
      "Epoch 3015 Loss is 3650.0409379978055\n",
      "Epoch 3016 Loss is 3649.955506313433\n",
      "Epoch 3017 Loss is 3649.8702431611428\n",
      "Epoch 3018 Loss is 3649.7851488187894\n",
      "Epoch 3019 Loss is 3649.7002235736636\n",
      "Epoch 3020 Loss is 3649.615467690761\n",
      "Epoch 3021 Loss is 3649.530881414539\n",
      "Epoch 3022 Loss is 3649.4464649658653\n",
      "Epoch 3023 Loss is 3649.3622186337475\n",
      "Epoch 3024 Loss is 3649.278142709134\n",
      "Epoch 3025 Loss is 3649.194237544073\n",
      "Epoch 3026 Loss is 3649.110503587001\n",
      "Epoch 3027 Loss is 3649.0269413497604\n",
      "Epoch 3028 Loss is 3648.943551327738\n",
      "Epoch 3029 Loss is 3648.86033424318\n",
      "Epoch 3030 Loss is 3648.777290690358\n",
      "Epoch 3031 Loss is 3648.6944212604453\n",
      "Epoch 3032 Loss is 3648.611726628188\n",
      "Epoch 3033 Loss is 3648.5292075509037\n",
      "Epoch 3034 Loss is 3648.446864815048\n",
      "Epoch 3035 Loss is 3648.364699164174\n",
      "Epoch 3036 Loss is 3648.2827115317928\n",
      "Epoch 3037 Loss is 3648.2009027978565\n",
      "Epoch 3038 Loss is 3648.119273855106\n",
      "Epoch 3039 Loss is 3648.0378256519407\n",
      "Epoch 3040 Loss is 3647.9565591659925\n",
      "Epoch 3041 Loss is 3647.875475375841\n",
      "Epoch 3042 Loss is 3647.7945752903984\n",
      "Epoch 3043 Loss is 3647.713859918652\n",
      "Epoch 3044 Loss is 3647.6333302867642\n",
      "Epoch 3045 Loss is 3647.552987468498\n",
      "Epoch 3046 Loss is 3647.472832454639\n",
      "Epoch 3047 Loss is 3647.3928662516687\n",
      "Epoch 3048 Loss is 3647.3130899084167\n",
      "Epoch 3049 Loss is 3647.233504445373\n",
      "Epoch 3050 Loss is 3647.1541109453988\n",
      "Epoch 3051 Loss is 3647.0749103821063\n",
      "Epoch 3052 Loss is 3646.995903798635\n",
      "Epoch 3053 Loss is 3646.9170921560926\n",
      "Epoch 3054 Loss is 3646.838476613364\n",
      "Epoch 3055 Loss is 3646.7600582224695\n",
      "Epoch 3056 Loss is 3646.6818379960596\n",
      "Epoch 3057 Loss is 3646.6038170053794\n",
      "Epoch 3058 Loss is 3646.525996388238\n",
      "Epoch 3059 Loss is 3646.448377347964\n",
      "Epoch 3060 Loss is 3646.370961058568\n",
      "Epoch 3061 Loss is 3646.29374873679\n",
      "Epoch 3062 Loss is 3646.21674153526\n",
      "Epoch 3063 Loss is 3646.139940591803\n",
      "Epoch 3064 Loss is 3646.0633471362285\n",
      "Epoch 3065 Loss is 3645.98696234503\n",
      "Epoch 3066 Loss is 3645.910787473283\n",
      "Epoch 3067 Loss is 3645.8348237870523\n",
      "Epoch 3068 Loss is 3645.7590725365103\n",
      "Epoch 3069 Loss is 3645.68353496571\n",
      "Epoch 3070 Loss is 3645.6082124635923\n",
      "Epoch 3071 Loss is 3645.533106359274\n",
      "Epoch 3072 Loss is 3645.458218146386\n",
      "Epoch 3073 Loss is 3645.383549298707\n",
      "Epoch 3074 Loss is 3645.309101318677\n",
      "Epoch 3075 Loss is 3645.234875827415\n",
      "Epoch 3076 Loss is 3645.1608744717473\n",
      "Epoch 3077 Loss is 3645.087098930966\n",
      "Epoch 3078 Loss is 3645.0135510242853\n",
      "Epoch 3079 Loss is 3644.9402326137615\n",
      "Epoch 3080 Loss is 3644.8671455516032\n",
      "Epoch 3081 Loss is 3644.794291734081\n",
      "Epoch 3082 Loss is 3644.721673077473\n",
      "Epoch 3083 Loss is 3644.649291749619\n",
      "Epoch 3084 Loss is 3644.577149967571\n",
      "Epoch 3085 Loss is 3644.505249913412\n",
      "Epoch 3086 Loss is 3644.433593835682\n",
      "Epoch 3087 Loss is 3644.3621840419087\n",
      "Epoch 3088 Loss is 3644.2910229252575\n",
      "Epoch 3089 Loss is 3644.2201130337944\n",
      "Epoch 3090 Loss is 3644.149457044935\n",
      "Epoch 3091 Loss is 3644.0790576203144\n",
      "Epoch 3092 Loss is 3644.0089174359837\n",
      "Epoch 3093 Loss is 3643.9390391907104\n",
      "Epoch 3094 Loss is 3643.86942566541\n",
      "Epoch 3095 Loss is 3643.80007980432\n",
      "Epoch 3096 Loss is 3643.7310046469047\n",
      "Epoch 3097 Loss is 3643.6622031872867\n",
      "Epoch 3098 Loss is 3643.59367845455\n",
      "Epoch 3099 Loss is 3643.5254335261184\n",
      "Epoch 3100 Loss is 3643.4574715433305\n",
      "Epoch 3101 Loss is 3643.3897956545466\n",
      "Epoch 3102 Loss is 3643.3224091244974\n",
      "Epoch 3103 Loss is 3643.2553152158603\n",
      "Epoch 3104 Loss is 3643.1885171491604\n",
      "Epoch 3105 Loss is 3643.1220181876793\n",
      "Epoch 3106 Loss is 3643.055821685513\n",
      "Epoch 3107 Loss is 3642.989930957304\n",
      "Epoch 3108 Loss is 3642.9243493569816\n",
      "Epoch 3109 Loss is 3642.859080268441\n",
      "Epoch 3110 Loss is 3642.7941270685724\n",
      "Epoch 3111 Loss is 3642.7294931285055\n",
      "Epoch 3112 Loss is 3642.665181755288\n",
      "Epoch 3113 Loss is 3642.601196272448\n",
      "Epoch 3114 Loss is 3642.5375400266716\n",
      "Epoch 3115 Loss is 3642.474216348099\n",
      "Epoch 3116 Loss is 3642.411228513017\n",
      "Epoch 3117 Loss is 3642.348579806331\n",
      "Epoch 3118 Loss is 3642.2862734337964\n",
      "Epoch 3119 Loss is 3642.224312593942\n",
      "Epoch 3120 Loss is 3642.1627004051434\n",
      "Epoch 3121 Loss is 3642.1014398585444\n",
      "Epoch 3122 Loss is 3642.0405339714057\n",
      "Epoch 3123 Loss is 3641.979985734964\n",
      "Epoch 3124 Loss is 3641.9197982082783\n",
      "Epoch 3125 Loss is 3641.8599742452166\n",
      "Epoch 3126 Loss is 3641.8005167272636\n",
      "Epoch 3127 Loss is 3641.7414284529414\n",
      "Epoch 3128 Loss is 3641.682712201117\n",
      "Epoch 3129 Loss is 3641.6243706282917\n",
      "Epoch 3130 Loss is 3641.566406350341\n",
      "Epoch 3131 Loss is 3641.5088219216095\n",
      "Epoch 3132 Loss is 3641.451619842894\n",
      "Epoch 3133 Loss is 3641.3948025371756\n",
      "Epoch 3134 Loss is 3641.3383723549528\n",
      "Epoch 3135 Loss is 3641.2823316306094\n",
      "Epoch 3136 Loss is 3641.2266826172904\n",
      "Epoch 3137 Loss is 3641.171427470412\n",
      "Epoch 3138 Loss is 3641.116568258246\n",
      "Epoch 3139 Loss is 3641.0621068906835\n",
      "Epoch 3140 Loss is 3641.008045546343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3141 Loss is 3640.9543861682682\n",
      "Epoch 3142 Loss is 3640.9011306269135\n",
      "Epoch 3143 Loss is 3640.848280668408\n",
      "Epoch 3144 Loss is 3640.7958378796457\n",
      "Epoch 3145 Loss is 3640.743803902252\n",
      "Epoch 3146 Loss is 3640.692180200378\n",
      "Epoch 3147 Loss is 3640.6409681467967\n",
      "Epoch 3148 Loss is 3640.5901690287883\n",
      "Epoch 3149 Loss is 3640.5397839547463\n",
      "Epoch 3150 Loss is 3640.489813944391\n",
      "Epoch 3151 Loss is 3640.440259805645\n",
      "Epoch 3152 Loss is 3640.39112224499\n",
      "Epoch 3153 Loss is 3640.342401954347\n",
      "Epoch 3154 Loss is 3640.294099525308\n",
      "Epoch 3155 Loss is 3640.246215351072\n",
      "Epoch 3156 Loss is 3640.1987497210703\n",
      "Epoch 3157 Loss is 3640.151702837275\n",
      "Epoch 3158 Loss is 3640.105074766863\n",
      "Epoch 3159 Loss is 3640.0588655019\n",
      "Epoch 3160 Loss is 3640.013074921401\n",
      "Epoch 3161 Loss is 3639.9677027861444\n",
      "Epoch 3162 Loss is 3639.922748798388\n",
      "Epoch 3163 Loss is 3639.8782123731607\n",
      "Epoch 3164 Loss is 3639.8340928809553\n",
      "Epoch 3165 Loss is 3639.7903895371514\n",
      "Epoch 3166 Loss is 3639.7471014604257\n",
      "Epoch 3167 Loss is 3639.704227723503\n",
      "Epoch 3168 Loss is 3639.661767241465\n",
      "Epoch 3169 Loss is 3639.6197187627768\n",
      "Epoch 3170 Loss is 3639.5780808905497\n",
      "Epoch 3171 Loss is 3639.5368521671053\n",
      "Epoch 3172 Loss is 3639.496030904999\n",
      "Epoch 3173 Loss is 3639.4556154229567\n",
      "Epoch 3174 Loss is 3639.4156039156546\n",
      "Epoch 3175 Loss is 3639.375994331915\n",
      "Epoch 3176 Loss is 3639.3367845217927\n",
      "Epoch 3177 Loss is 3639.297972215348\n",
      "Epoch 3178 Loss is 3639.2595548222425\n",
      "Epoch 3179 Loss is 3639.2215295982387\n",
      "Epoch 3180 Loss is 3639.183893773381\n",
      "Epoch 3181 Loss is 3639.146644426484\n",
      "Epoch 3182 Loss is 3639.1097784533285\n",
      "Epoch 3183 Loss is 3639.073292554917\n",
      "Epoch 3184 Loss is 3639.0371832973046\n",
      "Epoch 3185 Loss is 3639.0014469801613\n",
      "Epoch 3186 Loss is 3638.9660797855754\n",
      "Epoch 3187 Loss is 3638.9310778036042\n",
      "Epoch 3188 Loss is 3638.8964369816404\n",
      "Epoch 3189 Loss is 3638.862153138281\n",
      "Epoch 3190 Loss is 3638.8282219714183\n",
      "Epoch 3191 Loss is 3638.7946390149114\n",
      "Epoch 3192 Loss is 3638.761399675981\n",
      "Epoch 3193 Loss is 3638.728499262365\n",
      "Epoch 3194 Loss is 3638.6959327103036\n",
      "Epoch 3195 Loss is 3638.6636948734927\n",
      "Epoch 3196 Loss is 3638.6317804195446\n",
      "Epoch 3197 Loss is 3638.6001838529937\n",
      "Epoch 3198 Loss is 3638.5688996440094\n",
      "Epoch 3199 Loss is 3638.537922019769\n",
      "Epoch 3200 Loss is 3638.5072451665856\n",
      "Epoch 3201 Loss is 3638.4768631053416\n",
      "Epoch 3202 Loss is 3638.446769661312\n",
      "Epoch 3203 Loss is 3638.416958583429\n",
      "Epoch 3204 Loss is 3638.387423468891\n",
      "Epoch 3205 Loss is 3638.3581577792406\n",
      "Epoch 3206 Loss is 3638.329154824847\n",
      "Epoch 3207 Loss is 3638.300407828988\n",
      "Epoch 3208 Loss is 3638.2719099815895\n",
      "Epoch 3209 Loss is 3638.2436542088735\n",
      "Epoch 3210 Loss is 3638.2156331861424\n",
      "Epoch 3211 Loss is 3638.1878395545755\n",
      "Epoch 3212 Loss is 3638.1602657655103\n",
      "Epoch 3213 Loss is 3638.13290417823\n",
      "Epoch 3214 Loss is 3638.105747097061\n",
      "Epoch 3215 Loss is 3638.078786557534\n",
      "Epoch 3216 Loss is 3638.0520145502865\n",
      "Epoch 3217 Loss is 3638.025422882219\n",
      "Epoch 3218 Loss is 3637.9990031943753\n",
      "Epoch 3219 Loss is 3637.972747099272\n",
      "Epoch 3220 Loss is 3637.946646074941\n",
      "Epoch 3221 Loss is 3637.9206914235383\n",
      "Epoch 3222 Loss is 3637.894874361816\n",
      "Epoch 3223 Loss is 3637.8691860329636\n",
      "Epoch 3224 Loss is 3637.843617392329\n",
      "Epoch 3225 Loss is 3637.8181593523977\n",
      "Epoch 3226 Loss is 3637.792802683098\n",
      "Epoch 3227 Loss is 3637.7675378613653\n",
      "Epoch 3228 Loss is 3637.7423552623254\n",
      "Epoch 3229 Loss is 3637.7172452894583\n",
      "Epoch 3230 Loss is 3637.6921981815003\n",
      "Epoch 3231 Loss is 3637.667204058091\n",
      "Epoch 3232 Loss is 3637.6422530687864\n",
      "Epoch 3233 Loss is 3637.6173352648507\n",
      "Epoch 3234 Loss is 3637.5924405276505\n",
      "Epoch 3235 Loss is 3637.567558659893\n",
      "Epoch 3236 Loss is 3637.5426793686215\n",
      "Epoch 3237 Loss is 3637.517792338458\n",
      "Epoch 3238 Loss is 3637.4928871057973\n",
      "Epoch 3239 Loss is 3637.467953123466\n",
      "Epoch 3240 Loss is 3637.4429797768366\n",
      "Epoch 3241 Loss is 3637.417956355726\n",
      "Epoch 3242 Loss is 3637.392872049609\n",
      "Epoch 3243 Loss is 3637.3677160190546\n",
      "Epoch 3244 Loss is 3637.3424774742953\n",
      "Epoch 3245 Loss is 3637.317145455097\n",
      "Epoch 3246 Loss is 3637.2917090136543\n",
      "Epoch 3247 Loss is 3637.266157086695\n",
      "Epoch 3248 Loss is 3637.2404785879276\n",
      "Epoch 3249 Loss is 3637.214662512121\n",
      "Epoch 3250 Loss is 3637.188697709715\n",
      "Epoch 3251 Loss is 3637.1625732088855\n",
      "Epoch 3252 Loss is 3637.1362779088436\n",
      "Epoch 3253 Loss is 3637.109800718653\n",
      "Epoch 3254 Loss is 3637.0831305604156\n",
      "Epoch 3255 Loss is 3637.056256351804\n",
      "Epoch 3256 Loss is 3637.0291671043938\n",
      "Epoch 3257 Loss is 3637.001851804171\n",
      "Epoch 3258 Loss is 3636.9742995525717\n",
      "Epoch 3259 Loss is 3636.9464994117475\n",
      "Epoch 3260 Loss is 3636.918440466655\n",
      "Epoch 3261 Loss is 3636.8901119876978\n",
      "Epoch 3262 Loss is 3636.8615034365644\n",
      "Epoch 3263 Loss is 3636.8326042438725\n",
      "Epoch 3264 Loss is 3636.803403939262\n",
      "Epoch 3265 Loss is 3636.773892211789\n",
      "Epoch 3266 Loss is 3636.7440589849416\n",
      "Epoch 3267 Loss is 3636.7138942465504\n",
      "Epoch 3268 Loss is 3636.6833881580915\n",
      "Epoch 3269 Loss is 3636.652531027769\n",
      "Epoch 3270 Loss is 3636.621313298672\n",
      "Epoch 3271 Loss is 3636.5897256197286\n",
      "Epoch 3272 Loss is 3636.55775880798\n",
      "Epoch 3273 Loss is 3636.525403970162\n",
      "Epoch 3274 Loss is 3636.4926523336544\n",
      "Epoch 3275 Loss is 3636.4594954645327\n",
      "Epoch 3276 Loss is 3636.425925186216\n",
      "Epoch 3277 Loss is 3636.391933532649\n",
      "Epoch 3278 Loss is 3636.3575128050725\n",
      "Epoch 3279 Loss is 3636.3226555851948\n",
      "Epoch 3280 Loss is 3636.287354624787\n",
      "Epoch 3281 Loss is 3636.251603303817\n",
      "Epoch 3282 Loss is 3636.2153950589277\n",
      "Epoch 3283 Loss is 3636.1787235948655\n",
      "Epoch 3284 Loss is 3636.1415828746476\n",
      "Epoch 3285 Loss is 3636.1039673286737\n",
      "Epoch 3286 Loss is 3636.065871739038\n",
      "Epoch 3287 Loss is 3636.0272911964316\n",
      "Epoch 3288 Loss is 3635.9882212313755\n",
      "Epoch 3289 Loss is 3635.9486576703316\n",
      "Epoch 3290 Loss is 3635.9085967617502\n",
      "Epoch 3291 Loss is 3635.868035013687\n",
      "Epoch 3292 Loss is 3635.826969310929\n",
      "Epoch 3293 Loss is 3635.7853969226785\n",
      "Epoch 3294 Loss is 3635.743315599646\n",
      "Epoch 3295 Loss is 3635.70072338224\n",
      "Epoch 3296 Loss is 3635.657618801701\n",
      "Epoch 3297 Loss is 3635.614000595495\n",
      "Epoch 3298 Loss is 3635.5698679420743\n",
      "Epoch 3299 Loss is 3635.5252205091897\n",
      "Epoch 3300 Loss is 3635.4800584384916\n",
      "Epoch 3301 Loss is 3635.434382175479\n",
      "Epoch 3302 Loss is 3635.3881925036767\n",
      "Epoch 3303 Loss is 3635.3414906187\n",
      "Epoch 3304 Loss is 3635.294278085748\n",
      "Epoch 3305 Loss is 3635.2465568091634\n",
      "Epoch 3306 Loss is 3635.1983291345746\n",
      "Epoch 3307 Loss is 3635.149597754087\n",
      "Epoch 3308 Loss is 3635.1003657280867\n",
      "Epoch 3309 Loss is 3635.050636481676\n",
      "Epoch 3310 Loss is 3635.0004138221193\n",
      "Epoch 3311 Loss is 3634.949701923785\n",
      "Epoch 3312 Loss is 3634.898505293112\n",
      "Epoch 3313 Loss is 3634.846828804383\n",
      "Epoch 3314 Loss is 3634.7946775564956\n",
      "Epoch 3315 Loss is 3634.7420570078048\n",
      "Epoch 3316 Loss is 3634.688972842485\n",
      "Epoch 3317 Loss is 3634.6354311086493\n",
      "Epoch 3318 Loss is 3634.581438164447\n",
      "Epoch 3319 Loss is 3634.5270007788954\n",
      "Epoch 3320 Loss is 3634.472125847815\n",
      "Epoch 3321 Loss is 3634.4168206256486\n",
      "Epoch 3322 Loss is 3634.3610927449195\n",
      "Epoch 3323 Loss is 3634.304949895565\n",
      "Epoch 3324 Loss is 3634.24840000107\n",
      "Epoch 3325 Loss is 3634.191451263939\n",
      "Epoch 3326 Loss is 3634.1341120285283\n",
      "Epoch 3327 Loss is 3634.0763906677084\n",
      "Epoch 3328 Loss is 3634.0182959073713\n",
      "Epoch 3329 Loss is 3633.959836648897\n",
      "Epoch 3330 Loss is 3633.9010219807938\n",
      "Epoch 3331 Loss is 3633.841861060857\n",
      "Epoch 3332 Loss is 3633.782363173398\n",
      "Epoch 3333 Loss is 3633.722537684333\n",
      "Epoch 3334 Loss is 3633.662394220121\n",
      "Epoch 3335 Loss is 3633.6019424419596\n",
      "Epoch 3336 Loss is 3633.5411921969\n",
      "Epoch 3337 Loss is 3633.4801533100235\n",
      "Epoch 3338 Loss is 3633.41883580771\n",
      "Epoch 3339 Loss is 3633.3572497430837\n",
      "Epoch 3340 Loss is 3633.2954051084334\n",
      "Epoch 3341 Loss is 3633.233312018718\n",
      "Epoch 3342 Loss is 3633.1709804967977\n",
      "Epoch 3343 Loss is 3633.108420644105\n",
      "Epoch 3344 Loss is 3633.0456425611164\n",
      "Epoch 3345 Loss is 3632.982656006642\n",
      "Epoch 3346 Loss is 3632.9194709870876\n",
      "Epoch 3347 Loss is 3632.8560975759133\n",
      "Epoch 3348 Loss is 3632.7925458846116\n",
      "Epoch 3349 Loss is 3632.728825867569\n",
      "Epoch 3350 Loss is 3632.6649474515243\n",
      "Epoch 3351 Loss is 3632.6009204588113\n",
      "Epoch 3352 Loss is 3632.536754802869\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_wide = mlp.predict(X_train)\n",
    "test_pred_wide = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO - ADD HISTORY (loss and accuracy) AND A WAY TO SAVE THE WEIGHTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIGMOID FUNCtion preDICTING EVERYTHIGN THE SAME CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999,)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.argmax(train_pred_wide, axis=1)\n",
    "test_pred = np.argmax(test_pred_wide, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
